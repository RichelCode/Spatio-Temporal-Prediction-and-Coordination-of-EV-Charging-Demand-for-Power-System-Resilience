{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89513630-ec30-466f-b512-fcd1050f72a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.1+cu121\n",
      "CUDA available: True\n",
      "GPU: Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f9d8553-4c0d-4698-a4bd-7c236dbb911a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: artifacts/pems_graph_dataset_strict.npz\n",
      "Keys: ['X', 'Y', 'A', 'stations', 'timestamps', 'train_starts', 'val_starts', 'test_starts', 'in_len', 'out_len', 'flow_mean', 'flow_std', 'speed_mean', 'speed_std']\n",
      "X: (2208, 1821, 6) Y: (2208, 1821)\n",
      "A: (1821, 1821)\n",
      "IN_LEN: 24 OUT_LEN: 72\n",
      "Stations: 1821\n",
      "Time range: 2024-10-01 00:00:00 → 2024-12-31 23:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134/1765687619.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  IN_LEN  = int(data[\"in_len\"])\n",
      "/tmp/ipykernel_134/1765687619.py:22: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  OUT_LEN = int(data[\"out_len\"])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path(\"artifacts/pems_graph_dataset_strict.npz\")\n",
    "assert DATA_PATH.exists(), f\"Missing dataset: {DATA_PATH}\"\n",
    "\n",
    "data = np.load(DATA_PATH, allow_pickle=True)\n",
    "print(\"Loaded:\", DATA_PATH)\n",
    "print(\"Keys:\", list(data.keys()))\n",
    "\n",
    "X = data[\"X\"].astype(np.float32)          # (T,N,F)\n",
    "Y = data[\"Y\"].astype(np.float32)          # (T,N)\n",
    "A = data[\"A\"].astype(np.float32)          # (N,N)\n",
    "\n",
    "stations = data[\"stations\"]\n",
    "timestamps = pd.to_datetime(data[\"timestamps\"])\n",
    "\n",
    "train_starts = data[\"train_starts\"]\n",
    "val_starts   = data[\"val_starts\"]\n",
    "test_starts  = data[\"test_starts\"]\n",
    "\n",
    "IN_LEN  = int(data[\"in_len\"])\n",
    "OUT_LEN = int(data[\"out_len\"])\n",
    "\n",
    "flow_mean  = data[\"flow_mean\"]\n",
    "flow_std   = data[\"flow_std\"]\n",
    "speed_mean = data[\"speed_mean\"]\n",
    "speed_std  = data[\"speed_std\"]\n",
    "\n",
    "T, N, Fdim = X.shape\n",
    "print(\"X:\", X.shape, \"Y:\", Y.shape)\n",
    "print(\"A:\", A.shape)\n",
    "print(\"IN_LEN:\", IN_LEN, \"OUT_LEN:\", OUT_LEN)\n",
    "print(\"Stations:\", len(stations))\n",
    "print(\"Time range:\", timestamps.min(), \"→\", timestamps.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b7e727-63ad-42f0-8f9c-8fa91dadec11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_sp nnz: 7856\n"
     ]
    }
   ],
   "source": [
    "def scaled_laplacian(A):\n",
    "    A = np.maximum(A, A.T)                     # undirected\n",
    "    A = A + np.eye(A.shape[0], dtype=np.float32)\n",
    "\n",
    "    d = A.sum(axis=1)\n",
    "    d_inv_sqrt = np.power(d, -0.5, where=(d > 0))\n",
    "    d_inv_sqrt[~np.isfinite(d_inv_sqrt)] = 0.0\n",
    "\n",
    "    A_norm = (d_inv_sqrt[:, None] * A) * d_inv_sqrt[None, :]\n",
    "    L = np.eye(A.shape[0], dtype=np.float32) - A_norm\n",
    "\n",
    "    lambda_max = 2.0\n",
    "    L_tilde = (2.0 / lambda_max) * L - np.eye(A.shape[0], dtype=np.float32)\n",
    "    return L_tilde\n",
    "\n",
    "def dense_to_sparse(A_dense, device):\n",
    "    idx = np.nonzero(A_dense)\n",
    "    indices = torch.tensor(np.vstack(idx), dtype=torch.long)\n",
    "    values = torch.tensor(A_dense[idx], dtype=torch.float32)\n",
    "    return torch.sparse_coo_tensor(\n",
    "        indices, values, size=A_dense.shape, device=device\n",
    "    ).coalesce()\n",
    "\n",
    "L_tilde = scaled_laplacian(A)\n",
    "L_sp = dense_to_sparse(L_tilde, DEVICE)\n",
    "\n",
    "print(\"L_sp nnz:\", int(L_sp._nnz()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69bf968f-0273-4521-82ff-96a7521803af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x: torch.Size([8, 6, 1821, 24]) Batch y: torch.Size([8, 72, 1821])\n"
     ]
    }
   ],
   "source": [
    "class STGCNDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y, starts, in_len, out_len,\n",
    "                 flow_mean, flow_std, speed_mean, speed_std):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.starts = starts.astype(int)\n",
    "        self.in_len = in_len\n",
    "        self.out_len = out_len\n",
    "        self.flow_mean = flow_mean\n",
    "        self.flow_std = flow_std\n",
    "        self.speed_mean = speed_mean\n",
    "        self.speed_std = speed_std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.starts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = self.starts[idx]\n",
    "\n",
    "        x = self.X[t:t+self.in_len].copy()      # (IN,N,F)\n",
    "        y = self.Y[t+self.in_len:t+self.in_len+self.out_len].copy()\n",
    "\n",
    "        # scale\n",
    "        x[:, :, 0] = (x[:, :, 0] - self.flow_mean) / self.flow_std\n",
    "        x[:, :, 1] = (x[:, :, 1] - self.speed_mean) / self.speed_std\n",
    "        y = (y - self.flow_mean) / self.flow_std\n",
    "\n",
    "        x = np.transpose(x, (2,1,0))            # (F,N,IN)\n",
    "\n",
    "        return (\n",
    "            torch.tensor(x, dtype=torch.float32),\n",
    "            torch.tensor(y, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "train_ds = STGCNDataset(X, Y, train_starts, IN_LEN, OUT_LEN,\n",
    "                         flow_mean, flow_std, speed_mean, speed_std)\n",
    "val_ds   = STGCNDataset(X, Y, val_starts, IN_LEN, OUT_LEN,\n",
    "                         flow_mean, flow_std, speed_mean, speed_std)\n",
    "test_ds  = STGCNDataset(X, Y, test_starts, IN_LEN, OUT_LEN,\n",
    "                         flow_mean, flow_std, speed_mean, speed_std)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=0, pin_memory=False\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=0, pin_memory=False\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=0, pin_memory=False\n",
    ")\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"Batch x:\", xb.shape, \"Batch y:\", yb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b9ce7c-cc27-4b6e-8de8-5d263ef58a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IN_LEN  = int(np.array(data[\"in_len\"]).item())\n",
    "OUT_LEN = int(np.array(data[\"out_len\"]).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89519cd1-6e06-4b30-80de-4af91db3b4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd3d2b2a-699d-4103-bbda-5116fa04022e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json, time, gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "EVAL_HORIZONS = [12, 24, 48, 72]\n",
    "\n",
    "def print_metrics(title, metrics):\n",
    "    print(\"\\n\" + title)\n",
    "    for h in sorted(metrics.keys()):\n",
    "        print(f\"  {h:>3}h  MAE={metrics[h]['MAE']:.3f}  RMSE={metrics[h]['RMSE']:.3f}\")\n",
    "\n",
    "def avg_mae(metrics):\n",
    "    return float(np.mean([metrics[h][\"MAE\"] for h in metrics]))\n",
    "\n",
    "def _unscale(y_scaled, flow_mean_t, flow_std_t):\n",
    "    return y_scaled * flow_std_t + flow_mean_t\n",
    "\n",
    "@torch.inference_mode()\n",
    "def eval_horizons_fast(model, loader, device, flow_mean, flow_std, eval_horizons=EVAL_HORIZONS):\n",
    "    model.eval()\n",
    "    flow_mean_t = torch.tensor(flow_mean, dtype=torch.float32, device=device).view(1, 1, -1)\n",
    "    flow_std_t  = torch.tensor(flow_std,  dtype=torch.float32, device=device).view(1, 1, -1)\n",
    "    h_idx = torch.tensor([h - 1 for h in eval_horizons], device=device)\n",
    "\n",
    "    acc = {h: {\"abs\": 0.0, \"sq\": 0.0, \"count\": 0} for h in eval_horizons}\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        if len(batch) == 2:\n",
    "            xb, yb = batch\n",
    "            tfb = None\n",
    "        else:\n",
    "            xb, yb, tfb = batch\n",
    "\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "        if tfb is not None:\n",
    "            tfb = tfb.to(device, non_blocking=True)\n",
    "\n",
    "        pred = model(xb, tfb) if tfb is not None else model(xb)  # scaled\n",
    "\n",
    "        pred_u = _unscale(pred, flow_mean_t, flow_std_t)\n",
    "        true_u = _unscale(yb,   flow_mean_t, flow_std_t)\n",
    "\n",
    "        pred_h = pred_u[:, h_idx, :]  # (B, H, N)\n",
    "        true_h = true_u[:, h_idx, :]\n",
    "        err = pred_h - true_h\n",
    "\n",
    "        for i, h in enumerate(eval_horizons):\n",
    "            e = err[:, i, :]\n",
    "            acc[h][\"abs\"] += float(e.abs().sum().item())\n",
    "            acc[h][\"sq\"]  += float((e * e).sum().item())\n",
    "            acc[h][\"count\"] += e.numel()\n",
    "\n",
    "    metrics = {}\n",
    "    for h in eval_horizons:\n",
    "        mae = acc[h][\"abs\"] / acc[h][\"count\"]\n",
    "        rmse = (acc[h][\"sq\"] / acc[h][\"count\"]) ** 0.5\n",
    "        metrics[h] = {\"MAE\": float(mae), \"RMSE\": float(rmse)}\n",
    "    return metrics\n",
    "\n",
    "def make_run_dir(model_name, base_dir=\"artifacts/runs\"):\n",
    "    base = Path(base_dir)\n",
    "    base.mkdir(parents=True, exist_ok=True)\n",
    "    stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = base / f\"{stamp}_{model_name}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def save_json(path: Path, obj):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def metrics_to_flat_row(metrics, prefix):\n",
    "    row = {}\n",
    "    for h in sorted(metrics.keys()):\n",
    "        row[f\"{prefix}_MAE_{h}h\"]  = metrics[h][\"MAE\"]\n",
    "        row[f\"{prefix}_RMSE_{h}h\"] = metrics[h][\"RMSE\"]\n",
    "    return row\n",
    "\n",
    "def append_master_summary(row_dict, master_csv=\"artifacts/results_summary.csv\"):\n",
    "    master = Path(master_csv)\n",
    "    master.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_new = pd.DataFrame([row_dict])\n",
    "    if master.exists():\n",
    "        df_old = pd.read_csv(master)\n",
    "        df = pd.concat([df_old, df_new], ignore_index=True)\n",
    "    else:\n",
    "        df = df_new\n",
    "    df.to_csv(master, index=False)\n",
    "    return master\n",
    "\n",
    "@torch.inference_mode()\n",
    "def collect_preds_true_selected(model, loader, device, flow_mean, flow_std,\n",
    "                               horizons_to_save=(12, 24, 48, 72),\n",
    "                               stations_all=None,\n",
    "                               timestamps_all=None,\n",
    "                               in_len=None,\n",
    "                               max_stations=300):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      pred_u: (S, H, M)\n",
    "      true_u: (S, H, M)\n",
    "      horizons: list\n",
    "      station_ids: (M,)\n",
    "      ts_h: (S, H) timestamps for each sample/horizon if possible else None\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    flow_mean_t = torch.tensor(flow_mean, dtype=torch.float32, device=device).view(1, 1, -1)\n",
    "    flow_std_t  = torch.tensor(flow_std,  dtype=torch.float32, device=device).view(1, 1, -1)\n",
    "    horizons = list(horizons_to_save)\n",
    "    h_idx = torch.tensor([h - 1 for h in horizons], device=device)\n",
    "\n",
    "    # station subset\n",
    "    N = len(stations_all) if stations_all is not None else None\n",
    "    if (max_stations is None) or (N is None) or (max_stations >= N):\n",
    "        sel = None\n",
    "        station_ids = np.array(stations_all) if stations_all is not None else None\n",
    "    else:\n",
    "        sel = np.arange(max_stations, dtype=int)\n",
    "        station_ids = np.array(stations_all)[sel]\n",
    "\n",
    "    preds, trues = [], []\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Collect preds\", leave=False):\n",
    "        if len(batch) == 2:\n",
    "            xb, yb = batch\n",
    "            tfb = None\n",
    "        else:\n",
    "            xb, yb, tfb = batch\n",
    "\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "        if tfb is not None:\n",
    "            tfb = tfb.to(device, non_blocking=True)\n",
    "\n",
    "        pred = model(xb, tfb) if tfb is not None else model(xb)  # scaled\n",
    "\n",
    "        pred_u = _unscale(pred, flow_mean_t, flow_std_t)[:, h_idx, :]  # (B,H,N)\n",
    "        true_u = _unscale(yb,   flow_mean_t, flow_std_t)[:, h_idx, :]\n",
    "\n",
    "        if sel is not None:\n",
    "            pred_u = pred_u[:, :, sel]\n",
    "            true_u = true_u[:, :, sel]\n",
    "\n",
    "        preds.append(pred_u.detach().cpu())\n",
    "        trues.append(true_u.detach().cpu())\n",
    "\n",
    "    pred_u = torch.cat(preds, dim=0).numpy()\n",
    "    true_u = torch.cat(trues, dim=0).numpy()\n",
    "\n",
    "    # timestamps for each sample/horizon (optional)\n",
    "    ts_h = None\n",
    "    if (timestamps_all is not None) and (in_len is not None) and hasattr(loader.dataset, \"starts\"):\n",
    "        starts = np.array(loader.dataset.starts, dtype=int)  # (S,)\n",
    "        # For each horizon h, timestamp = timestamps[start + in_len + (h-1)]\n",
    "        ts_h = np.zeros((len(starts), len(horizons)), dtype=\"datetime64[ns]\")\n",
    "        ts_all = pd.to_datetime(timestamps_all).to_numpy()\n",
    "        for j, h in enumerate(horizons):\n",
    "            ts_h[:, j] = ts_all[starts + in_len + (h - 1)]\n",
    "\n",
    "    return pred_u, true_u, horizons, station_ids, ts_h\n",
    "\n",
    "def save_preds_to_excel_and_csv(run_dir: Path, pred_u, true_u, horizons, station_ids, ts_h=None):\n",
    "    # NPZ (always)\n",
    "    npz_path = run_dir / \"test_pred_true_selected_horizons.npz\"\n",
    "    np.savez_compressed(\n",
    "        npz_path,\n",
    "        pred=pred_u,\n",
    "        true=true_u,\n",
    "        horizons=np.array(horizons, dtype=int),\n",
    "        stations=np.array(station_ids) if station_ids is not None else None,\n",
    "        timestamps=ts_h\n",
    "    )\n",
    "\n",
    "    # Excel + CSV per horizon (readable)\n",
    "    xlsx_path = run_dir / \"test_pred_true_selected_horizons.xlsx\"\n",
    "    csv_dir = run_dir / \"preds_csv\"\n",
    "    csv_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with pd.ExcelWriter(xlsx_path, engine=\"openpyxl\") as writer:\n",
    "        for j, h in enumerate(horizons):\n",
    "            cols = [str(s) for s in station_ids] if station_ids is not None else [f\"node_{i}\" for i in range(pred_u.shape[2])]\n",
    "            df_pred = pd.DataFrame(pred_u[:, j, :], columns=cols)\n",
    "            df_true = pd.DataFrame(true_u[:, j, :], columns=cols)\n",
    "\n",
    "            if ts_h is not None:\n",
    "                df_pred.insert(0, \"timestamp\", pd.to_datetime(ts_h[:, j]))\n",
    "                df_true.insert(0, \"timestamp\", pd.to_datetime(ts_h[:, j]))\n",
    "\n",
    "            df_pred.to_excel(writer, sheet_name=f\"pred_{h}h\", index=False)\n",
    "            df_true.to_excel(writer, sheet_name=f\"true_{h}h\", index=False)\n",
    "\n",
    "            # CSV versions too\n",
    "            df_pred.to_csv(csv_dir / f\"pred_{h}h.csv\", index=False)\n",
    "            df_true.to_csv(csv_dir / f\"true_{h}h.csv\", index=False)\n",
    "\n",
    "    return npz_path, xlsx_path, csv_dir\n",
    "\n",
    "def train_and_save_best(model, model_name, run_dir: Path,\n",
    "                        train_loader, val_loader,\n",
    "                        device,\n",
    "                        flow_mean, flow_std,\n",
    "                        epochs=40, lr=1e-3, weight_decay=1e-4, clip=5.0,\n",
    "                        patience=6, eval_every=2):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.SmoothL1Loss(beta=1.0)\n",
    "\n",
    "    best_score = float(\"inf\")\n",
    "    best_state = None\n",
    "    bad = 0\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Train {epoch}/{epochs}\", leave=False):\n",
    "            if len(batch) == 2:\n",
    "                xb, yb = batch\n",
    "                tfb = None\n",
    "            else:\n",
    "                xb, yb, tfb = batch\n",
    "\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            if tfb is not None:\n",
    "                tfb = tfb.to(device, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            pred = model(xb, tfb) if tfb is not None else model(xb)  # scaled\n",
    "            loss = loss_fn(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "            running += float(loss.item())\n",
    "\n",
    "        train_loss = running / max(1, len(train_loader))\n",
    "\n",
    "        if epoch % eval_every == 0:\n",
    "            val_metrics = eval_horizons_fast(model, val_loader, device, flow_mean, flow_std)\n",
    "            score = avg_mae(val_metrics)\n",
    "\n",
    "            print(f\"\\nEpoch {epoch}: train_loss={train_loss:.6f} val_avg_MAE={score:.3f}\")\n",
    "            print_metrics(\"VAL\", val_metrics)\n",
    "\n",
    "            history.append({\"epoch\": epoch, \"train_loss\": train_loss, \"val_avg_MAE\": score, **metrics_to_flat_row(val_metrics, \"val\")})\n",
    "            pd.DataFrame(history).to_csv(run_dir / \"history.csv\", index=False)\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                torch.save(best_state, run_dir / \"best.pt\")\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= patience:\n",
    "                    print(f\"\\nEarly stopping. Best val_avg_MAE={best_score:.3f}\")\n",
    "                    break\n",
    "\n",
    "    if best_state is None:\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        torch.save(best_state, run_dir / \"best.pt\")\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "def run_experiment_and_save(model_name, model,\n",
    "                            train_loader, val_loader, test_loader,\n",
    "                            device,\n",
    "                            flow_mean, flow_std,\n",
    "                            stations, timestamps,\n",
    "                            in_len,\n",
    "                            epochs=40, patience=6, eval_every=2,\n",
    "                            horizons_to_save=(12, 24, 48, 72),\n",
    "                            max_stations_excel=300):\n",
    "    run_dir = make_run_dir(model_name)\n",
    "    print(\"Run dir:\", run_dir)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Train (and keep saving best.pt + history.csv)\n",
    "    model = train_and_save_best(\n",
    "        model=model,\n",
    "        model_name=model_name,\n",
    "        run_dir=run_dir,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        flow_mean=flow_mean,\n",
    "        flow_std=flow_std,\n",
    "        epochs=epochs,\n",
    "        patience=patience,\n",
    "        eval_every=eval_every\n",
    "    )\n",
    "\n",
    "    # TEST\n",
    "    print(\"\\nEvaluating on TEST set...\")\n",
    "    test_metrics = eval_horizons_fast(model, test_loader, device, flow_mean, flow_std)\n",
    "    print_metrics(f\"{model_name} — TEST\", test_metrics)\n",
    "\n",
    "    save_json(run_dir / \"test_metrics.json\", test_metrics)\n",
    "    pd.DataFrame([metrics_to_flat_row(test_metrics, \"test\")]).to_csv(run_dir / \"test_metrics.csv\", index=False)\n",
    "\n",
    "    # Save preds/true for selected horizons + subset of stations (NPZ + XLSX + CSV)\n",
    "    pred_u, true_u, horizons, station_ids, ts_h = collect_preds_true_selected(\n",
    "        model=model,\n",
    "        loader=test_loader,\n",
    "        device=device,\n",
    "        flow_mean=flow_mean,\n",
    "        flow_std=flow_std,\n",
    "        horizons_to_save=horizons_to_save,\n",
    "        stations_all=stations,\n",
    "        timestamps_all=timestamps,\n",
    "        in_len=in_len,\n",
    "        max_stations=max_stations_excel\n",
    "    )\n",
    "\n",
    "    npz_path, xlsx_path, csv_dir = save_preds_to_excel_and_csv(run_dir, pred_u, true_u, horizons, station_ids, ts_h)\n",
    "\n",
    "    # Append to master summary\n",
    "    row = {\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model_name\": model_name,\n",
    "        \"run_dir\": str(run_dir),\n",
    "        **metrics_to_flat_row(test_metrics, \"test\")\n",
    "    }\n",
    "    master = append_master_summary(row)\n",
    "\n",
    "    print(\"\\nSaved run outputs to:\", run_dir)\n",
    "    print(\" - best checkpoint:\", run_dir / \"best.pt\")\n",
    "    print(\" - history:\", run_dir / \"history.csv\")\n",
    "    print(\" - test metrics (json):\", run_dir / \"test_metrics.json\")\n",
    "    print(\" - test metrics (csv):\", run_dir / \"test_metrics.csv\")\n",
    "    print(\" - predictions (npz):\", npz_path)\n",
    "    print(\" - predictions (xlsx):\", xlsx_path)\n",
    "    print(\" - predictions (csv folder):\", csv_dir)\n",
    "    print(\" - master summary:\", master)\n",
    "\n",
    "    return run_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f70b0ef1-a15f-4c5c-a382-7f3650912c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STGCN_RNNHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrap a base STGCN model and refine its multi-horizon output using GRU/LSTM.\n",
    "    Base model must output (B, OUT_LEN, N) in *scaled* space.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model: nn.Module, out_len: int, rnn_hidden: int = 128,\n",
    "                 use_gru: bool = False, use_lstm: bool = False):\n",
    "        super().__init__()\n",
    "        assert use_gru or use_lstm, \"Turn on at least one of use_gru/use_lstm.\"\n",
    "        self.base = base_model\n",
    "        self.out_len = out_len\n",
    "\n",
    "        in_dim = 1  # we feed the STGCN scalar output sequence per node\n",
    "\n",
    "        self.gru = nn.GRU(in_dim, rnn_hidden, batch_first=True) if use_gru else None\n",
    "        rnn_in = rnn_hidden if use_gru else in_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(rnn_in, rnn_hidden, batch_first=True) if use_lstm else None\n",
    "        rnn_out = rnn_hidden if use_lstm else rnn_in\n",
    "\n",
    "        self.proj = nn.Linear(rnn_out, 1)\n",
    "\n",
    "    def forward(self, x, tf=None):\n",
    "        y0 = self.base(x, tf) if tf is not None else self.base(x)   # (B, T, N)\n",
    "        B, T, N = y0.shape\n",
    "\n",
    "        seq = y0.permute(0, 2, 1).contiguous().view(B * N, T, 1)     # (B*N, T, 1)\n",
    "\n",
    "        out = seq\n",
    "        if self.gru is not None:\n",
    "            out, _ = self.gru(out)\n",
    "        if self.lstm is not None:\n",
    "            out, _ = self.lstm(out)\n",
    "\n",
    "        out = self.proj(out)                                        # (B*N, T, 1)\n",
    "        out = out.view(B, N, T).permute(0, 2, 1).contiguous()        # (B, T, N)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813ac5f4-0f13-4f25-aec7-dce9ab87546b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_stgcn():\n",
    "    return STGCN_MultiHorizon(\n",
    "        num_nodes=N,\n",
    "        in_dim=Fdim,\n",
    "        out_len=OUT_LEN,\n",
    "        L_sp=L_sp,\n",
    "        kt=3,\n",
    "        Ks=3,\n",
    "        dropout=0.1,\n",
    "        c_t=64, c_s=16, c_out=64,\n",
    "        blocks=2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7dc5a59-53d5-4795-9fba-ebd9cb8de265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# -------------------------\n",
    "# Helpers: sparse node-mix\n",
    "# -------------------------\n",
    "def nconv_sparse(x: torch.Tensor, A_sp: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x: (B, C, N, T)\n",
    "    A_sp: sparse (N, N)\n",
    "    returns: (B, C, N, T)\n",
    "    \"\"\"\n",
    "    B, C, N, T = x.shape\n",
    "    x_r = x.permute(2, 0, 1, 3).reshape(N, -1)          # (N, B*C*T)\n",
    "    x_r = torch.sparse.mm(A_sp, x_r)                    # (N, B*C*T)\n",
    "    x_out = x_r.reshape(N, B, C, T).permute(1, 2, 0, 3) # (B,C,N,T)\n",
    "    return x_out\n",
    "\n",
    "\n",
    "class TemporalConvGLU(nn.Module):\n",
    "    \"\"\"\n",
    "    Causal temporal conv with GLU gating.\n",
    "    Input/Output: (B,C,N,T)\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in: int, c_out: int, kt: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.kt = kt\n",
    "        self.conv = nn.Conv2d(c_in, 2*c_out, kernel_size=(1, kt), bias=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # causal pad on the left in time dimension (last dim)\n",
    "        x = F.pad(x, (self.kt - 1, 0, 0, 0))     # pad time: (left, right, top, bottom) for last two dims\n",
    "        z = self.conv(x)                         # (B, 2*Cout, N, T)\n",
    "        a, b = z.chunk(2, dim=1)\n",
    "        out = a * torch.sigmoid(b)\n",
    "        return self.dropout(out)\n",
    "\n",
    "\n",
    "class ChebGraphConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Chebyshev graph convolution with Ks terms.\n",
    "    Uses sparse scaled Laplacian L_sp (N,N).\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in: int, c_out: int, Ks: int, L_sp: torch.Tensor):\n",
    "        super().__init__()\n",
    "        assert Ks >= 1\n",
    "        self.Ks = Ks\n",
    "        self.L_sp = L_sp\n",
    "        self.theta = nn.Conv2d(Ks * c_in, c_out, kernel_size=(1, 1), bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,C,N,T)\n",
    "        out = [x]  # T0\n",
    "        if self.Ks > 1:\n",
    "            x1 = nconv_sparse(x, self.L_sp)  # T1\n",
    "            out.append(x1)\n",
    "            for _ in range(2, self.Ks):\n",
    "                x2 = 2 * nconv_sparse(out[-1], self.L_sp) - out[-2]  # Tk\n",
    "                out.append(x2)\n",
    "\n",
    "        x_cat = torch.cat(out, dim=1)  # (B, Ks*C, N, T)\n",
    "        return self.theta(x_cat)\n",
    "\n",
    "\n",
    "class STConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ST block: TemporalConv -> GraphConv -> TemporalConv (+ residual)\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_t, c_s, c_out, kt, Ks, L_sp, dropout):\n",
    "        super().__init__()\n",
    "        self.temp1 = TemporalConvGLU(c_in,  c_t,  kt=kt, dropout=dropout)\n",
    "        self.gconv = ChebGraphConv(c_t, c_s, Ks=Ks, L_sp=L_sp)\n",
    "        self.temp2 = TemporalConvGLU(c_s,  c_out, kt=kt, dropout=dropout)\n",
    "\n",
    "        self.res = None\n",
    "        if c_in != c_out:\n",
    "            self.res = nn.Conv2d(c_in, c_out, kernel_size=(1,1))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "        x = self.temp1(x)\n",
    "        x = F.relu(self.gconv(x))\n",
    "        x = self.temp2(x)\n",
    "\n",
    "        if self.res is not None:\n",
    "            x_in = self.res(x_in)\n",
    "\n",
    "        x = F.relu(x + x_in)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class STGCN_MultiHorizon(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-horizon forecaster:\n",
    "      encode past window -> take last time state -> project to OUT_LEN for each node\n",
    "    forward(x, tf) keeps signature compatible (tf is ignored here).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes: int,\n",
    "        in_dim: int,\n",
    "        out_len: int,\n",
    "        L_sp: torch.Tensor,\n",
    "        kt: int = 3,\n",
    "        Ks: int = 3,\n",
    "        dropout: float = 0.1,\n",
    "        c_t: int = 64,\n",
    "        c_s: int = 16,\n",
    "        c_out: int = 64,\n",
    "        blocks: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.in_dim = in_dim\n",
    "        self.out_len = out_len\n",
    "        self.c_out = c_out\n",
    "\n",
    "        layers = []\n",
    "        c_in = in_dim\n",
    "        for _ in range(blocks):\n",
    "            layers.append(STConvBlock(\n",
    "                c_in=c_in, c_t=c_t, c_s=c_s, c_out=c_out,\n",
    "                kt=kt, Ks=Ks, L_sp=L_sp, dropout=dropout\n",
    "            ))\n",
    "            c_in = c_out\n",
    "        self.blocks = nn.ModuleList(layers)\n",
    "\n",
    "        # node-wise linear map: (B, c_out, N) -> (B, out_len, N)\n",
    "        self.head = nn.Conv1d(c_out, out_len, kernel_size=1)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # x: (B,F,N,T)\n",
    "        h = x\n",
    "        for blk in self.blocks:\n",
    "            h = blk(h)  # (B,c_out,N,T)\n",
    "        return h\n",
    "\n",
    "    def forward(self, x, tf=None):\n",
    "        h = self.encode(x)\n",
    "        h_last = h[:, :, :, -1]           # (B, c_out, N)\n",
    "        out = self.head(h_last)           # (B, out_len, N)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a630419-45ea-4577-a54d-34a79962cd92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STGCN_RNNHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrap STGCN encoder with optional GRU and/or LSTM over the encoder time sequence per node.\n",
    "    If both are enabled: GRU -> LSTM (stacked).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        base: STGCN_MultiHorizon,\n",
    "        out_len: int,\n",
    "        rnn_hidden: int = 128,\n",
    "        use_gru: bool = False,\n",
    "        use_lstm: bool = False,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert use_gru or use_lstm, \"Enable at least one of GRU/LSTM\"\n",
    "        self.base = base\n",
    "        self.out_len = out_len\n",
    "        self.use_gru = use_gru\n",
    "        self.use_lstm = use_lstm\n",
    "        self.rnn_hidden = rnn_hidden\n",
    "\n",
    "        enc_dim = base.c_out\n",
    "\n",
    "        self.gru = None\n",
    "        self.lstm = None\n",
    "\n",
    "        if use_gru:\n",
    "            self.gru = nn.GRU(\n",
    "                input_size=enc_dim,\n",
    "                hidden_size=rnn_hidden,\n",
    "                num_layers=1,\n",
    "                batch_first=True,\n",
    "                dropout=0.0\n",
    "            )\n",
    "\n",
    "        if use_lstm:\n",
    "            lstm_in = rnn_hidden if use_gru else enc_dim\n",
    "            self.lstm = nn.LSTM(\n",
    "                input_size=lstm_in,\n",
    "                hidden_size=rnn_hidden,\n",
    "                num_layers=1,\n",
    "                batch_first=True,\n",
    "                dropout=0.0\n",
    "            )\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.head = nn.Conv1d(rnn_hidden, out_len, kernel_size=1)\n",
    "\n",
    "    def forward(self, x, tf=None):\n",
    "        # Encode: (B,C,N,T)\n",
    "        feat = self.base.encode(x)\n",
    "        B, C, N, T = feat.shape\n",
    "\n",
    "        # per-node sequences: (B*N, T, C)\n",
    "        seq = feat.permute(0, 2, 3, 1).contiguous().view(B*N, T, C)\n",
    "\n",
    "        if self.use_gru:\n",
    "            seq, _ = self.gru(seq)  # (B*N, T, H)\n",
    "\n",
    "        if self.use_lstm:\n",
    "            seq, _ = self.lstm(seq) # (B*N, T, H)\n",
    "\n",
    "        last = seq[:, -1, :]                    # (B*N, H)\n",
    "        last = self.drop(last)\n",
    "        last = last.view(B, N, self.rnn_hidden).permute(0, 2, 1)  # (B,H,N)\n",
    "\n",
    "        out = self.head(last)                   # (B,out_len,N)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98de8f6d-3b60-499e-8841-079fa50e00fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def save_pred_true_csv_long(\n",
    "    out_csv: Path,\n",
    "    pred_u: np.ndarray,   # (S, H, N)\n",
    "    true_u: np.ndarray,   # (S, H, N)\n",
    "    horizons: list[int],\n",
    "    station_ids: list[str] | None = None,\n",
    "    max_stations: int = 300,\n",
    "):\n",
    "    \"\"\"\n",
    "    Saves long-form CSV:\n",
    "      sample, horizon, station, y_true, y_pred\n",
    "    To keep it sane, we limit to first max_stations.\n",
    "    \"\"\"\n",
    "    S, H, N = pred_u.shape\n",
    "    assert H == len(horizons)\n",
    "\n",
    "    take = min(N, max_stations)\n",
    "    stations = station_ids[:take] if station_ids is not None else [f\"node_{i}\" for i in range(take)]\n",
    "\n",
    "    rows = []\n",
    "    for hi, h in enumerate(horizons):\n",
    "        # (S, take)\n",
    "        p = pred_u[:, hi, :take]\n",
    "        t = true_u[:, hi, :take]\n",
    "\n",
    "        # build long rows efficiently\n",
    "        sample_idx = np.repeat(np.arange(S), take)\n",
    "        station_col = np.tile(np.array(stations, dtype=object), S)\n",
    "\n",
    "        df_h = pd.DataFrame({\n",
    "            \"sample\": sample_idx,\n",
    "            \"horizon_h\": h,\n",
    "            \"station\": station_col,\n",
    "            \"y_true\": t.reshape(-1),\n",
    "            \"y_pred\": p.reshape(-1),\n",
    "        })\n",
    "        rows.append(df_h)\n",
    "\n",
    "    df = pd.concat(rows, ignore_index=True)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return out_csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d3352-3e78-444b-b8a3-eabbe61866a6",
   "metadata": {},
   "source": [
    "### WORKING ON STGCN AGAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "691985f4-5b04-4bc4-a410-ed56026f3e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.1.1+cu121\n",
      "Device: cuda\n",
      "GPU: Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "import os, json, time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ---------------- Repro ----------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Device:\", DEVICE)\n",
    "if DEVICE == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1705b30d-f128-4bf7-9f88-fb7d56704077",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: artifacts/pems_graph_dataset_strict.npz\n",
      "Keys: ['X', 'Y', 'A', 'stations', 'timestamps', 'train_starts', 'val_starts', 'test_starts', 'in_len', 'out_len', 'flow_mean', 'flow_std', 'speed_mean', 'speed_std']\n",
      "\n",
      "Shapes:\n",
      "X_raw: (2208, 1821, 6) (T,N,F)\n",
      "Y_raw: (2208, 1821) (T,N)\n",
      "A: (1821, 1821)\n",
      "IN_LEN: 24 OUT_LEN: 72\n",
      "train/val/test starts: 1009 289 673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134/3711306228.py:18: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  IN_LEN  = int(data[\"in_len\"])\n",
      "/tmp/ipykernel_134/3711306228.py:19: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  OUT_LEN = int(data[\"out_len\"])\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"artifacts/pems_graph_dataset_strict.npz\")\n",
    "assert DATA_PATH.exists(), f\"Missing {DATA_PATH}. Rebuild the dataset first.\"\n",
    "\n",
    "data = np.load(DATA_PATH, allow_pickle=True)\n",
    "print(\"Loaded:\", DATA_PATH)\n",
    "print(\"Keys:\", list(data.keys()))\n",
    "\n",
    "X_raw = data[\"X\"]            # (T, N, F)\n",
    "Y_raw = data[\"Y\"]            # (T, N)  (flow target)\n",
    "A = data[\"A\"]                # (N, N)\n",
    "stations = data[\"stations\"]\n",
    "timestamps = data[\"timestamps\"]\n",
    "\n",
    "train_starts = data[\"train_starts\"]\n",
    "val_starts   = data[\"val_starts\"]\n",
    "test_starts  = data[\"test_starts\"]\n",
    "\n",
    "IN_LEN  = int(data[\"in_len\"])\n",
    "OUT_LEN = int(data[\"out_len\"])\n",
    "\n",
    "flow_mean = data[\"flow_mean\"]   # (N,)\n",
    "flow_std  = data[\"flow_std\"]    # (N,)\n",
    "speed_mean = data[\"speed_mean\"] # (N,)\n",
    "speed_std  = data[\"speed_std\"]  # (N,)\n",
    "\n",
    "T, N, Fdim = X_raw.shape\n",
    "print(\"\\nShapes:\")\n",
    "print(\"X_raw:\", X_raw.shape, \"(T,N,F)\")\n",
    "print(\"Y_raw:\", Y_raw.shape, \"(T,N)\")\n",
    "print(\"A:\", A.shape)\n",
    "print(\"IN_LEN:\", IN_LEN, \"OUT_LEN:\", OUT_LEN)\n",
    "print(\"train/val/test starts:\", len(train_starts), len(val_starts), len(test_starts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc4fc82b-e352-4a7f-a921-51fd16e48c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_fnt: (6, 1821, 2208) Y_scaled: (2208, 1821) TF_all: (2208, 4)\n",
      "Sanity (Y_scaled mean/std approx): -780.4212036132812 30666.189453125\n"
     ]
    }
   ],
   "source": [
    "def time_encoding(dt_index: pd.DatetimeIndex) -> np.ndarray:\n",
    "    hours = dt_index.hour.values\n",
    "    dow   = dt_index.dayofweek.values\n",
    "    hour_sin = np.sin(2*np.pi*hours/24.0)\n",
    "    hour_cos = np.cos(2*np.pi*hours/24.0)\n",
    "    dow_sin  = np.sin(2*np.pi*dow/7.0)\n",
    "    dow_cos  = np.cos(2*np.pi*dow/7.0)\n",
    "    return np.stack([hour_sin, hour_cos, dow_sin, dow_cos], axis=1).astype(np.float32)\n",
    "\n",
    "dt_idx = pd.to_datetime(timestamps)\n",
    "TF_all = time_encoding(dt_idx)         # (T,4)\n",
    "\n",
    "# ----- scale inputs -----\n",
    "X_scaled = X_raw.astype(np.float32).copy()\n",
    "X_scaled[:, :, 0] = (X_scaled[:, :, 0] - flow_mean[None, :]) / (flow_std[None, :] + 1e-6)\n",
    "X_scaled[:, :, 1] = (X_scaled[:, :, 1] - speed_mean[None, :]) / (speed_std[None, :] + 1e-6)\n",
    "\n",
    "# ----- scale targets (flow) -----\n",
    "Y_scaled = (Y_raw.astype(np.float32) - flow_mean[None, :]) / (flow_std[None, :] + 1e-6)\n",
    "\n",
    "# Store for fast slicing as (F,N,T)\n",
    "X_fnt = np.transpose(X_scaled, (2, 1, 0)).copy()  # (F,N,T)\n",
    "\n",
    "print(\"X_fnt:\", X_fnt.shape, \"Y_scaled:\", Y_scaled.shape, \"TF_all:\", TF_all.shape)\n",
    "print(\"Sanity (Y_scaled mean/std approx):\", float(Y_scaled.mean()), float(Y_scaled.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8f7a593-ee85-467e-b6dd-a95264f34500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x: torch.Size([8, 6, 1821, 24]) Batch y: torch.Size([8, 72, 1821]) Batch tf: torch.Size([8, 72, 4])\n"
     ]
    }
   ],
   "source": [
    "class FastPeMSWindowDataset(Dataset):\n",
    "    def __init__(self, X_fnt, Y_scaled, TF_all, starts, in_len, out_len):\n",
    "        self.X_fnt = X_fnt\n",
    "        self.Y = Y_scaled\n",
    "        self.TF = TF_all\n",
    "        self.starts = starts.astype(np.int64)\n",
    "        self.in_len = int(in_len)\n",
    "        self.out_len = int(out_len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.starts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = int(self.starts[idx])\n",
    "        x = self.X_fnt[:, :, t:t+self.in_len]  # (F,N,IN_LEN)\n",
    "        y = self.Y[t+self.in_len:t+self.in_len+self.out_len, :]  # (OUT_LEN,N)\n",
    "        tf = self.TF[t+self.in_len:t+self.in_len+self.out_len, :]  # (OUT_LEN,4)\n",
    "        return (\n",
    "            torch.from_numpy(x).float(),\n",
    "            torch.from_numpy(y).float(),\n",
    "            torch.from_numpy(tf).float()\n",
    "        )\n",
    "\n",
    "train_ds = FastPeMSWindowDataset(X_fnt, Y_scaled, TF_all, train_starts, IN_LEN, OUT_LEN)\n",
    "val_ds   = FastPeMSWindowDataset(X_fnt, Y_scaled, TF_all, val_starts,   IN_LEN, OUT_LEN)\n",
    "test_ds  = FastPeMSWindowDataset(X_fnt, Y_scaled, TF_all, test_starts,  IN_LEN, OUT_LEN)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0, pin_memory=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "print(\"Batch x:\", xb.shape, \"Batch y:\", yb.shape, \"Batch tf:\", tfb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23ca9bf5-4491-41d9-9164-6e64ed0bb2da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_sp nnz: 7856\n"
     ]
    }
   ],
   "source": [
    "def dense_to_sparse(A_dense: np.ndarray, device: str):\n",
    "    idx = np.nonzero(A_dense)\n",
    "    indices = torch.from_numpy(np.vstack(idx)).long()\n",
    "    values  = torch.from_numpy(A_dense[idx].astype(np.float32))\n",
    "    sp = torch.sparse_coo_tensor(indices, values, size=A_dense.shape, device=device)\n",
    "    return sp.coalesce()\n",
    "\n",
    "def scaled_laplacian(A: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build scaled Laplacian L_tilde = (2/lambda_max)*L - I.\n",
    "    We follow the common approximation lambda_max ≈ 2. :contentReference[oaicite:3]{index=3}\n",
    "    \"\"\"\n",
    "    A = A.astype(np.float32)\n",
    "    # Make undirected for STGCN (common choice)\n",
    "    A = np.maximum(A, A.T)\n",
    "\n",
    "    # Add self loops\n",
    "    A = A + np.eye(A.shape[0], dtype=np.float32)\n",
    "\n",
    "    d = A.sum(axis=1)\n",
    "    d_inv_sqrt = np.power(d, -0.5, where=(d > 0))\n",
    "    d_inv_sqrt[~np.isfinite(d_inv_sqrt)] = 0.0\n",
    "\n",
    "    A_norm = (d_inv_sqrt[:, None] * A) * d_inv_sqrt[None, :]\n",
    "    L = np.eye(A.shape[0], dtype=np.float32) - A_norm\n",
    "\n",
    "    lambda_max = 2.0\n",
    "    L_tilde = (2.0 / lambda_max) * L - np.eye(A.shape[0], dtype=np.float32)\n",
    "    return L_tilde\n",
    "\n",
    "L_tilde = scaled_laplacian(A)\n",
    "L_sp = dense_to_sparse(L_tilde, DEVICE)\n",
    "print(\"L_sp nnz:\", int(L_sp._nnz()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d387f1c5-ca91-483b-a325-efd5807832a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EVAL_HORIZONS = [12, 24, 48, 72]\n",
    "h_idx = torch.tensor([h-1 for h in EVAL_HORIZONS], device=DEVICE)\n",
    "\n",
    "flow_mean_t = torch.tensor(flow_mean, dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "flow_std_t  = torch.tensor(flow_std,  dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "\n",
    "def print_metrics(title, metrics):\n",
    "    print(\"\\n\" + title)\n",
    "    for h in sorted(metrics.keys()):\n",
    "        print(f\"  {h:>3}h  MAE={metrics[h]['MAE']:.3f}  RMSE={metrics[h]['RMSE']:.3f}\")\n",
    "\n",
    "def avg_mae(metrics):\n",
    "    return float(np.mean([metrics[h][\"MAE\"] for h in metrics]))\n",
    "\n",
    "@torch.inference_mode()\n",
    "def eval_horizons_fast(model, loader):\n",
    "    model.eval()\n",
    "    acc = {h: {\"abs\": 0.0, \"sq\": 0.0, \"count\": 0} for h in EVAL_HORIZONS}\n",
    "\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        pred = model(xb, tfb)  # MUST be scaled outputs (B,OUT_LEN,N)\n",
    "\n",
    "        pred_u = pred * flow_std_t + flow_mean_t\n",
    "        true_u = yb   * flow_std_t + flow_mean_t\n",
    "\n",
    "        # selected horizons\n",
    "        pred_sel = pred_u[:, h_idx, :]\n",
    "        true_sel = true_u[:, h_idx, :]\n",
    "        for i, h in enumerate(EVAL_HORIZONS):\n",
    "            err = pred_sel[:, i, :] - true_sel[:, i, :]\n",
    "            acc[h][\"abs\"] += float(err.abs().sum())\n",
    "            acc[h][\"sq\"]  += float((err ** 2).sum())\n",
    "            acc[h][\"count\"] += err.numel()\n",
    "\n",
    "    metrics = {}\n",
    "    for h in EVAL_HORIZONS:\n",
    "        mae = acc[h][\"abs\"] / acc[h][\"count\"]\n",
    "        rmse = (acc[h][\"sq\"] / acc[h][\"count\"]) ** 0.5\n",
    "        metrics[h] = {\"MAE\": mae, \"RMSE\": rmse}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0457d4f1-c83c-4f14-9f57-edf959387477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NConv(nn.Module):\n",
    "    \"\"\"Sparse matrix multiply along node dimension.\"\"\"\n",
    "    def forward(self, x, A_sp):\n",
    "        # x: (B, C, N, T)\n",
    "        B, C, N, T = x.shape\n",
    "        x_r = x.permute(2, 0, 1, 3).reshape(N, -1).float()      # (N, B*C*T)\n",
    "        x_r = torch.sparse.mm(A_sp, x_r)                         # (N, B*C*T)\n",
    "        x_out = x_r.reshape(N, B, C, T).permute(1, 2, 0, 3)      # (B, C, N, T)\n",
    "        return x_out\n",
    "\n",
    "class ChebGraphConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Chebyshev graph conv using recurrence:\n",
    "      T0(X)=X\n",
    "      T1(X)=L~ X\n",
    "      Tk(X)=2 L~ T_{k-1}(X) - T_{k-2}(X)\n",
    "    Then 1x1 conv mixes the K stacks.\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out, K, L_sp):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.L_sp = L_sp\n",
    "        self.nconv = NConv()\n",
    "        self.mlp = nn.Conv2d(c_in * K, c_out, kernel_size=(1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,C,N,T)\n",
    "        out = [x]\n",
    "        if self.K > 1:\n",
    "            x1 = self.nconv(x, self.L_sp)\n",
    "            out.append(x1)\n",
    "        for k in range(2, self.K):\n",
    "            x2 = 2.0 * self.nconv(out[-1], self.L_sp) - out[-2]\n",
    "            out.append(x2)\n",
    "\n",
    "        h = torch.cat(out, dim=1)  # (B, C*K, N, T)\n",
    "        return self.mlp(h)\n",
    "\n",
    "class TemporalGLU(nn.Module):\n",
    "    \"\"\"Temporal convolution + GLU gating. No padding -> time shrinks.\"\"\"\n",
    "    def __init__(self, c_in, c_out, kt):\n",
    "        super().__init__()\n",
    "        self.kt = kt\n",
    "        self.conv = nn.Conv2d(c_in, 2*c_out, kernel_size=(1, kt))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,C,N,T)\n",
    "        z = self.conv(x)                 # (B,2C,N,T-kt+1)\n",
    "        P, Q = torch.chunk(z, 2, dim=1)  # each (B,C,N,T')\n",
    "        return P * torch.sigmoid(Q)\n",
    "\n",
    "class STConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    STGCN block: TemporalGLU -> ChebGraphConv -> ReLU -> TemporalGLU\n",
    "    + residual (time-aligned) + LayerNorm over channels\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_t, c_s, c_out, kt, Ks, L_sp, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.temporal1 = TemporalGLU(c_in, c_t, kt)\n",
    "        self.graphconv = ChebGraphConv(c_t, c_s, Ks, L_sp)\n",
    "        self.temporal2 = TemporalGLU(c_s, c_out, kt)\n",
    "\n",
    "        self.res_conv = None\n",
    "        if c_in != c_out:\n",
    "            self.res_conv = nn.Conv2d(c_in, c_out, kernel_size=(1,1))\n",
    "\n",
    "        self.ln = nn.LayerNorm(c_out)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        self.kt = kt\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,C_in,N,T)\n",
    "        x_in = x\n",
    "        x = self.temporal1(x)            # (B,c_t,N,T1)\n",
    "        x = self.graphconv(x)            # (B,c_s,N,T1)\n",
    "        x = F.relu(x)\n",
    "        x = self.temporal2(x)            # (B,c_out,N,T2)\n",
    "\n",
    "        # residual: align last T2 timesteps\n",
    "        T2 = x.shape[-1]\n",
    "        res = x_in[..., -T2:]\n",
    "        if self.res_conv is not None:\n",
    "            res = self.res_conv(res)\n",
    "        x = x + res\n",
    "\n",
    "        x = self.drop(x)\n",
    "\n",
    "        # LayerNorm over channels (per node per time)\n",
    "        x = x.permute(0, 2, 3, 1)        # (B,N,T,C)\n",
    "        x = self.ln(x)\n",
    "        x = x.permute(0, 3, 1, 2)        # (B,C,N,T)\n",
    "        return x\n",
    "\n",
    "class STGCN_MultiHorizon(nn.Module):\n",
    "    \"\"\"\n",
    "    STGCN encoder + multi-horizon head.\n",
    "    Output is (B, OUT_LEN, N) in SCALED space (no unscale inside).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_nodes, in_dim, out_len, L_sp,\n",
    "                 kt=3, Ks=3, dropout=0.1,\n",
    "                 c_t=64, c_s=16, c_out=64, blocks=2):\n",
    "        super().__init__()\n",
    "        self.out_len = out_len\n",
    "\n",
    "        layers = []\n",
    "        c_in = in_dim\n",
    "        for _ in range(blocks):\n",
    "            layers.append(STConvBlock(c_in, c_t=c_t, c_s=c_s, c_out=c_out,\n",
    "                                      kt=kt, Ks=Ks, L_sp=L_sp, dropout=dropout))\n",
    "            c_in = c_out\n",
    "        self.blocks = nn.ModuleList(layers)\n",
    "\n",
    "        # After blocks, time is reduced by blocks * 2*(kt-1)\n",
    "        # We will infer the remaining time at runtime and build head lazily if needed.\n",
    "        self.head = None\n",
    "        self.c_out = c_out\n",
    "\n",
    "    def _build_head(self, T_rem):\n",
    "        # Collapse time dimension into 1, output channels = out_len\n",
    "        self.head = nn.Conv2d(self.c_out, self.out_len, kernel_size=(1, T_rem))\n",
    "\n",
    "    def forward(self, x, tf_future=None):\n",
    "        # x: (B,F,N,IN_LEN)\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        T_rem = x.shape[-1]\n",
    "        if self.head is None:\n",
    "            self._build_head(T_rem)\n",
    "            self.head = self.head.to(x.device)\n",
    "\n",
    "        y = self.head(x)       # (B,OUT_LEN,N,1)\n",
    "        y = y.squeeze(-1)      # (B,OUT_LEN,N)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19cb7d69-1f9c-4358-98da-88e75bccf54c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ART_DIR = Path(\"artifacts\")\n",
    "RUNS_DIR = ART_DIR / \"runs\"\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def make_run_dir(model_name: str) -> Path:\n",
    "    ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = RUNS_DIR / f\"{ts}_{model_name}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def save_json(path: Path, obj: dict):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def metrics_to_flat_row(model_name: str, split: str, metrics: dict) -> dict:\n",
    "    row = {\"model_name\": model_name, \"split\": split}\n",
    "    for h in EVAL_HORIZONS:\n",
    "        row[f\"{split}_MAE_{h}h\"] = metrics[h][\"MAE\"]\n",
    "        row[f\"{split}_RMSE_{h}h\"] = metrics[h][\"RMSE\"]\n",
    "    row[f\"{split}_avg_MAE\"] = avg_mae(metrics)\n",
    "    return row\n",
    "\n",
    "def append_results_summary(row: dict, out_csv: Path = ART_DIR/\"results_summary.csv\"):\n",
    "    df_new = pd.DataFrame([row])\n",
    "    if out_csv.exists():\n",
    "        df_old = pd.read_csv(out_csv)\n",
    "        df = pd.concat([df_old, df_new], ignore_index=True)\n",
    "    else:\n",
    "        df = df_new\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return out_csv\n",
    "\n",
    "@torch.inference_mode()\n",
    "def collect_predictions_selected_horizons(model, loader, horizons=(12,24,48,72)):\n",
    "    model.eval()\n",
    "    h_idx_local = torch.tensor([h-1 for h in horizons], device=DEVICE)\n",
    "    preds_all = []\n",
    "    trues_all = []\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Collect preds\", leave=False):\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "        tfb = tfb.to(DEVICE)\n",
    "        pred = model(xb, tfb)  # scaled\n",
    "\n",
    "        pred_u = pred * flow_std_t + flow_mean_t\n",
    "        true_u = yb   * flow_std_t + flow_mean_t\n",
    "\n",
    "        preds_all.append(pred_u[:, h_idx_local, :].detach().cpu().numpy())\n",
    "        trues_all.append(true_u[:, h_idx_local, :].detach().cpu().numpy())\n",
    "\n",
    "    preds_all = np.concatenate(preds_all, axis=0)  # (Btot, Hsel, N)\n",
    "    trues_all = np.concatenate(trues_all, axis=0)\n",
    "    return preds_all, trues_all, horizons\n",
    "\n",
    "def save_predictions_excel(run_dir: Path, preds, trues, horizons, stations, max_stations=300):\n",
    "    N_total = preds.shape[-1]\n",
    "    N_use = min(max_stations, N_total)\n",
    "    st_sel = stations[:N_use]\n",
    "\n",
    "    out_xlsx = run_dir / \"test_pred_true_selected_horizons.xlsx\"\n",
    "    with pd.ExcelWriter(out_xlsx, engine=\"openpyxl\") as writer:\n",
    "        for hi, h in enumerate(horizons):\n",
    "            df = pd.DataFrame({\n",
    "                \"station\": np.repeat(st_sel, preds.shape[0]),\n",
    "                \"sample\":  np.tile(np.arange(preds.shape[0]), N_use),\n",
    "                \"true\":    trues[:, hi, :N_use].T.reshape(-1),\n",
    "                \"pred\":    preds[:, hi, :N_use].T.reshape(-1),\n",
    "            })\n",
    "            df.to_excel(writer, sheet_name=f\"h{h}\", index=False)\n",
    "    return out_xlsx\n",
    "\n",
    "def train_and_save_best(\n",
    "    model, model_name: str, run_dir: Path,\n",
    "    epochs=40, lr=1e-3, weight_decay=1e-4, clip=5.0,\n",
    "    patience=6, eval_every=2\n",
    "):\n",
    "    model = model.to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    best_score = float(\"inf\")\n",
    "    best_state = None\n",
    "    bad = 0\n",
    "\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        run_loss = 0.0\n",
    "\n",
    "        for xb, yb, tfb in tqdm(train_loader, desc=f\"Train {epoch}/{epochs}\", leave=False):\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            tfb = tfb.to(DEVICE)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            pred = model(xb, tfb)               # scaled\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "\n",
    "            run_loss += float(loss.item())\n",
    "\n",
    "        row = {\"epoch\": epoch, \"train_loss\": run_loss / max(1, len(train_loader))}\n",
    "        history.append(row)\n",
    "\n",
    "        # Evaluate every eval_every epochs\n",
    "        if epoch % eval_every == 0:\n",
    "            val_m = eval_horizons_fast(model, val_loader)\n",
    "            score = avg_mae(val_m)\n",
    "\n",
    "            print(f\"\\nEpoch {epoch}: train_loss={row['train_loss']:.6f} val_avg_MAE={score:.3f}\")\n",
    "            print_metrics(\"VAL\", val_m)\n",
    "\n",
    "            row.update({f\"val_MAE_{h}h\": val_m[h][\"MAE\"] for h in EVAL_HORIZONS})\n",
    "            row.update({f\"val_RMSE_{h}h\": val_m[h][\"RMSE\"] for h in EVAL_HORIZONS})\n",
    "            row[\"val_avg_MAE\"] = score\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                bad = 0\n",
    "                torch.save(best_state, run_dir / \"best.pt\")\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= patience:\n",
    "                    print(f\"\\nEarly stopping. Best val_avg_MAE={best_score:.3f}\")\n",
    "                    break\n",
    "\n",
    "    # Save history\n",
    "    hist_df = pd.DataFrame(history)\n",
    "    hist_df.to_csv(run_dir / \"history.csv\", index=False)\n",
    "    print(\"Saved history:\", run_dir / \"history.csv\")\n",
    "\n",
    "    # Load best\n",
    "    assert best_state is not None, \"best_state is None (evaluation never ran?)\"\n",
    "    model.load_state_dict(best_state)\n",
    "    return model, hist_df\n",
    "\n",
    "def run_experiment_and_save(\n",
    "    model_name: str,\n",
    "    model: nn.Module,\n",
    "    epochs=40, patience=6, eval_every=2,\n",
    "    horizons_to_save=(12,24,48,72),\n",
    "    max_stations_excel=300\n",
    "):\n",
    "    run_dir = make_run_dir(model_name)\n",
    "    print(\"Run dir:\", run_dir)\n",
    "\n",
    "    # Train\n",
    "    model, history_df = train_and_save_best(\n",
    "        model=model,\n",
    "        model_name=model_name,\n",
    "        run_dir=run_dir,\n",
    "        epochs=epochs,\n",
    "        patience=patience,\n",
    "        eval_every=eval_every,\n",
    "    )\n",
    "\n",
    "    # Test metrics\n",
    "    print(\"\\nEvaluating on TEST set...\")\n",
    "    test_m = eval_horizons_fast(model, test_loader)\n",
    "    print_metrics(f\"{model_name} — TEST\", test_m)\n",
    "\n",
    "    # Save test metrics\n",
    "    save_json(run_dir / \"test_metrics.json\", test_m)\n",
    "    pd.DataFrame([metrics_to_flat_row(model_name, \"test\", test_m)]).to_csv(run_dir / \"test_metrics.csv\", index=False)\n",
    "\n",
    "    # Collect & save predictions\n",
    "    preds, trues, horizons = collect_predictions_selected_horizons(model, test_loader, horizons=horizons_to_save)\n",
    "    np.savez_compressed(run_dir / \"test_pred_true_selected_horizons.npz\",\n",
    "                        preds=preds, trues=trues, horizons=np.array(horizons))\n",
    "    out_xlsx = save_predictions_excel(run_dir, preds, trues, horizons, stations, max_stations=max_stations_excel)\n",
    "\n",
    "    # Update master summary CSV\n",
    "    summary_row = metrics_to_flat_row(model_name, \"test\", test_m)\n",
    "    out_summary = append_results_summary(summary_row)\n",
    "\n",
    "    print(\"\\nSaved run outputs to:\", run_dir)\n",
    "    print(\" - best checkpoint:\", run_dir / \"best.pt\")\n",
    "    print(\" - history:\", run_dir / \"history.csv\")\n",
    "    print(\" - test metrics:\", run_dir / \"test_metrics.json\")\n",
    "    print(\" - predictions (npz):\", run_dir / \"test_pred_true_selected_horizons.npz\")\n",
    "    print(\" - predictions (xlsx):\", out_xlsx)\n",
    "    print(\" - master summary:\", out_summary)\n",
    "\n",
    "    return run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28abba99-1355-4d64-89c3-afb50914dd9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch check: torch.Size([8, 6, 1821, 24]) torch.Size([8, 72, 1821]) torch.Size([8, 72, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE_ABL = 8  \n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE_ABL, shuffle=True, num_workers=0, pin_memory=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE_ABL, shuffle=False, num_workers=0, pin_memory=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE_ABL, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "print(\"Batch check:\", xb.shape, yb.shape, tfb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3639546b-232c-46ae-a0ce-8fff3fff4857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# Assumes you already have:\n",
    "# N, Fdim, OUT_LEN, L_sp, DEVICE\n",
    "# and STGCN_MultiHorizon class defined\n",
    "# ----------------------------\n",
    "\n",
    "def build_stgcn_backbone():\n",
    "    # EXACT same hyperparams as your STGCN baseline\n",
    "    return STGCN_MultiHorizon(\n",
    "        num_nodes=N,\n",
    "        in_dim=Fdim,\n",
    "        out_len=OUT_LEN,\n",
    "        L_sp=L_sp,\n",
    "        kt=3,\n",
    "        Ks=3,\n",
    "        dropout=0.1,\n",
    "        c_t=64, c_s=16, c_out=64,\n",
    "        blocks=2\n",
    "    )\n",
    "\n",
    "class HorizonRNNRefinement(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes baseline multi-horizon predictions y0: (B, T, N),\n",
    "    runs an RNN across horizon dimension T for each node independently,\n",
    "    and outputs y = y0 + delta (residual refinement).\n",
    "    \"\"\"\n",
    "    def __init__(self, out_len, mode=\"gru\", hidden=32, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.out_len = out_len\n",
    "        self.mode = mode\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        if mode == \"gru\":\n",
    "            self.rnn = nn.GRU(input_size=1, hidden_size=hidden, num_layers=1, batch_first=True)\n",
    "            self.proj = nn.Linear(hidden, 1)\n",
    "\n",
    "        elif mode == \"lstm\":\n",
    "            self.rnn = nn.LSTM(input_size=1, hidden_size=hidden, num_layers=1, batch_first=True)\n",
    "            self.proj = nn.Linear(hidden, 1)\n",
    "\n",
    "        elif mode == \"gru_lstm\":\n",
    "            self.gru  = nn.GRU(input_size=1, hidden_size=hidden, num_layers=1, batch_first=True)\n",
    "            self.lstm = nn.LSTM(input_size=hidden, hidden_size=hidden, num_layers=1, batch_first=True)\n",
    "            self.proj = nn.Linear(hidden, 1)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown mode={mode}\")\n",
    "\n",
    "    def forward(self, y0):\n",
    "        # y0: (B, T, N)\n",
    "        B, T, Nn = y0.shape\n",
    "        assert T == self.out_len\n",
    "\n",
    "        # reshape into (B*N, T, 1)\n",
    "        seq = y0.permute(0, 2, 1).contiguous().view(B * Nn, T, 1)\n",
    "\n",
    "        if self.mode in (\"gru\", \"lstm\"):\n",
    "            out, _ = self.rnn(seq)\n",
    "            out = self.drop(out)\n",
    "        else:\n",
    "            out, _ = self.gru(seq)\n",
    "            out = self.drop(out)\n",
    "            out, _ = self.lstm(out)\n",
    "            out = self.drop(out)\n",
    "\n",
    "        delta = self.proj(out)  # (B*N, T, 1)\n",
    "        delta = delta.view(B, Nn, T).permute(0, 2, 1).contiguous()  # (B, T, N)\n",
    "\n",
    "        return y0 + delta\n",
    "\n",
    "class STGCN_WithHorizonRNN(nn.Module):\n",
    "    def __init__(self, backbone, rnn_mode=\"gru\", rnn_hidden=32, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.head = HorizonRNNRefinement(\n",
    "            out_len=OUT_LEN,\n",
    "            mode=rnn_mode,\n",
    "            hidden=rnn_hidden,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, x, tf):\n",
    "        y0 = self.backbone(x, tf)      # (B, OUT_LEN, N)\n",
    "        y  = self.head(y0)             # refined (B, OUT_LEN, N)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74e1a568-85ba-4b7a-ac8b-5ae79540c027",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU out: torch.Size([8, 72, 1821]) 0.02864772081375122 0.5788347721099854\n",
      "LSTM out: torch.Size([8, 72, 1821]) 0.12592457234859467 0.6218409538269043\n",
      "GRU+LSTM out: torch.Size([8, 72, 1821]) 0.08967868238687515 0.5888320207595825\n"
     ]
    }
   ],
   "source": [
    "RNN_H = 64   \n",
    "\n",
    "# STGCN + GRU\n",
    "stgcn_gru = STGCN_WithHorizonRNN(\n",
    "    backbone=build_stgcn_backbone(),\n",
    "    rnn_mode=\"gru\",\n",
    "    rnn_hidden=RNN_H,\n",
    "    dropout=0.1\n",
    ").to(DEVICE)\n",
    "\n",
    "# STGCN + LSTM\n",
    "stgcn_lstm = STGCN_WithHorizonRNN(\n",
    "    backbone=build_stgcn_backbone(),\n",
    "    rnn_mode=\"lstm\",\n",
    "    rnn_hidden=RNN_H,\n",
    "    dropout=0.1\n",
    ").to(DEVICE)\n",
    "\n",
    "# STGCN + GRU + LSTM\n",
    "stgcn_gru_lstm = STGCN_WithHorizonRNN(\n",
    "    backbone=build_stgcn_backbone(),\n",
    "    rnn_mode=\"gru_lstm\",\n",
    "    rnn_hidden=RNN_H,\n",
    "    dropout=0.1\n",
    ").to(DEVICE)\n",
    "\n",
    "# Sanity forward on one batch\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "with torch.no_grad():\n",
    "    o1 = stgcn_gru(xb.to(DEVICE), tfb.to(DEVICE))\n",
    "    o2 = stgcn_lstm(xb.to(DEVICE), tfb.to(DEVICE))\n",
    "    o3 = stgcn_gru_lstm(xb.to(DEVICE), tfb.to(DEVICE))\n",
    "\n",
    "print(\"GRU out:\", o1.shape, float(o1.mean()), float(o1.std()))\n",
    "print(\"LSTM out:\", o2.shape, float(o2.mean()), float(o2.std()))\n",
    "print(\"GRU+LSTM out:\", o3.shape, float(o3.mean()), float(o3.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "441d6911-3ffa-4e4c-a1c7-5638cfe1679a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run dir: artifacts/runs/20260210_164556_STGCN_GRU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 2/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.233457 val_avg_MAE=162.355\n",
      "\n",
      "VAL\n",
      "   12h  MAE=132.679  RMSE=274.616\n",
      "   24h  MAE=145.910  RMSE=296.275\n",
      "   48h  MAE=169.809  RMSE=326.279\n",
      "   72h  MAE=201.022  RMSE=372.767\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 3/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 4/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=0.192937 val_avg_MAE=156.977\n",
      "\n",
      "VAL\n",
      "   12h  MAE=130.212  RMSE=264.033\n",
      "   24h  MAE=141.334  RMSE=288.662\n",
      "   48h  MAE=169.113  RMSE=331.880\n",
      "   72h  MAE=187.249  RMSE=358.667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 5/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 6/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: train_loss=0.181725 val_avg_MAE=145.410\n",
      "\n",
      "VAL\n",
      "   12h  MAE=123.258  RMSE=256.287\n",
      "   24h  MAE=130.922  RMSE=273.983\n",
      "   48h  MAE=161.902  RMSE=320.846\n",
      "   72h  MAE=165.558  RMSE=327.910\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 7/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 8/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: train_loss=0.176242 val_avg_MAE=155.415\n",
      "\n",
      "VAL\n",
      "   12h  MAE=122.523  RMSE=253.124\n",
      "   24h  MAE=145.893  RMSE=298.684\n",
      "   48h  MAE=168.463  RMSE=332.305\n",
      "   72h  MAE=184.782  RMSE=365.916\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 9/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 10/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: train_loss=0.172649 val_avg_MAE=147.570\n",
      "\n",
      "VAL\n",
      "   12h  MAE=121.350  RMSE=254.394\n",
      "   24h  MAE=135.674  RMSE=283.390\n",
      "   48h  MAE=156.397  RMSE=313.861\n",
      "   72h  MAE=176.857  RMSE=349.310\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 11/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 12/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: train_loss=0.170450 val_avg_MAE=142.513\n",
      "\n",
      "VAL\n",
      "   12h  MAE=118.083  RMSE=246.980\n",
      "   24h  MAE=125.901  RMSE=267.427\n",
      "   48h  MAE=155.710  RMSE=312.449\n",
      "   72h  MAE=170.357  RMSE=336.486\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 13/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 14/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: train_loss=0.167303 val_avg_MAE=138.592\n",
      "\n",
      "VAL\n",
      "   12h  MAE=115.010  RMSE=243.345\n",
      "   24h  MAE=126.481  RMSE=268.437\n",
      "   48h  MAE=151.305  RMSE=303.086\n",
      "   72h  MAE=161.573  RMSE=319.423\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 15/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 16/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: train_loss=0.165809 val_avg_MAE=140.440\n",
      "\n",
      "VAL\n",
      "   12h  MAE=112.584  RMSE=240.759\n",
      "   24h  MAE=130.733  RMSE=273.106\n",
      "   48h  MAE=155.904  RMSE=313.882\n",
      "   72h  MAE=162.540  RMSE=324.726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 17/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 18/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: train_loss=0.164238 val_avg_MAE=142.036\n",
      "\n",
      "VAL\n",
      "   12h  MAE=110.058  RMSE=237.700\n",
      "   24h  MAE=126.057  RMSE=268.692\n",
      "   48h  MAE=159.678  RMSE=318.739\n",
      "   72h  MAE=172.350  RMSE=338.892\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 19/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 20/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: train_loss=0.162566 val_avg_MAE=146.869\n",
      "\n",
      "VAL\n",
      "   12h  MAE=119.753  RMSE=246.967\n",
      "   24h  MAE=134.456  RMSE=273.656\n",
      "   48h  MAE=155.852  RMSE=311.114\n",
      "   72h  MAE=177.416  RMSE=350.614\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 21/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 22/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: train_loss=0.161222 val_avg_MAE=145.426\n",
      "\n",
      "VAL\n",
      "   12h  MAE=120.119  RMSE=247.471\n",
      "   24h  MAE=132.355  RMSE=277.711\n",
      "   48h  MAE=158.508  RMSE=322.369\n",
      "   72h  MAE=170.721  RMSE=341.792\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 23/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 24/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: train_loss=0.160558 val_avg_MAE=137.293\n",
      "\n",
      "VAL\n",
      "   12h  MAE=107.795  RMSE=231.601\n",
      "   24h  MAE=129.091  RMSE=269.415\n",
      "   48h  MAE=151.080  RMSE=302.184\n",
      "   72h  MAE=161.208  RMSE=323.545\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 25/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814978167b8b463b90d507432d459a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 26/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d94836c65b14564b45f4817fd7d632f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: train_loss=0.160306 val_avg_MAE=138.522\n",
      "\n",
      "VAL\n",
      "   12h  MAE=111.397  RMSE=240.659\n",
      "   24h  MAE=121.117  RMSE=255.377\n",
      "   48h  MAE=152.851  RMSE=307.654\n",
      "   72h  MAE=168.723  RMSE=335.303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23987a923d9485fa479d5852750fd95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 27/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5227a024a294740b711667369a69c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 28/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f77c86e0b34c7ca79753001fcd493f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: train_loss=0.160269 val_avg_MAE=140.849\n",
      "\n",
      "VAL\n",
      "   12h  MAE=114.607  RMSE=246.903\n",
      "   24h  MAE=127.767  RMSE=273.332\n",
      "   48h  MAE=154.790  RMSE=310.309\n",
      "   72h  MAE=166.232  RMSE=331.476\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67016269343b4e4591f4dc3b66ff1247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 29/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cfdd92d07849e5bdbf0eceef4441b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 30/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86fe1b37d39477d823056c51d0851bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: train_loss=0.158811 val_avg_MAE=144.401\n",
      "\n",
      "VAL\n",
      "   12h  MAE=122.488  RMSE=250.167\n",
      "   24h  MAE=130.235  RMSE=269.371\n",
      "   48h  MAE=156.271  RMSE=311.808\n",
      "   72h  MAE=168.610  RMSE=336.249\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abbcb1dc4a2411f85728a3c953ce2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 31/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7f042978d14aadabcf9854605223cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 32/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5903e09887c4f69a2911ee54469c9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: train_loss=0.159083 val_avg_MAE=137.183\n",
      "\n",
      "VAL\n",
      "   12h  MAE=111.426  RMSE=235.852\n",
      "   24h  MAE=124.315  RMSE=261.876\n",
      "   48h  MAE=147.983  RMSE=297.230\n",
      "   72h  MAE=165.007  RMSE=325.756\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfff079380f49cd86f877596ed36d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 33/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c3ee32b27942b3a1a2c93425d95457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 34/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62954e37a624bad99e221cd245f2307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: train_loss=0.157646 val_avg_MAE=141.288\n",
      "\n",
      "VAL\n",
      "   12h  MAE=111.152  RMSE=233.853\n",
      "   24h  MAE=125.634  RMSE=265.269\n",
      "   48h  MAE=156.955  RMSE=310.384\n",
      "   72h  MAE=171.409  RMSE=340.021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab44bc04bc04253a1d9fe826d0b5823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 35/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685ab79916ac49a7ac144a7d57b7464a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 36/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf168c05b3fc4fb5afa01d82f719ddfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: train_loss=0.157855 val_avg_MAE=141.869\n",
      "\n",
      "VAL\n",
      "   12h  MAE=107.503  RMSE=232.932\n",
      "   24h  MAE=133.673  RMSE=278.477\n",
      "   48h  MAE=154.939  RMSE=311.314\n",
      "   72h  MAE=171.361  RMSE=344.863\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf4e34f122b48efaede1463de2735c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 37/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678fbf34b56a4031a41b37440a1450e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 38/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ff229dca2c4dcd99f570e606e2ed2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: train_loss=0.158190 val_avg_MAE=140.429\n",
      "\n",
      "VAL\n",
      "   12h  MAE=114.866  RMSE=242.470\n",
      "   24h  MAE=127.761  RMSE=268.938\n",
      "   48h  MAE=153.205  RMSE=312.580\n",
      "   72h  MAE=165.883  RMSE=333.867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd43861a04941a58facae61e57ff055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 39/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbce3cf0594b4e0ba064d21175756ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 40/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f729fb3dff84ee8a57562043902ce91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40: train_loss=0.157008 val_avg_MAE=140.610\n",
      "\n",
      "VAL\n",
      "   12h  MAE=114.599  RMSE=244.400\n",
      "   24h  MAE=127.006  RMSE=267.813\n",
      "   48h  MAE=152.633  RMSE=307.594\n",
      "   72h  MAE=168.202  RMSE=335.233\n",
      "Saved history: artifacts/runs/20260210_164556_STGCN_GRU/history.csv\n",
      "\n",
      "Evaluating on TEST set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9297200a48664fdfb84c2c8235343df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STGCN_GRU — TEST\n",
      "   12h  MAE=114.689  RMSE=237.374\n",
      "   24h  MAE=121.745  RMSE=246.048\n",
      "   48h  MAE=139.941  RMSE=288.741\n",
      "   72h  MAE=154.067  RMSE=311.239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1dcaf881d84eacab68d576dbf74528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collect preds:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved run outputs to: artifacts/runs/20260210_164556_STGCN_GRU\n",
      " - best checkpoint: artifacts/runs/20260210_164556_STGCN_GRU/best.pt\n",
      " - history: artifacts/runs/20260210_164556_STGCN_GRU/history.csv\n",
      " - test metrics: artifacts/runs/20260210_164556_STGCN_GRU/test_metrics.json\n",
      " - predictions (npz): artifacts/runs/20260210_164556_STGCN_GRU/test_pred_true_selected_horizons.npz\n",
      " - predictions (xlsx): artifacts/runs/20260210_164556_STGCN_GRU/test_pred_true_selected_horizons.xlsx\n",
      " - master summary: artifacts/results_summary.csv\n",
      "Run dir: artifacts/runs/20260210_172238_STGCN_LSTM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e3af9ed1964794ac150ba3d797eccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea0e1899568486f8c072a2783234731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 2/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a098309c5b4e2f89334dbe017be37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.235437 val_avg_MAE=168.148\n",
      "\n",
      "VAL\n",
      "   12h  MAE=136.817  RMSE=282.580\n",
      "   24h  MAE=156.017  RMSE=312.699\n",
      "   48h  MAE=186.110  RMSE=347.872\n",
      "   72h  MAE=193.649  RMSE=366.188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 3/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 4/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=0.191356 val_avg_MAE=157.006\n",
      "\n",
      "VAL\n",
      "   12h  MAE=133.078  RMSE=262.476\n",
      "   24h  MAE=140.939  RMSE=283.698\n",
      "   48h  MAE=170.372  RMSE=325.841\n",
      "   72h  MAE=183.635  RMSE=351.639\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 5/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa6697ac99444aa94dde964d8e28cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 6/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: train_loss=0.160918 val_avg_MAE=140.096\n",
      "\n",
      "VAL\n",
      "   12h  MAE=117.900  RMSE=248.929\n",
      "   24h  MAE=123.442  RMSE=260.428\n",
      "   48h  MAE=152.487  RMSE=306.179\n",
      "   72h  MAE=166.555  RMSE=330.844\n",
      "\n",
      "Early stopping. Best val_avg_MAE=139.155\n",
      "Saved history: artifacts/runs/20260210_174759_STGCN_GRU_LSTM/history.csv\n",
      "\n",
      "Evaluating on TEST set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STGCN_GRU_LSTM — TEST\n",
      "   12h  MAE=118.894  RMSE=240.794\n",
      "   24h  MAE=123.720  RMSE=250.828\n",
      "   48h  MAE=142.579  RMSE=289.527\n",
      "   72h  MAE=155.208  RMSE=309.939\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collect preds:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved run outputs to: artifacts/runs/20260210_174759_STGCN_GRU_LSTM\n",
      " - best checkpoint: artifacts/runs/20260210_174759_STGCN_GRU_LSTM/best.pt\n",
      " - history: artifacts/runs/20260210_174759_STGCN_GRU_LSTM/history.csv\n",
      " - test metrics: artifacts/runs/20260210_174759_STGCN_GRU_LSTM/test_metrics.json\n",
      " - predictions (npz): artifacts/runs/20260210_174759_STGCN_GRU_LSTM/test_pred_true_selected_horizons.npz\n",
      " - predictions (xlsx): artifacts/runs/20260210_174759_STGCN_GRU_LSTM/test_pred_true_selected_horizons.xlsx\n",
      " - master summary: artifacts/results_summary.csv\n",
      "Done.\n",
      "GRU run dir: artifacts/runs/20260210_164556_STGCN_GRU\n",
      "LSTM run dir: artifacts/runs/20260210_172238_STGCN_LSTM\n",
      "GRU_LSTM run dir: artifacts/runs/20260210_174759_STGCN_GRU_LSTM\n"
     ]
    }
   ],
   "source": [
    "#  make station subset selection reproducible \n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "run_dir_gru = run_experiment_and_save(\n",
    "    model_name=\"STGCN_GRU\",\n",
    "    model=stgcn_gru,\n",
    "    epochs=40,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    "    horizons_to_save=(12,24,48,72),\n",
    "    max_stations_excel=300\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "run_dir_lstm = run_experiment_and_save(\n",
    "    model_name=\"STGCN_LSTM\",\n",
    "    model=stgcn_lstm,\n",
    "    epochs=40,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    "    horizons_to_save=(12,24,48,72),\n",
    "    max_stations_excel=300\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "run_dir_gru_lstm = run_experiment_and_save(\n",
    "    model_name=\"STGCN_GRU_LSTM\",\n",
    "    model=stgcn_gru_lstm,\n",
    "    epochs=40,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    "    horizons_to_save=(12,24,48,72),\n",
    "    max_stations_excel=300\n",
    ")\n",
    "\n",
    "print(\"Done.\")\n",
    "print(\"GRU run dir:\", run_dir_gru)\n",
    "print(\"LSTM run dir:\", run_dir_lstm)\n",
    "print(\"GRU_LSTM run dir:\", run_dir_gru_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61054206-ca75-487a-83ad-4bab23a07d03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported CSVs to: artifacts/runs/20260210_164556_STGCN_GRU\n",
      "Exported CSVs to: artifacts/runs/20260210_172238_STGCN_LSTM\n",
      "Exported CSVs to: artifacts/runs/20260210_174759_STGCN_GRU_LSTM\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def xlsx_to_csvs(run_dir):\n",
    "    run_dir = Path(run_dir)\n",
    "    xlsx_path = run_dir / \"test_pred_true_selected_horizons.xlsx\"\n",
    "    if not xlsx_path.exists():\n",
    "        print(\"No xlsx found:\", xlsx_path)\n",
    "        return\n",
    "\n",
    "    xls = pd.ExcelFile(xlsx_path)\n",
    "    for sheet in xls.sheet_names:\n",
    "        df = pd.read_excel(xlsx_path, sheet_name=sheet)\n",
    "        out = run_dir / f\"{sheet}.csv\"\n",
    "        df.to_csv(out, index=False)\n",
    "    print(\"Exported CSVs to:\", run_dir)\n",
    "\n",
    "\n",
    "xlsx_to_csvs(run_dir_gru)\n",
    "xlsx_to_csvs(run_dir_lstm)\n",
    "xlsx_to_csvs(run_dir_gru_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d31ec-fdea-4e77-836d-19ee0c415bea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>avg_MAE</th>\n",
       "      <th>test_MAE_12h</th>\n",
       "      <th>test_MAE_24h</th>\n",
       "      <th>test_MAE_48h</th>\n",
       "      <th>test_MAE_72h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GraphWaveNet_GRU_LSTM</td>\n",
       "      <td>130.347263</td>\n",
       "      <td>119.049412</td>\n",
       "      <td>125.123518</td>\n",
       "      <td>135.325328</td>\n",
       "      <td>141.890796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GraphWaveNet_LSTM</td>\n",
       "      <td>131.859503</td>\n",
       "      <td>123.367641</td>\n",
       "      <td>125.953695</td>\n",
       "      <td>135.830582</td>\n",
       "      <td>142.286094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>STGCN</td>\n",
       "      <td>132.266313</td>\n",
       "      <td>119.125651</td>\n",
       "      <td>121.787452</td>\n",
       "      <td>139.610473</td>\n",
       "      <td>148.541676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>STGCN_GRU</td>\n",
       "      <td>132.610577</td>\n",
       "      <td>114.689314</td>\n",
       "      <td>121.745046</td>\n",
       "      <td>139.941089</td>\n",
       "      <td>154.066858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>STGCN</td>\n",
       "      <td>132.881293</td>\n",
       "      <td>124.865714</td>\n",
       "      <td>121.199576</td>\n",
       "      <td>136.894008</td>\n",
       "      <td>148.565873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>STGCN</td>\n",
       "      <td>132.881293</td>\n",
       "      <td>124.865714</td>\n",
       "      <td>121.199576</td>\n",
       "      <td>136.894008</td>\n",
       "      <td>148.565873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GraphWaveNet_GRU</td>\n",
       "      <td>133.121911</td>\n",
       "      <td>122.688777</td>\n",
       "      <td>127.520536</td>\n",
       "      <td>138.531665</td>\n",
       "      <td>143.746668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>STGCN_LSTM</td>\n",
       "      <td>133.812095</td>\n",
       "      <td>119.279658</td>\n",
       "      <td>124.610721</td>\n",
       "      <td>139.245704</td>\n",
       "      <td>152.112297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>STGCN_GRU_LSTM</td>\n",
       "      <td>135.100299</td>\n",
       "      <td>118.894072</td>\n",
       "      <td>123.719928</td>\n",
       "      <td>142.578867</td>\n",
       "      <td>155.208328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STGCN</td>\n",
       "      <td>4925.363840</td>\n",
       "      <td>4932.437692</td>\n",
       "      <td>4919.577328</td>\n",
       "      <td>4923.404710</td>\n",
       "      <td>4926.035632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STGCN</td>\n",
       "      <td>8772.041396</td>\n",
       "      <td>8775.111610</td>\n",
       "      <td>8771.100333</td>\n",
       "      <td>8771.417389</td>\n",
       "      <td>8770.536252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_name      avg_MAE  test_MAE_12h  test_MAE_24h  \\\n",
       "2   GraphWaveNet_GRU_LSTM   130.347263    119.049412    125.123518   \n",
       "1       GraphWaveNet_LSTM   131.859503    123.367641    125.953695   \n",
       "5                   STGCN   132.266313    119.125651    121.787452   \n",
       "8               STGCN_GRU   132.610577    114.689314    121.745046   \n",
       "6                   STGCN   132.881293    124.865714    121.199576   \n",
       "7                   STGCN   132.881293    124.865714    121.199576   \n",
       "0        GraphWaveNet_GRU   133.121911    122.688777    127.520536   \n",
       "9              STGCN_LSTM   133.812095    119.279658    124.610721   \n",
       "10         STGCN_GRU_LSTM   135.100299    118.894072    123.719928   \n",
       "4                   STGCN  4925.363840   4932.437692   4919.577328   \n",
       "3                   STGCN  8772.041396   8775.111610   8771.100333   \n",
       "\n",
       "    test_MAE_48h  test_MAE_72h  \n",
       "2     135.325328    141.890796  \n",
       "1     135.830582    142.286094  \n",
       "5     139.610473    148.541676  \n",
       "8     139.941089    154.066858  \n",
       "6     136.894008    148.565873  \n",
       "7     136.894008    148.565873  \n",
       "0     138.531665    143.746668  \n",
       "9     139.245704    152.112297  \n",
       "10    142.578867    155.208328  \n",
       "4    4923.404710   4926.035632  \n",
       "3    8771.417389   8770.536252  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"artifacts/results_summary.csv\")\n",
    "\n",
    "horizons = [12, 24, 48, 72]\n",
    "for h in horizons:\n",
    "    df[f\"test_MAE_{h}h\"] = pd.to_numeric(df[f\"test_MAE_{h}h\"], errors=\"coerce\")\n",
    "\n",
    "df[\"avg_MAE\"] = df[[f\"test_MAE_{h}h\" for h in horizons]].mean(axis=1)\n",
    "\n",
    "cols = [\"model_name\", \"avg_MAE\"] + [f\"test_MAE_{h}h\" for h in horizons]\n",
    "display(df.sort_values(\"avg_MAE\")[cols].head(25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2f96f8-896a-49f2-bfcc-c6a3e845d606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
