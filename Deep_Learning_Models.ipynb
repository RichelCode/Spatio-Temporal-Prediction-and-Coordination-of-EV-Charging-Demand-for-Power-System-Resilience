{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9795e03-a5db-4abb-947f-65a818b13483",
   "metadata": {},
   "source": [
    "# Multi-Horizon Traffic Forecasting on PeMS (Graph Models)\n",
    "\n",
    "## Goal (Paper Claim)\n",
    "Build a leakage-safe, reproducible pipeline on PeMS traffic data and evaluate multi-horizon forecasting models fairly.\n",
    "\n",
    "Primary goal:\n",
    "- Demonstrate the proposed **GraphWaveNet-GRU-LSTM** performs best on PeMS under the same train/val/test protocol.\n",
    "\n",
    "Key principles:\n",
    "- No time leakage (all statistics computed from train only).\n",
    "- One shared dataset representation for all deep models: **X ∈ R^{T×N×F}, Y ∈ R^{T×N}**.\n",
    "- One fixed evaluation harness (same horizons, same metrics, same seeds).\n",
    "- Strong baselines + ablations:\n",
    "  - HA / Persistence\n",
    "  - GRU / LSTM (non-graph)\n",
    "  - GraphWaveNet\n",
    "  - GraphWaveNet+GRU\n",
    "  - GraphWaveNet+LSTM\n",
    "  - **GraphWaveNet+GRU+LSTM (proposed)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dceeef19-2130-4a23-931a-06196ed31757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T19:36:12.615948Z",
     "iopub.status.busy": "2026-02-07T19:36:12.615649Z",
     "iopub.status.idle": "2026-02-07T19:36:20.583394Z",
     "shell.execute_reply": "2026-02-07T19:36:20.582642Z",
     "shell.execute_reply.started": "2026-02-07T19:36:12.615922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb15451a-d0ef-44ab-a5ae-c33eebe63c39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T19:36:29.430693Z",
     "iopub.status.busy": "2026-02-07T19:36:29.430355Z",
     "iopub.status.idle": "2026-02-07T19:36:33.161009Z",
     "shell.execute_reply": "2026-02-07T19:36:33.160283Z",
     "shell.execute_reply.started": "2026-02-07T19:36:29.430665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install numpy pandas openpyxl scikit-learn torch tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d3f8bf-2c00-4b4c-acfb-5ce948648cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T19:36:50.204022Z",
     "iopub.status.busy": "2026-02-07T19:36:50.203372Z",
     "iopub.status.idle": "2026-02-07T19:36:52.731520Z",
     "shell.execute_reply": "2026-02-07T19:36:52.730792Z",
     "shell.execute_reply.started": "2026-02-07T19:36:50.203991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.1.1+cu121\n",
      "Device: cuda\n",
      "GPU: Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def set_seed(seed: int = 42, deterministic: bool = True):\n",
    "    \"\"\"\n",
    "    Sets seeds for reproducibility.\n",
    "    deterministic=True makes results more reproducible but can reduce speed.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    else:\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED, deterministic=True)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Device:\", DEVICE)\n",
    "if DEVICE == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ddbd0-0ab3-4784-8fe2-930de04d11c3",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "We fix:\n",
    "- Input window length (`IN_LEN`) and forecast horizon length (`OUT_LEN`)\n",
    "- Train/val/test boundaries (time-based split)\n",
    "- Station inclusion rule (coverage threshold)\n",
    "- Output dataset artifact path (so every model uses the same processed dataset)\n",
    "\n",
    "Important:\n",
    "GraphWaveNet expects a consistent node set and continuous time axis,\n",
    "so we build a clean matrix format (timestamp × station).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "907ef442-d82f-4601-ba92-8f0b62467aa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T20:30:36.024501Z",
     "iopub.status.busy": "2026-02-07T20:30:36.023555Z",
     "iopub.status.idle": "2026-02-07T20:30:36.031533Z",
     "shell.execute_reply": "2026-02-07T20:30:36.030825Z",
     "shell.execute_reply.started": "2026-02-07T20:30:36.024473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will save processed dataset to: artifacts/pems_graph_dataset.npz\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Paths (your files are visible in the Paperspace file pane)\n",
    "# -------------------------\n",
    "TRAFFIC_CSV = Path(\"cleaned_traffic_data.csv\")\n",
    "META_XLSX   = Path(\"pems_output.xlsx\")\n",
    "\n",
    "assert TRAFFIC_CSV.exists(), f\"Missing {TRAFFIC_CSV}\"\n",
    "assert META_XLSX.exists(), f\"Missing {META_XLSX}\"\n",
    "\n",
    "# -------------------------\n",
    "# Split boundaries (same as your earlier work)\n",
    "# -------------------------\n",
    "TRAIN_END = pd.Timestamp(\"2024-11-15 23:59:59\")\n",
    "VAL_END   = pd.Timestamp(\"2024-11-30 23:59:59\")\n",
    "\n",
    "# -------------------------\n",
    "# Forecast setup\n",
    "# -------------------------\n",
    "IN_LEN  = 24     # hours of history used as input\n",
    "OUT_LEN = 72     # predict next 72 hours (we will evaluate at 12/24/48/72)\n",
    "\n",
    "EVAL_HORIZONS = [12, 24, 48, 72]  # hours ahead\n",
    "\n",
    "# -------------------------\n",
    "# Station coverage threshold\n",
    "# -------------------------\n",
    "# 1.0 means station must have ALL timestamps present.\n",
    "# 0.98 is often a good compromise if some stations are missing few points.\n",
    "COVERAGE_THRESHOLD = 0.98\n",
    "\n",
    "# -------------------------\n",
    "# Adjacency setup (static graph baseline)\n",
    "# -------------------------\n",
    "K_NEIGHBORS = 2   # connect up to 2 upstream + 2 downstream along the freeway chain\n",
    "\n",
    "# -------------------------\n",
    "# Output artifact (important for reproducibility)\n",
    "# -------------------------\n",
    "OUT_DIR = Path(\"artifacts\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "DATASET_NPZ = OUT_DIR / \"pems_graph_dataset.npz\"\n",
    "print(\"Will save processed dataset to:\", DATASET_NPZ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714660ee-bbf4-44ce-b128-8d23ca17d379",
   "metadata": {},
   "source": [
    "## Load raw traffic + metadata\n",
    "\n",
    "We:\n",
    "1) Load cleaned traffic data\n",
    "2) Load station metadata\n",
    "3) Standardize column names\n",
    "4) Merge metadata onto traffic records (inner join so every station has metadata)\n",
    "5) Verify timestamp parsing and basic integrity checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e82616-9813-4b63-9281-dd4766488c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T20:32:05.462983Z",
     "iopub.status.busy": "2026-02-07T20:32:05.462422Z",
     "iopub.status.idle": "2026-02-07T20:32:05.468279Z",
     "shell.execute_reply": "2026-02-07T20:32:05.467288Z",
     "shell.execute_reply.started": "2026-02-07T20:32:05.462959Z"
    }
   },
   "outputs": [],
   "source": [
    "def require_col(df: pd.DataFrame, candidates, friendly_name: str):\n",
    "    \"\"\"\n",
    "    Find the first matching column in candidates.\n",
    "    Raise a helpful error if not found.\n",
    "    \"\"\"\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise KeyError(\n",
    "        f\"Could not find column for '{friendly_name}'. Tried: {candidates}\\n\"\n",
    "        f\"Available columns: {list(df.columns)}\"\n",
    "    )\n",
    "\n",
    "def to_datetime_safe(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "def pct_missing(s: pd.Series) -> float:\n",
    "    return float(s.isna().mean() * 100.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "891ee42c-db17-4a5a-8760-c2d5307dcc93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T20:32:15.478248Z",
     "iopub.status.busy": "2026-02-07T20:32:15.477319Z",
     "iopub.status.idle": "2026-02-07T20:32:35.416432Z",
     "shell.execute_reply": "2026-02-07T20:32:35.415675Z",
     "shell.execute_reply.started": "2026-02-07T20:32:15.478222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic shape: (4114680, 42)\n",
      "Meta shape: (1861, 15)\n",
      "After basic parsing: (4114680, 42)\n",
      "Timestamp range: 2024-10-01 00:00:00 → 2024-12-31 23:00:00\n",
      "Meta columns (peek): ['Fwy', 'District', 'County', 'City', 'CA PM', 'Abs PM', 'Length', 'station', 'Name', 'Lanes', 'Type', 'Sensor Type', 'HOV', 'MS ID', 'IRM']\n",
      "Merged df shape: (4051621, 56)\n",
      "Unique stations: 1861\n"
     ]
    }
   ],
   "source": [
    "traffic_raw = pd.read_csv(TRAFFIC_CSV)\n",
    "meta_raw = pd.read_excel(META_XLSX)\n",
    "\n",
    "print(\"Traffic shape:\", traffic_raw.shape)\n",
    "print(\"Meta shape:\", meta_raw.shape)\n",
    "\n",
    "# --- Identify expected columns robustly ---\n",
    "ts_col   = require_col(traffic_raw, [\"Timestamp\", \"timestamp\", \"Time\", \"Datetime\"], \"Timestamp\")\n",
    "st_col   = require_col(traffic_raw, [\"Station\", \"station\", \"ID\"], \"Station ID\")\n",
    "flow_col = require_col(traffic_raw, [\"Total Flow\", \"total_flow\", \"Flow\", \"total flow\"], \"Total Flow\")\n",
    "spd_col  = require_col(traffic_raw, [\"Avg Speed\", \"avg_speed\", \"Speed\", \"Avg speed\"], \"Avg Speed\")\n",
    "\n",
    "lane_col = require_col(traffic_raw, [\"Lane Type\", \"lane_type\", \"LaneType\"], \"Lane Type\")\n",
    "dir_col  = require_col(traffic_raw, [\"Direction of Travel\", \"direction\", \"Dir\"], \"Direction\")\n",
    "dist_col = require_col(traffic_raw, [\"District\", \"district\"], \"District\")\n",
    "\n",
    "# --- Standardize traffic ---\n",
    "traffic = traffic_raw.rename(columns={\n",
    "    ts_col: \"timestamp\",\n",
    "    st_col: \"station\",\n",
    "    flow_col: \"total_flow\",\n",
    "    spd_col: \"avg_speed\",\n",
    "    lane_col: \"lane_type\",\n",
    "    dir_col: \"direction\",\n",
    "    dist_col: \"district\",\n",
    "}).copy()\n",
    "\n",
    "traffic[\"timestamp\"] = to_datetime_safe(traffic[\"timestamp\"])\n",
    "traffic[\"station\"] = pd.to_numeric(traffic[\"station\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "traffic = traffic.dropna(subset=[\"timestamp\", \"station\"]).copy()\n",
    "traffic[\"station\"] = traffic[\"station\"].astype(int)\n",
    "\n",
    "print(\"After basic parsing:\", traffic.shape)\n",
    "print(\"Timestamp range:\", traffic[\"timestamp\"].min(), \"→\", traffic[\"timestamp\"].max())\n",
    "\n",
    "# --- Standardize metadata ---\n",
    "# station id in metadata usually is 'ID'\n",
    "meta_id_col = require_col(meta_raw, [\"ID\", \"station\", \"Station\"], \"Meta Station ID\")\n",
    "meta = meta_raw.rename(columns={meta_id_col: \"station\"}).copy()\n",
    "meta[\"station\"] = pd.to_numeric(meta[\"station\"], errors=\"coerce\").astype(\"Int64\")\n",
    "meta = meta.dropna(subset=[\"station\"]).copy()\n",
    "meta[\"station\"] = meta[\"station\"].astype(int)\n",
    "\n",
    "print(\"Meta columns (peek):\", list(meta.columns)[:20])\n",
    "\n",
    "# Merge metadata (inner ensures we only keep stations that have metadata)\n",
    "df = traffic.merge(meta, on=\"station\", how=\"inner\", validate=\"m:1\")\n",
    "print(\"Merged df shape:\", df.shape)\n",
    "print(\"Unique stations:\", df[\"station\"].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f00d72-390f-4127-8fee-892c70b33868",
   "metadata": {},
   "source": [
    "## Sanity checks\n",
    "\n",
    "We check:\n",
    "- Duplicate rows per (timestamp, station)\n",
    "- Time frequency (hourly vs not)\n",
    "- Missingness rates\n",
    "These checks prevent silent data problems that can invalidate results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ccee1e2-e6e9-4140-835d-2d16cf1beabd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T20:33:17.465616Z",
     "iopub.status.busy": "2026-02-07T20:33:17.465333Z",
     "iopub.status.idle": "2026-02-07T20:33:17.896142Z",
     "shell.execute_reply": "2026-02-07T20:33:17.895372Z",
     "shell.execute_reply.started": "2026-02-07T20:33:17.465593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate (timestamp, station) rows: 0\n",
      "Most common timestamp deltas:\n",
      " 0 days 01:00:00    2207\n",
      "Name: count, dtype: int64\n",
      "Missing total_flow (%): 7.243150334150209\n",
      "Missing avg_speed (%): 37.88496011843161\n"
     ]
    }
   ],
   "source": [
    "# 1) Duplicates by (timestamp, station)\n",
    "dup_count = df.duplicated(subset=[\"timestamp\", \"station\"]).sum()\n",
    "print(\"Duplicate (timestamp, station) rows:\", int(dup_count))\n",
    "\n",
    "if dup_count > 0:\n",
    "    # Resolve duplicates safely: flow sums, speed averages\n",
    "    df = (df.groupby([\"timestamp\", \"station\"], as_index=False)\n",
    "            .agg({\n",
    "                \"total_flow\": \"sum\",\n",
    "                \"avg_speed\": \"mean\",\n",
    "                \"lane_type\": \"first\",\n",
    "                \"direction\": \"first\",\n",
    "                \"district\": \"first\",\n",
    "                # keep metadata columns by first\n",
    "                **{c: \"first\" for c in meta.columns if c != \"station\"}\n",
    "            }))\n",
    "    print(\"After de-duplication:\", df.shape)\n",
    "\n",
    "# 2) Check time deltas\n",
    "times = pd.DatetimeIndex(sorted(df[\"timestamp\"].unique()))\n",
    "deltas = pd.Series(times[1:] - times[:-1]).value_counts().head(5)\n",
    "print(\"Most common timestamp deltas:\\n\", deltas)\n",
    "\n",
    "# 3) Missingness\n",
    "print(\"Missing total_flow (%):\", pct_missing(df[\"total_flow\"]))\n",
    "print(\"Missing avg_speed (%):\", pct_missing(df[\"avg_speed\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78bf0b1-3cbf-4a41-85bc-b09e0ecd29d9",
   "metadata": {},
   "source": [
    "## Build station-time matrices\n",
    "\n",
    "Graph models require a clean tensor format.\n",
    "We create two matrices:\n",
    "- Flow:  (T timestamps × N stations)\n",
    "- Speed: (T timestamps × N stations)\n",
    "\n",
    "We also select a stable station set using a coverage threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c1913df-2f73-4406-99cc-2cc7019f4f19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T20:37:39.730439Z",
     "iopub.status.busy": "2026-02-07T20:37:39.730115Z",
     "iopub.status.idle": "2026-02-07T20:37:47.228785Z",
     "shell.execute_reply": "2026-02-07T20:37:47.228035Z",
     "shell.execute_reply.started": "2026-02-07T20:37:39.730415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamps (T) = 2208\n",
      "Stations kept (N) = 1821  (coverage threshold=0.98)\n",
      "Flow matrix: (2208, 1821) Speed matrix: (2208, 1821)\n",
      "Flow missing fraction: 0.0712893656137335\n",
      "Speed missing fraction: 0.3772684720928937\n"
     ]
    }
   ],
   "source": [
    "# Full timestamp index\n",
    "all_times = pd.DatetimeIndex(sorted(df[\"timestamp\"].unique()))\n",
    "T = len(all_times)\n",
    "\n",
    "# Station coverage\n",
    "counts = df.groupby(\"station\")[\"timestamp\"].nunique()\n",
    "coverage = counts / T\n",
    "\n",
    "keep_stations = coverage[coverage >= COVERAGE_THRESHOLD].index\n",
    "df2 = df[df[\"station\"].isin(keep_stations)].copy()\n",
    "\n",
    "stations = np.array(sorted(df2[\"station\"].unique()), dtype=int)\n",
    "N = len(stations)\n",
    "\n",
    "print(f\"Timestamps (T) = {T}\")\n",
    "print(f\"Stations kept (N) = {N}  (coverage threshold={COVERAGE_THRESHOLD})\")\n",
    "\n",
    "# Build matrices\n",
    "flow = (df2.pivot(index=\"timestamp\", columns=\"station\", values=\"total_flow\")\n",
    "          .reindex(index=all_times, columns=stations)\n",
    "          .sort_index())\n",
    "\n",
    "speed = (df2.pivot(index=\"timestamp\", columns=\"station\", values=\"avg_speed\")\n",
    "           .reindex(index=all_times, columns=stations)\n",
    "           .sort_index())\n",
    "\n",
    "print(\"Flow matrix:\", flow.shape, \"Speed matrix:\", speed.shape)\n",
    "print(\"Flow missing fraction:\", float(np.isnan(flow.to_numpy()).mean()))\n",
    "print(\"Speed missing fraction:\", float(np.isnan(speed.to_numpy()).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdefb51-4046-4fe5-8ae7-83654b1afbc3",
   "metadata": {},
   "source": [
    "## Leakage-safe imputation\n",
    "\n",
    "We must not use validation/test information when estimating fill values.\n",
    "\n",
    "Strategy:\n",
    "- Forward-fill across time (realistic streaming behavior).\n",
    "- Remaining NaNs filled using TRAIN statistics only.\n",
    "\n",
    "Flow:\n",
    "- ffill → fill with per-station TRAIN mean → fill with global TRAIN mean\n",
    "\n",
    "Speed:\n",
    "- ffill → fill using a TRAIN-only group lookup (lane_type, meta type, hour, fwy, district)\n",
    "- then per-station TRAIN mean → global TRAIN mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0cc46e-f59e-436a-9538-76628782eeb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T20:38:52.379831Z",
     "iopub.status.busy": "2026-02-07T20:38:52.379494Z",
     "iopub.status.idle": "2026-02-07T20:39:31.394012Z",
     "shell.execute_reply": "2026-02-07T20:39:31.392919Z",
     "shell.execute_reply.started": "2026-02-07T20:38:52.379793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After imputation:\n",
      "Flow missing fraction: 0.0\n",
      "Speed missing fraction: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Identify metadata columns we need for speed lookup\n",
    "meta_type_col = None\n",
    "for cand in [\"Type\", \"type\", \"Station Type\"]:\n",
    "    if cand in df2.columns:\n",
    "        meta_type_col = cand\n",
    "        break\n",
    "\n",
    "fwy_col = None\n",
    "for cand in [\"Fwy\", \"FWY\", \"fwy\", \"Freeway\"]:\n",
    "    if cand in df2.columns:\n",
    "        fwy_col = cand\n",
    "        break\n",
    "\n",
    "if meta_type_col is None or fwy_col is None:\n",
    "    raise KeyError(f\"Missing metadata columns for speed lookup. Found meta_type={meta_type_col}, fwy={fwy_col}\")\n",
    "\n",
    "train_time_mask = flow.index <= TRAIN_END\n",
    "\n",
    "# -------------------------\n",
    "# Flow imputation\n",
    "# -------------------------\n",
    "flow_ff = flow.ffill()\n",
    "\n",
    "flow_train_mean_station = flow_ff.loc[train_time_mask].mean(axis=0)\n",
    "flow_train_mean_global = flow_ff.loc[train_time_mask].stack().mean()\n",
    "\n",
    "flow_imp = flow_ff.fillna(flow_train_mean_station).fillna(flow_train_mean_global)\n",
    "\n",
    "# -------------------------\n",
    "# Speed lookup (TRAIN only)\n",
    "# -------------------------\n",
    "train_rows = df2[df2[\"timestamp\"] <= TRAIN_END].copy()\n",
    "train_rows[\"hour\"] = train_rows[\"timestamp\"].dt.hour\n",
    "\n",
    "speed_grp_cols = [\"lane_type\", meta_type_col, \"hour\", fwy_col, \"district\"]\n",
    "speed_lookup = train_rows.groupby(speed_grp_cols)[\"avg_speed\"].mean()\n",
    "\n",
    "global_speed_train_mean = train_rows[\"avg_speed\"].mean()\n",
    "\n",
    "# Station-level \"mode\" descriptors used when applying the lookup\n",
    "station_info = (df2.groupby(\"station\")\n",
    "                  .agg(\n",
    "                      lane_type=(\"lane_type\", lambda x: x.mode().iloc[0] if len(x.mode()) else x.iloc[0]),\n",
    "                      meta_type=(meta_type_col, lambda x: x.mode().iloc[0] if len(x.mode()) else x.iloc[0]),\n",
    "                      fwy=(fwy_col, lambda x: x.mode().iloc[0] if len(x.mode()) else x.iloc[0]),\n",
    "                      district=(\"district\", lambda x: x.mode().iloc[0] if len(x.mode()) else x.iloc[0]),\n",
    "                  )\n",
    "                  .reindex(stations))\n",
    "\n",
    "speed_ff = speed.ffill()\n",
    "speed_np = speed_ff.to_numpy(dtype=np.float32)\n",
    "miss = np.isnan(speed_np)\n",
    "hours = speed_ff.index.hour.values\n",
    "\n",
    "# Fill with lookup\n",
    "for j, st in enumerate(stations):\n",
    "    if not miss[:, j].any():\n",
    "        continue\n",
    "    info = station_info.loc[st]\n",
    "    lane_type = info[\"lane_type\"]\n",
    "    meta_type = info[\"meta_type\"]\n",
    "    fwy = info[\"fwy\"]\n",
    "    district = info[\"district\"]\n",
    "\n",
    "    idxs = np.where(miss[:, j])[0]\n",
    "    fill_vals = []\n",
    "    for t_idx in idxs:\n",
    "        h = int(hours[t_idx])\n",
    "        key = (lane_type, meta_type, h, fwy, district)\n",
    "        fill_vals.append(speed_lookup.get(key, np.nan))\n",
    "    speed_np[idxs, j] = np.array(fill_vals, dtype=np.float32)\n",
    "\n",
    "speed_imp = pd.DataFrame(speed_np, index=speed_ff.index, columns=speed_ff.columns)\n",
    "\n",
    "# Remaining NaNs → station TRAIN mean → global TRAIN mean\n",
    "speed_train_mean_station = speed_imp.loc[train_time_mask].mean(axis=0)\n",
    "speed_imp = speed_imp.fillna(speed_train_mean_station).fillna(global_speed_train_mean)\n",
    "\n",
    "print(\"After imputation:\")\n",
    "print(\"Flow missing fraction:\", float(np.isnan(flow_imp.to_numpy()).mean()))\n",
    "print(\"Speed missing fraction:\", float(np.isnan(speed_imp.to_numpy()).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ef022-a962-4b61-8216-b9f447935673",
   "metadata": {},
   "source": [
    "## Build graph-ready tensors\n",
    "\n",
    "We create:\n",
    "- X: (T, N, F)\n",
    "  Features include:\n",
    "  - flow (1)\n",
    "  - speed (1)\n",
    "  - time encodings: hour_sin, hour_cos, dow_sin, dow_cos (4)\n",
    "  Total F = 6\n",
    "\n",
    "- Y: (T, N)\n",
    "  Target is flow at each station.\n",
    "\n",
    "Later, each training sample is a sliding window:\n",
    "- Input:  X[t : t+IN_LEN]\n",
    "- Output: Y[t+IN_LEN : t+IN_LEN+OUT_LEN]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "979fd9ed-9d39-4ad5-8941-d65abd464ec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T20:39:31.395785Z",
     "iopub.status.busy": "2026-02-07T20:39:31.395279Z",
     "iopub.status.idle": "2026-02-07T20:39:31.523145Z",
     "shell.execute_reply": "2026-02-07T20:39:31.522242Z",
     "shell.execute_reply.started": "2026-02-07T20:39:31.395760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2208, 1821, 6)  (T,N,F)\n",
      "Y shape: (2208, 1821)  (T,N)\n"
     ]
    }
   ],
   "source": [
    "def make_time_features(timestamps: pd.DatetimeIndex) -> np.ndarray:\n",
    "    hours = timestamps.hour.values\n",
    "    dow   = timestamps.dayofweek.values\n",
    "    hour_sin = np.sin(2*np.pi*hours/24.0)\n",
    "    hour_cos = np.cos(2*np.pi*hours/24.0)\n",
    "    dow_sin  = np.sin(2*np.pi*dow/7.0)\n",
    "    dow_cos  = np.cos(2*np.pi*dow/7.0)\n",
    "    return np.stack([hour_sin, hour_cos, dow_sin, dow_cos], axis=1).astype(np.float32)  # (T,4)\n",
    "\n",
    "time_feats = make_time_features(flow_imp.index)  # (T,4)\n",
    "time_feats_b = np.repeat(time_feats[:, None, :], repeats=N, axis=1)  # (T,N,4)\n",
    "\n",
    "flow_arr  = flow_imp.to_numpy(dtype=np.float32)[:, :, None]   # (T,N,1)\n",
    "speed_arr = speed_imp.to_numpy(dtype=np.float32)[:, :, None]  # (T,N,1)\n",
    "\n",
    "X = np.concatenate([flow_arr, speed_arr, time_feats_b], axis=2)  # (T,N,6)\n",
    "Y = flow_arr.squeeze(-1).astype(np.float32)                      # (T,N)\n",
    "\n",
    "print(\"X shape:\", X.shape, \" (T,N,F)\")\n",
    "print(\"Y shape:\", Y.shape, \" (T,N)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316168d6-874e-4fb3-a6f0-9de8d05c5830",
   "metadata": {},
   "source": [
    "## Build adjacency matrix A (static graph baseline)\n",
    "\n",
    "We build a physical-neighborhood adjacency using metadata:\n",
    "- Sort stations by (freeway, absolute postmile)\n",
    "- Connect K neighbors upstream + downstream\n",
    "- Weight edges using a Gaussian kernel of distance\n",
    "- Add self-loops\n",
    "\n",
    "Note:\n",
    "GraphWaveNet can also learn an adaptive adjacency; this static graph is a strong baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "def5e213-a0b5-43ea-b332-25a80dfaa72b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T20:40:39.110976Z",
     "iopub.status.busy": "2026-02-07T20:40:39.110692Z",
     "iopub.status.idle": "2026-02-07T20:40:39.239413Z",
     "shell.execute_reply": "2026-02-07T20:40:39.238547Z",
     "shell.execute_reply.started": "2026-02-07T20:40:39.110955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shape: (1821, 1821)\n",
      "Adjacency density (A>0): 0.0023693916932872663\n"
     ]
    }
   ],
   "source": [
    "def build_adjacency_from_metadata(meta_df: pd.DataFrame, stations: np.ndarray, k_neighbors: int = 2) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build adjacency within each freeway chain using Abs PM order.\n",
    "    Edge weights = exp(-(dist^2 / sigma^2)), sigma = median neighbor distance.\n",
    "    \"\"\"\n",
    "    # Find needed meta columns\n",
    "    id_col = \"station\"\n",
    "    abs_pm_col = None\n",
    "    for cand in [\"Abs PM\", \"abs_pm\", \"AbsPM\", \"Postmile\", \"PM\"]:\n",
    "        if cand in meta_df.columns:\n",
    "            abs_pm_col = cand\n",
    "            break\n",
    "    fwy_col2 = None\n",
    "    for cand in [\"Fwy\", \"FWY\", \"fwy\", \"Freeway\"]:\n",
    "        if cand in meta_df.columns:\n",
    "            fwy_col2 = cand\n",
    "            break\n",
    "\n",
    "    if abs_pm_col is None or fwy_col2 is None:\n",
    "        raise KeyError(f\"Metadata missing Abs PM or Fwy columns. Found AbsPM={abs_pm_col}, Fwy={fwy_col2}\")\n",
    "\n",
    "    meta_sub = meta_df[meta_df[id_col].isin(stations)].copy()\n",
    "    meta_sub[\"abs_pm\"] = pd.to_numeric(meta_sub[abs_pm_col], errors=\"coerce\")\n",
    "    meta_sub[\"fwy\"] = meta_sub[fwy_col2].astype(str)\n",
    "\n",
    "    # station index map\n",
    "    station_to_idx = {s: i for i, s in enumerate(stations)}\n",
    "    N = len(stations)\n",
    "    A = np.zeros((N, N), dtype=np.float32)\n",
    "\n",
    "    # estimate sigma from typical neighbor distances\n",
    "    all_dists = []\n",
    "    for fwy, grp in meta_sub.sort_values([\"fwy\", \"abs_pm\"]).groupby(\"fwy\"):\n",
    "        pm = grp[\"abs_pm\"].dropna().values\n",
    "        if len(pm) < 2:\n",
    "            continue\n",
    "        d = np.diff(np.sort(pm))\n",
    "        d = d[d > 0]\n",
    "        all_dists.extend(d.tolist())\n",
    "\n",
    "    sigma = float(np.median(all_dists)) if len(all_dists) else 0.5\n",
    "    sigma = max(sigma, 1e-3)\n",
    "\n",
    "    def w(dist):  # gaussian weight\n",
    "        return float(np.exp(- (dist**2) / (sigma**2)))\n",
    "\n",
    "    # connect neighbors\n",
    "    for fwy, grp in meta_sub.sort_values([\"fwy\", \"abs_pm\"]).groupby(\"fwy\"):\n",
    "        grp = grp.dropna(subset=[\"abs_pm\"]).sort_values(\"abs_pm\")\n",
    "        ids = grp[id_col].astype(int).tolist()\n",
    "        pms = grp[\"abs_pm\"].astype(float).tolist()\n",
    "\n",
    "        for i, sid in enumerate(ids):\n",
    "            ii = station_to_idx[sid]\n",
    "            for step in range(1, k_neighbors + 1):\n",
    "                if i - step >= 0:\n",
    "                    sj = ids[i - step]; jj = station_to_idx[sj]\n",
    "                    A[ii, jj] = w(abs(pms[i] - pms[i-step]))\n",
    "                if i + step < len(ids):\n",
    "                    sj = ids[i + step]; jj = station_to_idx[sj]\n",
    "                    A[ii, jj] = w(abs(pms[i] - pms[i+step]))\n",
    "\n",
    "    # self loops + symmetrize\n",
    "    np.fill_diagonal(A, 1.0)\n",
    "    A = np.maximum(A, A.T)\n",
    "    return A\n",
    "\n",
    "# metadata table for adjacency should be meta with standardized station column\n",
    "meta_for_adj = meta.copy()\n",
    "meta_for_adj[\"station\"] = meta_for_adj[\"station\"].astype(int)\n",
    "\n",
    "A = build_adjacency_from_metadata(meta_for_adj, stations=stations, k_neighbors=K_NEIGHBORS)\n",
    "print(\"A shape:\", A.shape)\n",
    "print(\"Adjacency density (A>0):\", float((A > 0).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7f0ba-39f7-4563-a319-8809315ec010",
   "metadata": {},
   "source": [
    "## Sliding windows + splits\n",
    "\n",
    "Each sample uses:\n",
    "- Input window:  X[t : t+IN_LEN]\n",
    "- Output window: Y[t+IN_LEN : t+IN_LEN+OUT_LEN]\n",
    "\n",
    "We split by the **time of the first predicted hour** (t + IN_LEN):\n",
    "- Train if output_start_time ≤ TRAIN_END\n",
    "- Val   if TRAIN_END < output_start_time ≤ VAL_END\n",
    "- Test  if output_start_time > VAL_END\n",
    "\n",
    "Then we save everything to a single `.npz` artifact so every model reads the exact same dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ae1abeb-d866-4754-84c2-8e9e7c9353ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T20:41:15.441072Z",
     "iopub.status.busy": "2026-02-07T20:41:15.440758Z",
     "iopub.status.idle": "2026-02-07T20:41:19.936565Z",
     "shell.execute_reply": "2026-02-07T20:41:19.935601Z",
     "shell.execute_reply.started": "2026-02-07T20:41:15.441048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window starts: train=1080, val=360, test=673\n",
      "Saved: artifacts/pems_graph_dataset.npz\n"
     ]
    }
   ],
   "source": [
    "# Sliding window starts\n",
    "T_total = X.shape[0]\n",
    "max_t = T_total - (IN_LEN + OUT_LEN) + 1\n",
    "starts = np.arange(max_t, dtype=np.int32)\n",
    "\n",
    "timestamps = pd.DatetimeIndex(flow_imp.index)\n",
    "out_start_times = timestamps[starts + IN_LEN]\n",
    "\n",
    "train_starts = starts[out_start_times <= TRAIN_END]\n",
    "val_starts   = starts[(out_start_times > TRAIN_END) & (out_start_times <= VAL_END)]\n",
    "test_starts  = starts[out_start_times > VAL_END]\n",
    "\n",
    "print(f\"Window starts: train={len(train_starts)}, val={len(val_starts)}, test={len(test_starts)}\")\n",
    "\n",
    "# Train-only scalers (per node) for flow and speed (channels 0 and 1)\n",
    "train_time_mask = timestamps <= TRAIN_END\n",
    "\n",
    "flow_mean = X[train_time_mask, :, 0].mean(axis=0).astype(np.float32)\n",
    "flow_std  = (X[train_time_mask, :, 0].std(axis=0) + 1e-6).astype(np.float32)\n",
    "\n",
    "speed_mean = X[train_time_mask, :, 1].mean(axis=0).astype(np.float32)\n",
    "speed_std  = (X[train_time_mask, :, 1].std(axis=0) + 1e-6).astype(np.float32)\n",
    "\n",
    "np.savez_compressed(\n",
    "    DATASET_NPZ,\n",
    "    X=X.astype(np.float32),\n",
    "    Y=Y.astype(np.float32),\n",
    "    A=A.astype(np.float32),\n",
    "    stations=stations.astype(np.int32),\n",
    "    timestamps=np.array(timestamps.astype(\"datetime64[ns]\")),\n",
    "    train_starts=train_starts,\n",
    "    val_starts=val_starts,\n",
    "    test_starts=test_starts,\n",
    "    in_len=np.array([IN_LEN], dtype=np.int32),\n",
    "    out_len=np.array([OUT_LEN], dtype=np.int32),\n",
    "    flow_mean=flow_mean, flow_std=flow_std,\n",
    "    speed_mean=speed_mean, speed_std=speed_std,\n",
    "    seed=np.array([SEED], dtype=np.int32),\n",
    ")\n",
    "\n",
    "print(\"Saved:\", DATASET_NPZ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d7ebe-5650-4bac-b5be-468fe9cfb24d",
   "metadata": {},
   "source": [
    "## Fix window split leakage (strict horizon containment)\n",
    "\n",
    "A window starting at time t uses:\n",
    "- Input:  X[t : t+IN_LEN]\n",
    "- Output: Y[t+IN_LEN : t+IN_LEN+OUT_LEN]\n",
    "\n",
    "To prevent label leakage across train/val/test boundaries, we require:\n",
    "- Train: output_end_time ≤ TRAIN_END\n",
    "- Val:   output_start_time > TRAIN_END AND output_end_time ≤ VAL_END\n",
    "- Test:  output_start_time > VAL_END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26396172-e9bd-4411-b484-0b5dd724bd1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T21:10:34.519135Z",
     "iopub.status.busy": "2026-02-07T21:10:34.518819Z",
     "iopub.status.idle": "2026-02-07T21:10:39.611410Z",
     "shell.execute_reply": "2026-02-07T21:10:39.607849Z",
     "shell.execute_reply.started": "2026-02-07T21:10:34.519115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRICT window starts:\n",
      "train: 1009\n",
      "val:   289\n",
      "test:  673\n",
      "Saved strict dataset to: artifacts/pems_graph_dataset_strict.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATASET_NPZ = Path(\"artifacts/pems_graph_dataset.npz\")\n",
    "DATASET_NPZ_STRICT = Path(\"artifacts/pems_graph_dataset_strict.npz\")\n",
    "\n",
    "data = np.load(DATASET_NPZ, allow_pickle=True)\n",
    "\n",
    "X = data[\"X\"]\n",
    "Y = data[\"Y\"]\n",
    "A = data[\"A\"]\n",
    "stations = data[\"stations\"]\n",
    "timestamps = pd.to_datetime(data[\"timestamps\"])\n",
    "\n",
    "IN_LEN = int(data[\"in_len\"][0])\n",
    "OUT_LEN = int(data[\"out_len\"][0])\n",
    "\n",
    "flow_mean = data[\"flow_mean\"]\n",
    "flow_std  = data[\"flow_std\"]\n",
    "speed_mean = data[\"speed_mean\"]\n",
    "speed_std  = data[\"speed_std\"]\n",
    "\n",
    "T_total = X.shape[0]\n",
    "max_t = T_total - (IN_LEN + OUT_LEN) + 1\n",
    "starts = np.arange(max_t, dtype=np.int32)\n",
    "\n",
    "out_start_times = timestamps[starts + IN_LEN]\n",
    "out_end_times   = timestamps[starts + IN_LEN + OUT_LEN - 1]\n",
    "\n",
    "TRAIN_END = pd.Timestamp(\"2024-11-15 23:59:59\")\n",
    "VAL_END   = pd.Timestamp(\"2024-11-30 23:59:59\")\n",
    "\n",
    "# Strict splits\n",
    "train_starts = starts[out_end_times <= TRAIN_END]\n",
    "val_starts   = starts[(out_start_times > TRAIN_END) & (out_end_times <= VAL_END)]\n",
    "test_starts  = starts[out_start_times > VAL_END]\n",
    "\n",
    "print(\"STRICT window starts:\")\n",
    "print(\"train:\", len(train_starts))\n",
    "print(\"val:  \", len(val_starts))\n",
    "print(\"test: \", len(test_starts))\n",
    "\n",
    "np.savez_compressed(\n",
    "    DATASET_NPZ_STRICT,\n",
    "    X=X.astype(np.float32),\n",
    "    Y=Y.astype(np.float32),\n",
    "    A=A.astype(np.float32),\n",
    "    stations=stations.astype(np.int32),\n",
    "    timestamps=np.array(timestamps.astype(\"datetime64[ns]\")),\n",
    "    train_starts=train_starts,\n",
    "    val_starts=val_starts,\n",
    "    test_starts=test_starts,\n",
    "    in_len=np.array([IN_LEN], dtype=np.int32),\n",
    "    out_len=np.array([OUT_LEN], dtype=np.int32),\n",
    "    flow_mean=flow_mean.astype(np.float32),\n",
    "    flow_std=flow_std.astype(np.float32),\n",
    "    speed_mean=speed_mean.astype(np.float32),\n",
    "    speed_std=speed_std.astype(np.float32),\n",
    ")\n",
    "\n",
    "print(\"Saved strict dataset to:\", DATASET_NPZ_STRICT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb6355d-15db-480a-88c0-4504c380b16a",
   "metadata": {},
   "source": [
    "## Load strict dataset artifact\n",
    "\n",
    "We will only use the strict `.npz` going forward to ensure no leakage in labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5515da5a-67a7-47dd-a481-a12fc40907e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T21:11:06.047641Z",
     "iopub.status.busy": "2026-02-07T21:11:06.047230Z",
     "iopub.status.idle": "2026-02-07T21:11:06.540671Z",
     "shell.execute_reply": "2026-02-07T21:11:06.539927Z",
     "shell.execute_reply.started": "2026-02-07T21:11:06.047617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (2208, 1821, 6) Y: (2208, 1821) A: (1821, 1821)\n",
      "starts: 1009 289 673\n",
      "IN_LEN: 24 OUT_LEN: 72\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATASET_NPZ_STRICT = Path(\"artifacts/pems_graph_dataset_strict.npz\")\n",
    "d = np.load(DATASET_NPZ_STRICT, allow_pickle=True)\n",
    "\n",
    "X = d[\"X\"]          # (T,N,F)\n",
    "Y = d[\"Y\"]          # (T,N)\n",
    "A = d[\"A\"]          # (N,N)\n",
    "stations = d[\"stations\"]\n",
    "timestamps = pd.to_datetime(d[\"timestamps\"])\n",
    "\n",
    "train_starts = d[\"train_starts\"]\n",
    "val_starts   = d[\"val_starts\"]\n",
    "test_starts  = d[\"test_starts\"]\n",
    "\n",
    "IN_LEN = int(d[\"in_len\"][0])\n",
    "OUT_LEN = int(d[\"out_len\"][0])\n",
    "\n",
    "flow_mean = d[\"flow_mean\"]  # (N,)\n",
    "flow_std  = d[\"flow_std\"]   # (N,)\n",
    "\n",
    "print(\"X:\", X.shape, \"Y:\", Y.shape, \"A:\", A.shape)\n",
    "print(\"starts:\", len(train_starts), len(val_starts), len(test_starts))\n",
    "print(\"IN_LEN:\", IN_LEN, \"OUT_LEN:\", OUT_LEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada36a4-6634-47c0-98c5-7353202d241c",
   "metadata": {},
   "source": [
    "## Baseline evaluation\n",
    "\n",
    "We evaluate at horizons: 12, 24, 48, 72 hours ahead.\n",
    "\n",
    "Important detail:\n",
    "Our output sequence begins at +1 hour ahead of the last input time.\n",
    "So horizon `h` corresponds to output index `h-1` in the 72-step target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "737f6784-238b-4c35-a5bc-ea736646d0b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T21:12:53.206372Z",
     "iopub.status.busy": "2026-02-07T21:12:53.205790Z",
     "iopub.status.idle": "2026-02-07T21:12:53.212959Z",
     "shell.execute_reply": "2026-02-07T21:12:53.211829Z",
     "shell.execute_reply.started": "2026-02-07T21:12:53.206347Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "EVAL_HORIZONS = [12, 24, 48, 72]\n",
    "\n",
    "def init_metric_accumulators(horizons):\n",
    "    return {\n",
    "        h: {\"abs_sum\": 0.0, \"sq_sum\": 0.0, \"count\": 0}\n",
    "        for h in horizons\n",
    "    }\n",
    "\n",
    "def finalize_metrics(acc):\n",
    "    out = {}\n",
    "    for h, v in acc.items():\n",
    "        mae = v[\"abs_sum\"] / max(v[\"count\"], 1)\n",
    "        rmse = np.sqrt(v[\"sq_sum\"] / max(v[\"count\"], 1))\n",
    "        out[h] = {\"MAE\": mae, \"RMSE\": rmse}\n",
    "    return out\n",
    "\n",
    "def print_metrics(title, metrics_dict):\n",
    "    print(\"\\n\" + title)\n",
    "    for h in sorted(metrics_dict.keys()):\n",
    "        print(f\"  {h:>3}h  MAE={metrics_dict[h]['MAE']:.3f}  RMSE={metrics_dict[h]['RMSE']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd500bf-d0f5-4205-85c3-2c7a169a645d",
   "metadata": {},
   "source": [
    "### Baseline 1 — Persistence\n",
    "\n",
    "For each station:\n",
    "- Predict that all future horizons equal the **last observed flow** in the input window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8e7a280-81bd-4fea-8134-396e459526ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T21:14:18.584055Z",
     "iopub.status.busy": "2026-02-07T21:14:18.583297Z",
     "iopub.status.idle": "2026-02-07T21:14:18.770971Z",
     "shell.execute_reply": "2026-02-07T21:14:18.769750Z",
     "shell.execute_reply.started": "2026-02-07T21:14:18.584029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fa4fe544b943cfaf7ccc68a472cdd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Persistence (val):   0%|          | 0/289 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8248ff923c3a46dba30cc6d3c4398268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Persistence (test):   0%|          | 0/673 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Persistence — Validation\n",
      "   12h  MAE=910.133  RMSE=1437.403\n",
      "   24h  MAE=151.755  RMSE=354.476\n",
      "   48h  MAE=203.020  RMSE=451.021\n",
      "   72h  MAE=220.150  RMSE=478.588\n",
      "\n",
      "Persistence — Test\n",
      "   12h  MAE=917.014  RMSE=1455.414\n",
      "   24h  MAE=147.896  RMSE=340.247\n",
      "   48h  MAE=200.592  RMSE=443.364\n",
      "   72h  MAE=196.856  RMSE=431.611\n"
     ]
    }
   ],
   "source": [
    "def eval_persistence(X, Y, starts, in_len, horizons, desc=\"\"):\n",
    "    acc = init_metric_accumulators(horizons)\n",
    "\n",
    "    for t in tqdm(starts, desc=desc):\n",
    "        # last observed flow at the end of input window\n",
    "        last_flow = X[t + in_len - 1, :, 0]  # (N,)\n",
    "\n",
    "        for h in horizons:\n",
    "            idx = h - 1\n",
    "            true = Y[t + in_len + idx, :]     # (N,)\n",
    "            pred = last_flow                  # (N,)\n",
    "\n",
    "            err = pred - true\n",
    "            acc[h][\"abs_sum\"] += float(np.abs(err).sum())\n",
    "            acc[h][\"sq_sum\"]  += float((err ** 2).sum())\n",
    "            acc[h][\"count\"]   += err.size\n",
    "\n",
    "    return finalize_metrics(acc)\n",
    "\n",
    "pers_val  = eval_persistence(X, Y, val_starts, IN_LEN, EVAL_HORIZONS, desc=\"Persistence (val)\")\n",
    "pers_test = eval_persistence(X, Y, test_starts, IN_LEN, EVAL_HORIZONS, desc=\"Persistence (test)\")\n",
    "\n",
    "print_metrics(\"Persistence — Validation\", pers_val)\n",
    "print_metrics(\"Persistence — Test\", pers_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61797eea-3aad-422c-ab05-4cfc275c3280",
   "metadata": {},
   "source": [
    "### Baseline 2 — Historical Average (HA-168)\n",
    "\n",
    "We compute a per-node seasonal mean using train data only:\n",
    "- slot = (day_of_week * 24 + hour) ∈ [0..167]\n",
    "- mean_flow[slot, node] = average flow in train for that slot\n",
    "\n",
    "Forecast:\n",
    "- For each horizon step, use the slot mean of that future timestamp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f1ecda2-abdd-4241-bb4e-3215a5cb224d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T21:15:48.783046Z",
     "iopub.status.busy": "2026-02-07T21:15:48.782558Z",
     "iopub.status.idle": "2026-02-07T21:15:48.972239Z",
     "shell.execute_reply": "2026-02-07T21:15:48.971202Z",
     "shell.execute_reply.started": "2026-02-07T21:15:48.783009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab956bdc0c8415f836d0662d4fb5523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HA-168 (val):   0%|          | 0/289 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c08a3390fe74619a202d791c8b2c9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HA-168 (test):   0%|          | 0/673 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HA-168 — Validation\n",
      "   12h  MAE=116.424  RMSE=258.349\n",
      "   24h  MAE=123.997  RMSE=277.816\n",
      "   48h  MAE=134.454  RMSE=302.695\n",
      "   72h  MAE=137.523  RMSE=306.085\n",
      "\n",
      "HA-168 — Test\n",
      "   12h  MAE=119.650  RMSE=283.458\n",
      "   24h  MAE=120.382  RMSE=284.451\n",
      "   48h  MAE=122.195  RMSE=286.807\n",
      "   72h  MAE=126.187  RMSE=293.463\n"
     ]
    }
   ],
   "source": [
    "def build_ha168_means(Y, timestamps, train_end):\n",
    "    train_mask = timestamps <= train_end\n",
    "    Y_train = Y[train_mask]  # (T_train, N)\n",
    "    ts_train = timestamps[train_mask]\n",
    "\n",
    "    slot = ts_train.dayofweek.to_numpy() * 24 + ts_train.hour.to_numpy()  # (T_train,)\n",
    "    G = 168\n",
    "    N = Y.shape[1]\n",
    "\n",
    "    means = np.zeros((G, N), dtype=np.float32)\n",
    "    counts = np.zeros((G,), dtype=np.int64)\n",
    "\n",
    "    for g in range(G):\n",
    "        m = (slot == g)\n",
    "        if m.any():\n",
    "            means[g] = Y_train[m].mean(axis=0)\n",
    "            counts[g] = int(m.sum())\n",
    "        else:\n",
    "            # fallback (should be rare)\n",
    "            means[g] = Y_train.mean(axis=0)\n",
    "            counts[g] = 0\n",
    "    return means, counts\n",
    "\n",
    "def eval_ha168(Y, timestamps, starts, in_len, horizons, means_ha168, desc=\"\"):\n",
    "    acc = init_metric_accumulators(horizons)\n",
    "\n",
    "    for t in tqdm(starts, desc=desc):\n",
    "        for h in horizons:\n",
    "            idx = h - 1\n",
    "            future_time = timestamps[t + in_len + idx]\n",
    "            g = int(future_time.dayofweek * 24 + future_time.hour)\n",
    "\n",
    "            pred = means_ha168[g, :]                 # (N,)\n",
    "            true = Y[t + in_len + idx, :]            # (N,)\n",
    "\n",
    "            err = pred - true\n",
    "            acc[h][\"abs_sum\"] += float(np.abs(err).sum())\n",
    "            acc[h][\"sq_sum\"]  += float((err ** 2).sum())\n",
    "            acc[h][\"count\"]   += err.size\n",
    "\n",
    "    return finalize_metrics(acc)\n",
    "\n",
    "TRAIN_END = pd.Timestamp(\"2024-11-15 23:59:59\")\n",
    "ha_means, ha_counts = build_ha168_means(Y, timestamps, TRAIN_END)\n",
    "\n",
    "ha_val  = eval_ha168(Y, timestamps, val_starts, IN_LEN, EVAL_HORIZONS, ha_means, desc=\"HA-168 (val)\")\n",
    "ha_test = eval_ha168(Y, timestamps, test_starts, IN_LEN, EVAL_HORIZONS, ha_means, desc=\"HA-168 (test)\")\n",
    "\n",
    "print_metrics(\"HA-168 — Validation\", ha_val)\n",
    "print_metrics(\"HA-168 — Test\", ha_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcc74e4-add9-43ab-a18c-123e4dc5142b",
   "metadata": {},
   "source": [
    "## PyTorch Dataset for sliding windows\n",
    "\n",
    "Each item returns:\n",
    "- x: (C, N, IN_LEN)   where C = number of features (6)\n",
    "- y: (OUT_LEN, N)     scaled flow targets\n",
    "\n",
    "Scaling:\n",
    "- We scale flow and speed using TRAIN-only mean/std (per node)\n",
    "- Time features remain unchanged (already bounded by sin/cos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2c00304-797e-43d5-b857-245c266f37d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T21:16:13.532982Z",
     "iopub.status.busy": "2026-02-07T21:16:13.532696Z",
     "iopub.status.idle": "2026-02-07T21:16:13.906511Z",
     "shell.execute_reply": "2026-02-07T21:16:13.905799Z",
     "shell.execute_reply.started": "2026-02-07T21:16:13.532959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x: torch.Size([16, 6, 1821, 24]) Batch y: torch.Size([16, 72, 1821])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PemsWindowDataset(Dataset):\n",
    "    def __init__(self, X, Y, starts, in_len, out_len, flow_mean, flow_std, speed_mean, speed_std):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.starts = starts\n",
    "        self.in_len = in_len\n",
    "        self.out_len = out_len\n",
    "\n",
    "        self.flow_mean = flow_mean.astype(np.float32)\n",
    "        self.flow_std  = flow_std.astype(np.float32)\n",
    "        self.speed_mean = speed_mean.astype(np.float32)\n",
    "        self.speed_std  = speed_std.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.starts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = int(self.starts[idx])\n",
    "\n",
    "        x = self.X[t : t + self.in_len].copy().astype(np.float32)  # (IN_LEN, N, F)\n",
    "        y = self.Y[t + self.in_len : t + self.in_len + self.out_len].copy().astype(np.float32)  # (OUT_LEN, N)\n",
    "\n",
    "        # scale input channels: flow=0, speed=1\n",
    "        x[..., 0] = (x[..., 0] - self.flow_mean[None, :]) / self.flow_std[None, :]\n",
    "        x[..., 1] = (x[..., 1] - self.speed_mean[None, :]) / self.speed_std[None, :]\n",
    "\n",
    "        # scale targets (flow)\n",
    "        y = (y - self.flow_mean[None, :]) / self.flow_std[None, :]\n",
    "\n",
    "        # rearrange x to (C, N, IN_LEN) for conv models\n",
    "        x = np.transpose(x, (2, 1, 0))  # (F, N, IN_LEN)\n",
    "\n",
    "        return torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "# Load speed scaler too\n",
    "speed_mean = d[\"speed_mean\"]\n",
    "speed_std  = d[\"speed_std\"]\n",
    "\n",
    "train_ds = PemsWindowDataset(X, Y, train_starts, IN_LEN, OUT_LEN, flow_mean, flow_std, speed_mean, speed_std)\n",
    "val_ds   = PemsWindowDataset(X, Y, val_starts,   IN_LEN, OUT_LEN, flow_mean, flow_std, speed_mean, speed_std)\n",
    "test_ds  = PemsWindowDataset(X, Y, test_starts,  IN_LEN, OUT_LEN, flow_mean, flow_std, speed_mean, speed_std)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"Batch x:\", xb.shape, \"Batch y:\", yb.shape)\n",
    "# Expect: x=(B, 6, N, 24) and y=(B, 72, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fac0c314-8f62-4624-9d71-37bed7c48631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T21:57:23.849329Z",
     "iopub.status.busy": "2026-02-07T21:57:23.849007Z",
     "iopub.status.idle": "2026-02-07T21:57:23.916084Z",
     "shell.execute_reply": "2026-02-07T21:57:23.915230Z",
     "shell.execute_reply.started": "2026-02-07T21:57:23.849307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean |Δ| over 1h shift: 156.388\n",
      "Mean |Δ| over 6h shift: 666.328\n",
      "Mean |Δ| over 12h shift: 921.578\n",
      "Mean |Δ| over 24h shift: 143.347\n",
      "Mean |Δ| over 48h shift: 202.141\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_abs_change(Y, h):\n",
    "    return float(np.abs(Y[h:] - Y[:-h]).mean())\n",
    "\n",
    "for h in [1, 6, 12, 24, 48]:\n",
    "    print(f\"Mean |Δ| over {h}h shift: {mean_abs_change(Y, h):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7bb9a1-ed40-4e4c-aca1-cdb694fe9ab4",
   "metadata": {},
   "source": [
    "## Graph supports (normalized adjacency)\n",
    "\n",
    "GraphWaveNet uses graph propagation through adjacency matrices (\"supports\").\n",
    "We will build:\n",
    "- A_rw  = row-normalized adjacency (random-walk normalization)\n",
    "- A_rwT = transpose support (helps if graph is directed; still ok for symmetric graphs)\n",
    "\n",
    "We store them as sparse tensors for speed (our adjacency is very sparse).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a205f5bd-ad93-49f4-ab2f-ff60b6e200bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T21:59:44.385916Z",
     "iopub.status.busy": "2026-02-07T21:59:44.385011Z",
     "iopub.status.idle": "2026-02-07T21:59:44.530577Z",
     "shell.execute_reply": "2026-02-07T21:59:44.529646Z",
     "shell.execute_reply.started": "2026-02-07T21:59:44.385891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supports: [torch.Size([1821, 1821]), torch.Size([1821, 1821])] nnz: [7856, 7856]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def row_normalize_dense(A: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "    d = A.sum(axis=1, keepdims=True)\n",
    "    return A / (d + eps)\n",
    "\n",
    "def dense_to_torch_sparse(A: np.ndarray, device: str):\n",
    "    A = A.astype(np.float32)\n",
    "    idx = np.nonzero(A)\n",
    "    values = A[idx]\n",
    "    indices = np.vstack(idx)  # (2, nnz)\n",
    "\n",
    "    indices = torch.tensor(indices, dtype=torch.long, device=device)\n",
    "    values  = torch.tensor(values, dtype=torch.float32, device=device)\n",
    "    shape = A.shape\n",
    "\n",
    "    sp = torch.sparse_coo_tensor(indices, values, size=shape, device=device).coalesce()\n",
    "    return sp\n",
    "\n",
    "A_rw = row_normalize_dense(A)\n",
    "A_rwT = row_normalize_dense(A.T)\n",
    "\n",
    "supports = [\n",
    "    dense_to_torch_sparse(A_rw, DEVICE),\n",
    "    dense_to_torch_sparse(A_rwT, DEVICE),\n",
    "]\n",
    "\n",
    "print(\"Supports:\", [s.shape for s in supports], \"nnz:\", [int(s._nnz()) for s in supports])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d37d9-e314-48ec-8a9b-0368538be343",
   "metadata": {},
   "source": [
    "## Diffusion graph convolution (sparse)\n",
    "\n",
    "We need a fast way to compute:\n",
    "A @ X  (graph propagation)\n",
    "\n",
    "X is batched with shape (B, C, N, T).\n",
    "We reshape into (N, B*C*T) so sparse matrix multiply works efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6b573ca-1a08-4222-b75b-c6829443ea64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T22:00:11.218542Z",
     "iopub.status.busy": "2026-02-07T22:00:11.218057Z",
     "iopub.status.idle": "2026-02-07T22:00:11.226774Z",
     "shell.execute_reply": "2026-02-07T22:00:11.225879Z",
     "shell.execute_reply.started": "2026-02-07T22:00:11.218517Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NConv(nn.Module):\n",
    "    \"\"\"Sparse graph multiplication: (N,N) @ (B,C,N,T) -> (B,C,N,T)\"\"\"\n",
    "    def forward(self, x, A_sp):\n",
    "        # x: (B,C,N,T)\n",
    "        B, C, N, T = x.shape\n",
    "        x_r = x.permute(2, 0, 1, 3).reshape(N, -1)      # (N, B*C*T)\n",
    "        x_r = torch.sparse.mm(A_sp, x_r)                # (N, B*C*T)\n",
    "        x_out = x_r.reshape(N, B, C, T).permute(1, 2, 0, 3)  # (B,C,N,T)\n",
    "        return x_out\n",
    "\n",
    "class DiffusionGraphConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Diffusion graph conv:\n",
    "    concat [X, A1X, A2X, ...] then 1x1 conv.\n",
    "\n",
    "    order=1 means we use only one hop per support (fast and stable).\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out, supports, order=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.nconv = NConv()\n",
    "        self.supports = supports\n",
    "        self.order = order\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # total input channels after concatenation\n",
    "        c_total = c_in * (1 + len(supports) * order)\n",
    "        self.mlp = nn.Conv2d(c_total, c_out, kernel_size=(1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = [x]\n",
    "        for A in self.supports:\n",
    "            x1 = self.nconv(x, A)\n",
    "            out.append(x1)\n",
    "            for _ in range(2, self.order + 1):\n",
    "                x1 = self.nconv(x1, A)\n",
    "                out.append(x1)\n",
    "\n",
    "        h = torch.cat(out, dim=1)\n",
    "        h = self.mlp(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90555df0-af2c-407e-b789-20335ccd6ad3",
   "metadata": {},
   "source": [
    "## GraphWaveNet baseline model\n",
    "\n",
    "We use:\n",
    "- Causal dilated temporal convolutions (TCN-style)\n",
    "- Gated activations (tanh * sigmoid)\n",
    "- Residual + skip connections\n",
    "- Diffusion graph convolution inside each layer\n",
    "\n",
    "Output head:\n",
    "- Uses the final time step embedding to predict OUT_LEN horizons directly\n",
    "- Output shape: (B, OUT_LEN, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21a86ee7-6121-4910-ab01-db89a3a19e2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T22:04:50.463959Z",
     "iopub.status.busy": "2026-02-07T22:04:50.463528Z",
     "iopub.status.idle": "2026-02-07T22:04:50.478854Z",
     "shell.execute_reply": "2026-02-07T22:04:50.477780Z",
     "shell.execute_reply.started": "2026-02-07T22:04:50.463930Z"
    }
   },
   "outputs": [],
   "source": [
    "class CausalConv2d(nn.Module):\n",
    "    \"\"\"Causal conv along time axis only (last dimension).\"\"\"\n",
    "    def __init__(self, c_in, c_out, kernel_size=2, dilation=1):\n",
    "        super().__init__()\n",
    "        self.pad = (kernel_size - 1) * dilation\n",
    "        self.conv = nn.Conv2d(\n",
    "            c_in, c_out,\n",
    "            kernel_size=(1, kernel_size),\n",
    "            dilation=(1, dilation)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pad left on time dimension: (left_pad, right_pad, top, bottom) for 2d -> (time_left, time_right, node_left, node_right)\n",
    "        x = F.pad(x, (self.pad, 0, 0, 0))\n",
    "        return self.conv(x)\n",
    "\n",
    "class GraphWaveNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes: int,\n",
    "        in_dim: int,\n",
    "        out_len: int,\n",
    "        supports,\n",
    "        residual_channels=32,\n",
    "        dilation_channels=32,\n",
    "        skip_channels=64,\n",
    "        end_channels=128,\n",
    "        kernel_size=2,\n",
    "        blocks=2,\n",
    "        layers_per_block=3,\n",
    "        gcn_order=1,\n",
    "        dropout=0.3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.in_dim = in_dim\n",
    "        self.out_len = out_len\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.start_conv = nn.Conv2d(in_dim, residual_channels, kernel_size=(1, 1))\n",
    "\n",
    "        self.filter_convs = nn.ModuleList()\n",
    "        self.gate_convs   = nn.ModuleList()\n",
    "        self.res_convs    = nn.ModuleList()\n",
    "        self.skip_convs   = nn.ModuleList()\n",
    "        self.bn           = nn.ModuleList()\n",
    "        self.gconvs       = nn.ModuleList()\n",
    "\n",
    "        # Build temporal + graph blocks\n",
    "        for _ in range(blocks):\n",
    "            for i in range(layers_per_block):\n",
    "                dilation = 2 ** i\n",
    "\n",
    "                self.filter_convs.append(CausalConv2d(residual_channels, dilation_channels, kernel_size, dilation))\n",
    "                self.gate_convs.append(CausalConv2d(residual_channels, dilation_channels, kernel_size, dilation))\n",
    "\n",
    "                self.res_convs.append(nn.Conv2d(dilation_channels, residual_channels, kernel_size=(1, 1)))\n",
    "                self.skip_convs.append(nn.Conv2d(dilation_channels, skip_channels, kernel_size=(1, 1)))\n",
    "\n",
    "                self.gconvs.append(\n",
    "                    DiffusionGraphConv(dilation_channels, residual_channels, supports, order=gcn_order, dropout=dropout)\n",
    "                )\n",
    "\n",
    "                self.bn.append(nn.BatchNorm2d(residual_channels))\n",
    "\n",
    "        self.end_conv_1 = nn.Conv2d(skip_channels, end_channels, kernel_size=(1, 1))\n",
    "        self.end_conv_2 = nn.Conv2d(end_channels, out_len, kernel_size=(1, 1))  # outputs OUT_LEN channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, F, N, T_in)\n",
    "        return: (B, OUT_LEN, N)\n",
    "        \"\"\"\n",
    "        x = self.start_conv(x)  # (B, residual, N, T)\n",
    "        skip = None\n",
    "\n",
    "        for i in range(len(self.filter_convs)):\n",
    "            residual = x\n",
    "\n",
    "            # gated TCN\n",
    "            filt = torch.tanh(self.filter_convs[i](x))\n",
    "            gate = torch.sigmoid(self.gate_convs[i](x))\n",
    "            x = filt * gate\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "            # skip\n",
    "            s = self.skip_convs[i](x)\n",
    "            skip = s if skip is None else (skip + s)\n",
    "\n",
    "            # graph conv -> residual channels\n",
    "            x = self.gconvs[i](x)\n",
    "\n",
    "            # residual connection (time length is preserved by causal padding)\n",
    "            x = x + residual\n",
    "            x = self.bn[i](x)\n",
    "\n",
    "        x = F.relu(skip)\n",
    "        x = F.relu(self.end_conv_1(x))\n",
    "\n",
    "        # Use last time step to predict future horizons\n",
    "        x_last = x[..., -1:].contiguous()          # (B, end_channels, N, 1)\n",
    "        out = self.end_conv_2(x_last).squeeze(-1)  # (B, OUT_LEN, N)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937a1415-bd0e-41d1-9020-7e38b9a329e2",
   "metadata": {},
   "source": [
    "## Training & evaluation loop\n",
    "\n",
    "We train using MSE on scaled targets (stable optimization),\n",
    "then compute MAE/RMSE on the original scale at horizons 12/24/48/72.\n",
    "\n",
    "Early stopping monitors average validation MAE across horizons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f25c2c5-41a5-4944-be65-bc89dd8a13c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-07T22:19:03.564943Z",
     "iopub.status.busy": "2026-02-07T22:19:03.564622Z",
     "iopub.status.idle": "2026-02-07T22:39:25.208699Z",
     "shell.execute_reply": "2026-02-07T22:39:25.207909Z",
     "shell.execute_reply.started": "2026-02-07T22:19:03.564921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ab6472702d435694f36e4deac1d1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980a9332521b48d7815184e6f0e7c747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.529129  val_avg_MAE=203.973\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=225.832  RMSE=393.051\n",
      "   24h  MAE=184.901  RMSE=343.538\n",
      "   48h  MAE=208.168  RMSE=379.516\n",
      "   72h  MAE=196.993  RMSE=369.422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6c6ec16c124129a7fcdc834952f9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a076df23f04d2fa0e008ca01d6d064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss=0.325922  val_avg_MAE=185.356\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=193.387  RMSE=348.977\n",
      "   24h  MAE=166.734  RMSE=319.229\n",
      "   48h  MAE=185.582  RMSE=349.533\n",
      "   72h  MAE=195.720  RMSE=369.310\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491a7e91c8e5492d98cac243d4e14e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d577d368f05448ab97b31f0d01929de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss=0.287739  val_avg_MAE=180.951\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=179.654  RMSE=333.382\n",
      "   24h  MAE=157.967  RMSE=309.919\n",
      "   48h  MAE=187.718  RMSE=347.820\n",
      "   72h  MAE=198.465  RMSE=367.385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06deca55dca4e5aa09d631507ec9b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0e9bbbaddf4b49870b54da71a1f864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss=0.268916  val_avg_MAE=175.876\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=186.728  RMSE=342.408\n",
      "   24h  MAE=154.416  RMSE=309.196\n",
      "   48h  MAE=171.948  RMSE=328.877\n",
      "   72h  MAE=190.413  RMSE=357.469\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be87cd92ff8443796bbc85255e98952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2ee564a5b64113ac9e02ed39401539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss=0.257975  val_avg_MAE=170.299\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=184.271  RMSE=338.048\n",
      "   24h  MAE=148.209  RMSE=299.617\n",
      "   48h  MAE=168.291  RMSE=323.040\n",
      "   72h  MAE=180.426  RMSE=343.043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8a08f28ea04bf193504fbf316bf607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef25c89d44c47c3bdfac3e06acfd025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss=0.250068  val_avg_MAE=164.475\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=162.037  RMSE=303.679\n",
      "   24h  MAE=150.514  RMSE=301.402\n",
      "   48h  MAE=164.907  RMSE=316.562\n",
      "   72h  MAE=180.444  RMSE=343.314\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221d56ecd7bf48158f7c8e6c7fccf845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10d31b6ed954c099a6f40153beea0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss=0.244371  val_avg_MAE=167.873\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=164.548  RMSE=308.877\n",
      "   24h  MAE=156.601  RMSE=304.825\n",
      "   48h  MAE=176.487  RMSE=327.605\n",
      "   72h  MAE=173.856  RMSE=331.363\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc03844fc2e499a994cf2d2e8723459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5121344730d45cca619fc294c6a65ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss=0.239806  val_avg_MAE=160.063\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=160.283  RMSE=302.982\n",
      "   24h  MAE=148.200  RMSE=298.973\n",
      "   48h  MAE=161.825  RMSE=314.139\n",
      "   72h  MAE=169.943  RMSE=325.858\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe87bf5bcf0d458080d7970e67f046ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e70d0d3058c4b2e96963a75d951c006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss=0.234704  val_avg_MAE=163.708\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=158.480  RMSE=303.029\n",
      "   24h  MAE=158.671  RMSE=308.487\n",
      "   48h  MAE=163.579  RMSE=313.825\n",
      "   72h  MAE=174.101  RMSE=332.094\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1c22d395b441018b83008d3e3bae4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208b7bf85e04448d8fd6b1cb9670adca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss=0.234201  val_avg_MAE=155.655\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=153.175  RMSE=294.953\n",
      "   24h  MAE=141.512  RMSE=293.586\n",
      "   48h  MAE=159.561  RMSE=315.417\n",
      "   72h  MAE=168.371  RMSE=323.676\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d981020918f49f2b4eb1c6be10ab020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0863d122755d440b8aa7f42a953e9943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_loss=0.231096  val_avg_MAE=154.549\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=152.754  RMSE=293.402\n",
      "   24h  MAE=139.974  RMSE=287.064\n",
      "   48h  MAE=157.335  RMSE=307.804\n",
      "   72h  MAE=168.134  RMSE=323.799\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ebd152c3c94941814572045d6a0646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb14cd1a94e4b60b0e3d9db38cd1980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_loss=0.229034  val_avg_MAE=164.792\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=151.243  RMSE=291.496\n",
      "   24h  MAE=147.712  RMSE=297.619\n",
      "   48h  MAE=167.106  RMSE=321.370\n",
      "   72h  MAE=193.109  RMSE=358.011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71483139dfd4492193841d2d40300a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b5cf6455764f83900159e26f91a438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_loss=0.223892  val_avg_MAE=164.343\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=148.523  RMSE=289.870\n",
      "   24h  MAE=146.654  RMSE=296.672\n",
      "   48h  MAE=173.357  RMSE=328.243\n",
      "   72h  MAE=188.839  RMSE=347.545\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4932205875a843888c1c00ad43dfa3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d5da2bbe944fcca18e36d44f3fa7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_loss=0.222705  val_avg_MAE=166.283\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=153.376  RMSE=294.916\n",
      "   24h  MAE=155.567  RMSE=312.574\n",
      "   48h  MAE=176.343  RMSE=332.107\n",
      "   72h  MAE=179.847  RMSE=333.986\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe223285f59049948fae5bcdfbca00a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f13fc0332146d5a5f1627fcab5ba7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_loss=0.221832  val_avg_MAE=163.332\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=169.177  RMSE=314.841\n",
      "   24h  MAE=143.233  RMSE=290.326\n",
      "   48h  MAE=168.777  RMSE=325.777\n",
      "   72h  MAE=172.140  RMSE=329.309\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732e182a6ff14a22b91901bb24989380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95238e9cc1f346f3aaad86a8acd8456f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_loss=0.221454  val_avg_MAE=155.481\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=144.691  RMSE=279.696\n",
      "   24h  MAE=139.187  RMSE=284.711\n",
      "   48h  MAE=161.616  RMSE=311.975\n",
      "   72h  MAE=176.428  RMSE=331.767\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35154a1017dd48a38e86a9d2b076f1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/30:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f0e536b7c3405eb42729c619559838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_loss=0.217759  val_avg_MAE=155.037\n",
      "\n",
      "Val metrics\n",
      "   12h  MAE=151.572  RMSE=293.354\n",
      "   24h  MAE=139.192  RMSE=286.145\n",
      "   48h  MAE=161.421  RMSE=316.536\n",
      "   72h  MAE=167.963  RMSE=321.738\n",
      "Early stopping at epoch 17. Best val_avg_MAE=154.549\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0eebe30e2b4417b5d1366a8e47ad89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1014d6bab2704946b74a6266db129349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GraphWaveNet — Validation\n",
      "   12h  MAE=152.754  RMSE=293.402\n",
      "   24h  MAE=139.974  RMSE=287.064\n",
      "   48h  MAE=157.335  RMSE=307.804\n",
      "   72h  MAE=168.134  RMSE=323.799\n",
      "\n",
      "GraphWaveNet — Test\n",
      "   12h  MAE=156.900  RMSE=298.198\n",
      "   24h  MAE=134.966  RMSE=269.862\n",
      "   48h  MAE=153.469  RMSE=300.160\n",
      "   72h  MAE=161.221  RMSE=310.938\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# tensors for unscaling (put on device once)\n",
    "flow_mean_t = torch.tensor(flow_mean, dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "flow_std_t  = torch.tensor(flow_std,  dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "\n",
    "EVAL_HORIZONS = [12, 24, 48, 72]\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_horizons(model, loader):\n",
    "    model.eval()\n",
    "    acc = {h: {\"abs\": 0.0, \"sq\": 0.0, \"count\": 0} for h in EVAL_HORIZONS}\n",
    "\n",
    "    for xb, yb in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        xb = xb.to(DEVICE, non_blocking=True)   # (B,F,N,T)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)   # (B,OUT,N) scaled\n",
    "\n",
    "        pred = model(xb)                        # (B,OUT,N) scaled\n",
    "\n",
    "        # unscale to original flow units\n",
    "        pred_u = pred * flow_std_t + flow_mean_t\n",
    "        true_u = yb   * flow_std_t + flow_mean_t\n",
    "\n",
    "        for h in EVAL_HORIZONS:\n",
    "            idx = h - 1\n",
    "            err = pred_u[:, idx, :] - true_u[:, idx, :]\n",
    "            acc[h][\"abs\"] += float(err.abs().sum())\n",
    "            acc[h][\"sq\"]  += float((err ** 2).sum())\n",
    "            acc[h][\"count\"] += err.numel()\n",
    "\n",
    "    metrics = {}\n",
    "    for h in EVAL_HORIZONS:\n",
    "        mae = acc[h][\"abs\"] / acc[h][\"count\"]\n",
    "        rmse = (acc[h][\"sq\"] / acc[h][\"count\"]) ** 0.5\n",
    "        metrics[h] = {\"MAE\": mae, \"RMSE\": rmse}\n",
    "    return metrics\n",
    "\n",
    "def print_metrics(title, metrics):\n",
    "    print(\"\\n\" + title)\n",
    "    for h in sorted(metrics.keys()):\n",
    "        print(f\"  {h:>3}h  MAE={metrics[h]['MAE']:.3f}  RMSE={metrics[h]['RMSE']:.3f}\")\n",
    "\n",
    "def avg_mae(metrics):\n",
    "    return float(np.mean([metrics[h][\"MAE\"] for h in metrics]))\n",
    "\n",
    "def train_gwn(\n",
    "    epochs=30,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    clip=5.0,\n",
    "    patience=6,\n",
    "):\n",
    "    model = GraphWaveNet(\n",
    "        num_nodes=X.shape[1],\n",
    "        in_dim=X.shape[2],     # 6 features\n",
    "        out_len=OUT_LEN,\n",
    "        supports=supports,\n",
    "        residual_channels=32,\n",
    "        dilation_channels=32,\n",
    "        skip_channels=64,\n",
    "        end_channels=128,\n",
    "        kernel_size=2,\n",
    "        blocks=2,\n",
    "        layers_per_block=3,\n",
    "        gcn_order=1,\n",
    "        dropout=0.3,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    use_amp = False\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=False)\n",
    "\n",
    "    best_score = float(\"inf\")\n",
    "    best_state = None\n",
    "    bad = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "\n",
    "        for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False):\n",
    "            xb = xb.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                pred = model(xb)\n",
    "                loss = loss_fn(pred, yb)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "\n",
    "            running += float(loss.item())\n",
    "\n",
    "        # validation metrics (original scale)\n",
    "        val_metrics = eval_horizons(model, val_loader)\n",
    "        score = avg_mae(val_metrics)\n",
    "\n",
    "        print(f\"Epoch {epoch}: train_loss={running/len(train_loader):.6f}  val_avg_MAE={score:.3f}\")\n",
    "        print_metrics(\"Val metrics\", val_metrics)\n",
    "\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}. Best val_avg_MAE={best_score:.3f}\")\n",
    "                break\n",
    "\n",
    "    # load best\n",
    "    model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "gwn_model = train_gwn(epochs=30, lr=1e-3, weight_decay=1e-4, clip=5.0, patience=6)\n",
    "\n",
    "# Final evaluation\n",
    "val_m = eval_horizons(gwn_model, val_loader)\n",
    "test_m = eval_horizons(gwn_model, test_loader)\n",
    "\n",
    "print_metrics(\"GraphWaveNet — Validation\", val_m)\n",
    "print_metrics(\"GraphWaveNet — Test\", test_m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91367f4-27d1-49f3-92b9-469349e7b184",
   "metadata": {},
   "source": [
    "# GraphWaveNet Baseline (Journal-Grade) - Working on it again\n",
    "\n",
    "This notebook section trains a strong GraphWaveNet baseline on PeMS using:\n",
    "- Strict train/val/test window splits (no horizon leakage)\n",
    "- Direction-aware adjacency: edges only within same freeway AND same direction\n",
    "- Known future calendar covariates (hour-of-day/day-of-week), which are available at forecast time\n",
    "- Multi-horizon evaluation at 12/24/48/72 hours\n",
    "\n",
    "Outputs:\n",
    "- Validation and test MAE/RMSE at each horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25fa62ce-4074-4dbb-a733-6ac61f525cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T18:24:04.335500Z",
     "iopub.status.busy": "2026-02-08T18:24:04.334984Z",
     "iopub.status.idle": "2026-02-08T18:24:04.394065Z",
     "shell.execute_reply": "2026-02-08T18:24:04.393236Z",
     "shell.execute_reply.started": "2026-02-08T18:24:04.335476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.1.1+cu121\n",
      "Device: cuda\n",
      "GPU: Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Device:\", DEVICE)\n",
    "if DEVICE == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b060ac7e-7976-46c8-af82-ff35c5da77be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T18:24:09.025784Z",
     "iopub.status.busy": "2026-02-08T18:24:09.025118Z",
     "iopub.status.idle": "2026-02-08T18:24:09.607093Z",
     "shell.execute_reply": "2026-02-08T18:24:09.606509Z",
     "shell.execute_reply.started": "2026-02-08T18:24:09.025759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (2208, 1821, 6) Y: (2208, 1821)\n",
      "N stations: 1821 T: 2208\n",
      "starts: 1009 289 673\n",
      "IN_LEN: 24 OUT_LEN: 72\n"
     ]
    }
   ],
   "source": [
    "DATASET_BASE = Path(\"artifacts/pems_graph_dataset.npz\")\n",
    "DATASET_STRICT = Path(\"artifacts/pems_graph_dataset_strict.npz\")\n",
    "\n",
    "TRAIN_END = pd.Timestamp(\"2024-11-15 23:59:59\")\n",
    "VAL_END   = pd.Timestamp(\"2024-11-30 23:59:59\")\n",
    "\n",
    "def make_strict_dataset(base_npz: Path, strict_npz: Path):\n",
    "    d = np.load(base_npz, allow_pickle=True)\n",
    "\n",
    "    X = d[\"X\"]; Y = d[\"Y\"]; A = d[\"A\"]\n",
    "    stations = d[\"stations\"]\n",
    "    timestamps = pd.to_datetime(d[\"timestamps\"])\n",
    "    IN_LEN = int(d[\"in_len\"][0])\n",
    "    OUT_LEN = int(d[\"out_len\"][0])\n",
    "\n",
    "    flow_mean = d[\"flow_mean\"]; flow_std = d[\"flow_std\"]\n",
    "    speed_mean = d[\"speed_mean\"]; speed_std = d[\"speed_std\"]\n",
    "\n",
    "    T_total = X.shape[0]\n",
    "    max_t = T_total - (IN_LEN + OUT_LEN) + 1\n",
    "    starts = np.arange(max_t, dtype=np.int32)\n",
    "\n",
    "    out_start_times = timestamps[starts + IN_LEN]\n",
    "    out_end_times   = timestamps[starts + IN_LEN + OUT_LEN - 1]\n",
    "\n",
    "    train_starts = starts[out_end_times <= TRAIN_END]\n",
    "    val_starts   = starts[(out_start_times > TRAIN_END) & (out_end_times <= VAL_END)]\n",
    "    test_starts  = starts[out_start_times > VAL_END]\n",
    "\n",
    "    np.savez_compressed(\n",
    "        strict_npz,\n",
    "        X=X.astype(np.float32),\n",
    "        Y=Y.astype(np.float32),\n",
    "        A=A.astype(np.float32),\n",
    "        stations=stations.astype(np.int32),\n",
    "        timestamps=np.array(timestamps.astype(\"datetime64[ns]\")),\n",
    "        train_starts=train_starts,\n",
    "        val_starts=val_starts,\n",
    "        test_starts=test_starts,\n",
    "        in_len=np.array([IN_LEN], dtype=np.int32),\n",
    "        out_len=np.array([OUT_LEN], dtype=np.int32),\n",
    "        flow_mean=flow_mean.astype(np.float32),\n",
    "        flow_std=flow_std.astype(np.float32),\n",
    "        speed_mean=speed_mean.astype(np.float32),\n",
    "        speed_std=speed_std.astype(np.float32),\n",
    "        seed=np.array([SEED], dtype=np.int32),\n",
    "    )\n",
    "    print(\"Saved strict dataset:\", strict_npz)\n",
    "\n",
    "if (not DATASET_STRICT.exists()) and DATASET_BASE.exists():\n",
    "    make_strict_dataset(DATASET_BASE, DATASET_STRICT)\n",
    "\n",
    "assert DATASET_STRICT.exists(), \"Strict dataset not found. Make sure artifacts are created.\"\n",
    "\n",
    "d = np.load(DATASET_STRICT, allow_pickle=True)\n",
    "X = d[\"X\"]                      # (T,N,F)\n",
    "Y = d[\"Y\"]                      # (T,N)\n",
    "stations = d[\"stations\"]        # (N,)\n",
    "timestamps = pd.to_datetime(d[\"timestamps\"])\n",
    "\n",
    "train_starts = d[\"train_starts\"]\n",
    "val_starts   = d[\"val_starts\"]\n",
    "test_starts  = d[\"test_starts\"]\n",
    "\n",
    "IN_LEN = int(d[\"in_len\"][0])\n",
    "OUT_LEN = int(d[\"out_len\"][0])\n",
    "\n",
    "flow_mean = d[\"flow_mean\"]\n",
    "flow_std  = d[\"flow_std\"]\n",
    "speed_mean = d[\"speed_mean\"]\n",
    "speed_std  = d[\"speed_std\"]\n",
    "\n",
    "print(\"X:\", X.shape, \"Y:\", Y.shape)\n",
    "print(\"N stations:\", len(stations), \"T:\", len(timestamps))\n",
    "print(\"starts:\", len(train_starts), len(val_starts), len(test_starts))\n",
    "print(\"IN_LEN:\", IN_LEN, \"OUT_LEN:\", OUT_LEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a7af3-fea0-4595-af1a-0905b94a7143",
   "metadata": {},
   "source": [
    "## Direction-aware adjacency (recommended baseline graph)\n",
    "\n",
    "We build edges only among sensors that share:\n",
    "- the same freeway (Fwy)\n",
    "- the same direction of travel (Direction of Travel)\n",
    "sorted by Abs PM.\n",
    "\n",
    "This avoids mixing opposite-direction stations, which often destroys graph model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12650ee2-2402-4821-932a-53c80bd6fcc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T18:24:15.611058Z",
     "iopub.status.busy": "2026-02-08T18:24:15.610347Z",
     "iopub.status.idle": "2026-02-08T18:24:23.404133Z",
     "shell.execute_reply": "2026-02-08T18:24:23.403401Z",
     "shell.execute_reply.started": "2026-02-08T18:24:15.611025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direction mapping coverage: 1.0\n",
      "Direction counts:\n",
      " direction\n",
      "E    509\n",
      "W    499\n",
      "S    410\n",
      "N    403\n",
      "Name: count, dtype: int64\n",
      "A_dir shape: (1821, 1821)\n",
      "A_dir density: 0.0038374073179432942\n",
      "Supports nnz: [12720, 12720]\n"
     ]
    }
   ],
   "source": [
    "TRAFFIC_CSV = Path(\"cleaned_traffic_data.csv\")\n",
    "META_XLSX   = Path(\"pems_output.xlsx\")\n",
    "\n",
    "assert TRAFFIC_CSV.exists(), \"cleaned_traffic_data.csv not found in working directory.\"\n",
    "assert META_XLSX.exists(), \"pems_output.xlsx not found in working directory.\"\n",
    "\n",
    "# 1) station -> direction mapping (mode direction per station)\n",
    "tmp = pd.read_csv(TRAFFIC_CSV, usecols=[\"Station\", \"Direction of Travel\"])\n",
    "tmp = tmp.rename(columns={\"Station\": \"station\", \"Direction of Travel\": \"direction\"})\n",
    "tmp[\"station\"] = pd.to_numeric(tmp[\"station\"], errors=\"coerce\").astype(\"Int64\")\n",
    "tmp = tmp.dropna(subset=[\"station\"])\n",
    "tmp[\"station\"] = tmp[\"station\"].astype(int)\n",
    "\n",
    "station_dir = tmp.groupby(\"station\")[\"direction\"].agg(lambda x: x.mode().iloc[0] if len(x.mode()) else x.iloc[0])\n",
    "station_dir = station_dir.reindex(stations)\n",
    "\n",
    "print(\"Direction mapping coverage:\", float(station_dir.notna().mean()))\n",
    "print(\"Direction counts:\\n\", station_dir.value_counts(dropna=False))\n",
    "\n",
    "# 2) metadata\n",
    "meta = pd.read_excel(META_XLSX)\n",
    "# your metadata already has \"station\" column (from your earlier merge output)\n",
    "if \"station\" not in meta.columns and \"ID\" in meta.columns:\n",
    "    meta = meta.rename(columns={\"ID\": \"station\"})\n",
    "meta[\"station\"] = pd.to_numeric(meta[\"station\"], errors=\"coerce\").astype(\"Int64\")\n",
    "meta = meta.dropna(subset=[\"station\"])\n",
    "meta[\"station\"] = meta[\"station\"].astype(int)\n",
    "\n",
    "assert \"Fwy\" in meta.columns and \"Abs PM\" in meta.columns, \"Metadata must contain 'Fwy' and 'Abs PM'.\"\n",
    "\n",
    "def build_adjacency_fwy_dir(meta_df, stations, station_dir, k_neighbors=4):\n",
    "    meta_sub = meta_df[meta_df[\"station\"].isin(stations)].copy()\n",
    "    meta_sub[\"fwy\"] = meta_sub[\"Fwy\"].astype(str)\n",
    "    meta_sub[\"abs_pm\"] = pd.to_numeric(meta_sub[\"Abs PM\"], errors=\"coerce\")\n",
    "    meta_sub[\"direction\"] = meta_sub[\"station\"].map(station_dir)\n",
    "\n",
    "    # If direction missing, we exclude from neighbor edges (but keep self-loop later)\n",
    "    meta_sub = meta_sub.dropna(subset=[\"abs_pm\", \"direction\"]).copy()\n",
    "    meta_sub[\"direction\"] = meta_sub[\"direction\"].astype(str)\n",
    "\n",
    "    station_to_idx = {s: i for i, s in enumerate(stations)}\n",
    "    N = len(stations)\n",
    "    A = np.zeros((N, N), dtype=np.float32)\n",
    "\n",
    "    # sigma from typical neighbor distances\n",
    "    all_dists = []\n",
    "    for (fwy, direc), grp in meta_sub.sort_values([\"fwy\", \"direction\", \"abs_pm\"]).groupby([\"fwy\", \"direction\"]):\n",
    "        pm = grp[\"abs_pm\"].values\n",
    "        if len(pm) < 2:\n",
    "            continue\n",
    "        d = np.diff(np.sort(pm))\n",
    "        d = d[d > 0]\n",
    "        all_dists.extend(d.tolist())\n",
    "\n",
    "    sigma = float(np.median(all_dists)) if len(all_dists) else 0.5\n",
    "    sigma = max(sigma, 1e-3)\n",
    "\n",
    "    def w(dist):\n",
    "        return float(np.exp(- (dist**2) / (sigma**2)))\n",
    "\n",
    "    for (fwy, direc), grp in meta_sub.sort_values([\"fwy\", \"direction\", \"abs_pm\"]).groupby([\"fwy\", \"direction\"]):\n",
    "        grp = grp.sort_values(\"abs_pm\")\n",
    "        ids = grp[\"station\"].astype(int).tolist()\n",
    "        pms = grp[\"abs_pm\"].astype(float).tolist()\n",
    "\n",
    "        for i, sid in enumerate(ids):\n",
    "            ii = station_to_idx[sid]\n",
    "            for step in range(1, k_neighbors + 1):\n",
    "                if i - step >= 0:\n",
    "                    sj = ids[i-step]; jj = station_to_idx[sj]\n",
    "                    A[ii, jj] = w(abs(pms[i] - pms[i-step]))\n",
    "                if i + step < len(ids):\n",
    "                    sj = ids[i+step]; jj = station_to_idx[sj]\n",
    "                    A[ii, jj] = w(abs(pms[i] - pms[i+step]))\n",
    "\n",
    "    np.fill_diagonal(A, 1.0)\n",
    "    A = np.maximum(A, A.T)\n",
    "    return A\n",
    "\n",
    "A_dir = build_adjacency_fwy_dir(meta, stations, station_dir, k_neighbors=4)\n",
    "print(\"A_dir shape:\", A_dir.shape)\n",
    "print(\"A_dir density:\", float((A_dir > 0).mean()))\n",
    "\n",
    "def row_normalize_dense(A, eps=1e-6):\n",
    "    d = A.sum(axis=1, keepdims=True)\n",
    "    return A / (d + eps)\n",
    "\n",
    "def dense_to_sparse(A, device):\n",
    "    idx = np.nonzero(A)\n",
    "    values = A[idx].astype(np.float32)\n",
    "    indices = np.vstack(idx)\n",
    "    return torch.sparse_coo_tensor(\n",
    "        torch.tensor(indices, dtype=torch.long, device=device),\n",
    "        torch.tensor(values, dtype=torch.float32, device=device),\n",
    "        size=A.shape,\n",
    "        device=device\n",
    "    ).coalesce()\n",
    "\n",
    "A_rw  = row_normalize_dense(A_dir)\n",
    "A_rwT = row_normalize_dense(A_dir.T)\n",
    "\n",
    "supports = [dense_to_sparse(A_rw, DEVICE), dense_to_sparse(A_rwT, DEVICE)]\n",
    "print(\"Supports nnz:\", [int(s._nnz()) for s in supports])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0906678f-e4a6-4fcf-8218-b77fc031c3f0",
   "metadata": {},
   "source": [
    "## Dataset and loaders\n",
    "\n",
    "Each sample returns:\n",
    "- x:  (F, N, IN_LEN)\n",
    "- y:  (OUT_LEN, N)  scaled flow target\n",
    "- tf: (OUT_LEN, 4)  known future calendar covariates (hour/dow sin/cos)\n",
    "\n",
    "We compute tf from timestamps (not from future traffic), so it is NOT leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99606c21-0b57-4cdd-bd70-aefb2368818b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T18:24:31.629756Z",
     "iopub.status.busy": "2026-02-08T18:24:31.629441Z",
     "iopub.status.idle": "2026-02-08T18:24:31.679859Z",
     "shell.execute_reply": "2026-02-08T18:24:31.679019Z",
     "shell.execute_reply.started": "2026-02-08T18:24:31.629730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x: torch.Size([8, 6, 1821, 24]) Batch y: torch.Size([8, 72, 1821]) Batch tf: torch.Size([8, 72, 4])\n"
     ]
    }
   ],
   "source": [
    "def time_encoding(dt_index: pd.DatetimeIndex) -> np.ndarray:\n",
    "    hours = dt_index.hour.values\n",
    "    dow   = dt_index.dayofweek.values\n",
    "    hour_sin = np.sin(2*np.pi*hours/24.0)\n",
    "    hour_cos = np.cos(2*np.pi*hours/24.0)\n",
    "    dow_sin  = np.sin(2*np.pi*dow/7.0)\n",
    "    dow_cos  = np.cos(2*np.pi*dow/7.0)\n",
    "    return np.stack([hour_sin, hour_cos, dow_sin, dow_cos], axis=1).astype(np.float32)  # (T,4)\n",
    "\n",
    "class PemsWindowDatasetTF(Dataset):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      x:  (F, N, IN_LEN)\n",
    "      y:  (OUT_LEN, N) scaled\n",
    "      tf: (OUT_LEN, 4) known future time features\n",
    "    \"\"\"\n",
    "    def __init__(self, X, Y, timestamps, starts, in_len, out_len,\n",
    "                 flow_mean, flow_std, speed_mean, speed_std):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.timestamps = pd.DatetimeIndex(timestamps)\n",
    "        self.starts = starts.astype(np.int32)\n",
    "        self.in_len = int(in_len)\n",
    "        self.out_len = int(out_len)\n",
    "\n",
    "        self.flow_mean = flow_mean.astype(np.float32)\n",
    "        self.flow_std  = flow_std.astype(np.float32)\n",
    "        self.speed_mean = speed_mean.astype(np.float32)\n",
    "        self.speed_std  = speed_std.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.starts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = int(self.starts[idx])\n",
    "\n",
    "        x = self.X[t:t+self.in_len].copy().astype(np.float32)  # (IN_LEN, N, F)\n",
    "        y = self.Y[t+self.in_len:t+self.in_len+self.out_len].copy().astype(np.float32)  # (OUT_LEN, N)\n",
    "\n",
    "        ts_future = self.timestamps[t+self.in_len:t+self.in_len+self.out_len]\n",
    "        tf = time_encoding(ts_future)  # (OUT_LEN, 4)\n",
    "\n",
    "        # scale inputs: flow=0 speed=1\n",
    "        x[..., 0] = (x[..., 0] - self.flow_mean[None, :]) / self.flow_std[None, :]\n",
    "        x[..., 1] = (x[..., 1] - self.speed_mean[None, :]) / self.speed_std[None, :]\n",
    "\n",
    "        # scale targets (flow)\n",
    "        y = (y - self.flow_mean[None, :]) / self.flow_std[None, :]\n",
    "\n",
    "        # (IN_LEN, N, F) -> (F, N, IN_LEN)\n",
    "        x = np.transpose(x, (2, 1, 0))\n",
    "\n",
    "        return torch.from_numpy(x), torch.from_numpy(y), torch.from_numpy(tf)\n",
    "\n",
    "# Safer batch size for GraphWaveNet on N=1821\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_ds = PemsWindowDatasetTF(X, Y, timestamps, train_starts, IN_LEN, OUT_LEN, flow_mean, flow_std, speed_mean, speed_std)\n",
    "val_ds   = PemsWindowDatasetTF(X, Y, timestamps, val_starts,   IN_LEN, OUT_LEN, flow_mean, flow_std, speed_mean, speed_std)\n",
    "test_ds  = PemsWindowDatasetTF(X, Y, timestamps, test_starts,  IN_LEN, OUT_LEN, flow_mean, flow_std, speed_mean, speed_std)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "print(\"Batch x:\", xb.shape, \"Batch y:\", yb.shape, \"Batch tf:\", tfb.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfec408-6279-4717-901b-66fc4c51aa30",
   "metadata": {},
   "source": [
    "## GraphWaveNet baseline (sparse diffusion graph conv + dilated temporal conv)\n",
    "\n",
    "We:\n",
    "- use causal dilated temporal convolutions + gating\n",
    "- do sparse graph propagation with the supports\n",
    "- use residual + skip connections\n",
    "- use a time-aware output head with future calendar covariates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe61380b-ab8f-4410-aa56-2b71c8416a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T18:24:38.377957Z",
     "iopub.status.busy": "2026-02-08T18:24:38.377596Z",
     "iopub.status.idle": "2026-02-08T18:24:38.396662Z",
     "shell.execute_reply": "2026-02-08T18:24:38.395872Z",
     "shell.execute_reply.started": "2026-02-08T18:24:38.377931Z"
    }
   },
   "outputs": [],
   "source": [
    "class NConv(nn.Module):\n",
    "    \"\"\"Sparse graph multiplication: (N,N) @ (B,C,N,T) -> (B,C,N,T)\"\"\"\n",
    "    def forward(self, x, A_sp):\n",
    "        B, C, N, T = x.shape\n",
    "        x_r = x.permute(2, 0, 1, 3).reshape(N, -1)  # (N, B*C*T)\n",
    "\n",
    "        # sparse.mm requires float32 on cuda reliably\n",
    "        out = torch.sparse.mm(A_sp, x_r.float())\n",
    "        out = out.reshape(N, B, C, T).permute(1, 2, 0, 3)\n",
    "        return out.to(dtype=x.dtype)\n",
    "\n",
    "class DiffusionGraphConv(nn.Module):\n",
    "    def __init__(self, c_in, c_out, supports, order=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.nconv = NConv()\n",
    "        self.supports = supports\n",
    "        self.order = order\n",
    "        self.dropout = dropout\n",
    "\n",
    "        c_total = c_in * (1 + len(supports) * order)\n",
    "        self.mlp = nn.Conv2d(c_total, c_out, kernel_size=(1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = [x]\n",
    "        for A in self.supports:\n",
    "            x1 = self.nconv(x, A)\n",
    "            out.append(x1)\n",
    "            for _ in range(2, self.order + 1):\n",
    "                x1 = self.nconv(x1, A)\n",
    "                out.append(x1)\n",
    "\n",
    "        h = torch.cat(out, dim=1)\n",
    "        h = self.mlp(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        return h\n",
    "\n",
    "class CausalConv2d(nn.Module):\n",
    "    \"\"\"Causal conv along time axis only.\"\"\"\n",
    "    def __init__(self, c_in, c_out, kernel_size=2, dilation=1):\n",
    "        super().__init__()\n",
    "        self.pad = (kernel_size - 1) * dilation\n",
    "        self.conv = nn.Conv2d(c_in, c_out, kernel_size=(1, kernel_size), dilation=(1, dilation))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (self.pad, 0, 0, 0))\n",
    "        return self.conv(x)\n",
    "\n",
    "class GraphWaveNetTimeAware(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes,\n",
    "        in_dim,\n",
    "        out_len,\n",
    "        supports,\n",
    "        residual_channels=32,\n",
    "        dilation_channels=32,\n",
    "        skip_channels=64,\n",
    "        end_channels=128,\n",
    "        kernel_size=2,\n",
    "        blocks=2,\n",
    "        layers_per_block=4,   # ensures receptive field >= 24\n",
    "        gcn_order=1,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.in_dim = in_dim\n",
    "        self.out_len = out_len\n",
    "        self.dropout = dropout\n",
    "        self.kernel_size = kernel_size\n",
    "        self.blocks = blocks\n",
    "        self.layers_per_block = layers_per_block\n",
    "\n",
    "        # receptive field\n",
    "        receptive_field = 1\n",
    "        for _ in range(blocks):\n",
    "            for i in range(layers_per_block):\n",
    "                receptive_field += (kernel_size - 1) * (2 ** i)\n",
    "        self.receptive_field = receptive_field\n",
    "\n",
    "        self.start_conv = nn.Conv2d(in_dim, residual_channels, kernel_size=(1, 1))\n",
    "\n",
    "        self.filter_convs = nn.ModuleList()\n",
    "        self.gate_convs   = nn.ModuleList()\n",
    "        self.skip_convs   = nn.ModuleList()\n",
    "        self.bn           = nn.ModuleList()\n",
    "        self.gconvs       = nn.ModuleList()\n",
    "\n",
    "        for _ in range(blocks):\n",
    "            for i in range(layers_per_block):\n",
    "                dilation = 2 ** i\n",
    "                self.filter_convs.append(CausalConv2d(residual_channels, dilation_channels, kernel_size, dilation))\n",
    "                self.gate_convs.append(CausalConv2d(residual_channels, dilation_channels, kernel_size, dilation))\n",
    "\n",
    "                self.skip_convs.append(nn.Conv2d(dilation_channels, skip_channels, kernel_size=(1, 1)))\n",
    "                self.gconvs.append(DiffusionGraphConv(dilation_channels, residual_channels, supports, order=gcn_order, dropout=dropout))\n",
    "                self.bn.append(nn.BatchNorm2d(residual_channels))\n",
    "\n",
    "        self.end_conv_1 = nn.Conv2d(skip_channels, end_channels, kernel_size=(1, 1))\n",
    "\n",
    "        # time-aware head\n",
    "        self.time_embed = nn.Linear(4, end_channels)\n",
    "        self.horizon_out = nn.Linear(end_channels, 1)\n",
    "\n",
    "    def forward(self, x, tf_future):\n",
    "        \"\"\"\n",
    "        x:        (B, F, N, IN_LEN)\n",
    "        tf_future:(B, OUT_LEN, 4)\n",
    "        out:      (B, OUT_LEN, N)\n",
    "        \"\"\"\n",
    "        # pad input if needed to match receptive field\n",
    "        if x.size(-1) < self.receptive_field:\n",
    "            pad_len = self.receptive_field - x.size(-1)\n",
    "            x = F.pad(x, (pad_len, 0, 0, 0))\n",
    "\n",
    "        x = self.start_conv(x)  # (B, residual, N, T)\n",
    "        skip = None\n",
    "\n",
    "        for i in range(len(self.filter_convs)):\n",
    "            residual = x\n",
    "\n",
    "            filt = torch.tanh(self.filter_convs[i](x))\n",
    "            gate = torch.sigmoid(self.gate_convs[i](x))\n",
    "            x = filt * gate\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "            s = self.skip_convs[i](x)\n",
    "            skip = s if skip is None else (skip + s)\n",
    "\n",
    "            x = self.gconvs[i](x)\n",
    "            x = x + residual\n",
    "            x = self.bn[i](x)\n",
    "\n",
    "        x = F.relu(skip)\n",
    "        x = F.relu(self.end_conv_1(x))     # (B, end_channels, N, T)\n",
    "\n",
    "        z = x[..., -1]                     # (B, end_channels, N)\n",
    "        z = z.permute(0, 2, 1)             # (B, N, end_channels)\n",
    "\n",
    "        te = self.time_embed(tf_future)    # (B, OUT_LEN, end_channels)\n",
    "\n",
    "        h = F.relu(z.unsqueeze(1) + te.unsqueeze(2))  # (B, OUT_LEN, N, end_channels)\n",
    "        out = self.horizon_out(h).squeeze(-1)         # (B, OUT_LEN, N)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9401fe2-eea4-46ed-8ec2-96289780940a",
   "metadata": {},
   "source": [
    "## Training + evaluation\n",
    "\n",
    "- Loss: SmoothL1 (Huber) on SCALED targets\n",
    "- Metrics: MAE/RMSE on ORIGINAL scale\n",
    "- Early stopping on average validation MAE (across horizons)\n",
    "- AMP disabled (sparse graph ops do not support fp16 reliably)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a40363-ba7f-456f-8e7b-b1fb10bd5445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T17:57:10.289562Z",
     "iopub.status.busy": "2026-02-08T17:57:10.289281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9c82216663447cb2da7aa94f753016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705a3abde2f345af92cb80649b9caa8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: train_loss=0.166336  val_avg_MAE=192.611\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=191.403  RMSE=358.438\n",
      "   24h  MAE=189.733  RMSE=363.071\n",
      "   48h  MAE=196.351  RMSE=372.638\n",
      "   72h  MAE=192.957  RMSE=360.658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c54d87b9f3f4dd9ba4665da40fbb554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084d6828f8724d7d9ffdd13de342d264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.117438  val_avg_MAE=189.943\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=182.940  RMSE=338.154\n",
      "   24h  MAE=187.478  RMSE=348.945\n",
      "   48h  MAE=195.416  RMSE=359.328\n",
      "   72h  MAE=193.937  RMSE=352.510\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf8a38fa4c14f6391bb8deef93f686e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EVAL_HORIZONS = [12, 24, 48, 72]\n",
    "\n",
    "flow_mean_t = torch.tensor(flow_mean, dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "flow_std_t  = torch.tensor(flow_std,  dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_horizons(model, loader):\n",
    "    model.eval()\n",
    "    acc = {h: {\"abs\": 0.0, \"sq\": 0.0, \"count\": 0} for h in EVAL_HORIZONS}\n",
    "\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        pred = model(xb, tfb)  # scaled\n",
    "\n",
    "        pred_u = pred * flow_std_t + flow_mean_t\n",
    "        true_u = yb   * flow_std_t + flow_mean_t\n",
    "\n",
    "        for h in EVAL_HORIZONS:\n",
    "            idx = h - 1\n",
    "            err = pred_u[:, idx, :] - true_u[:, idx, :]\n",
    "            acc[h][\"abs\"] += float(err.abs().sum())\n",
    "            acc[h][\"sq\"]  += float((err ** 2).sum())\n",
    "            acc[h][\"count\"] += err.numel()\n",
    "\n",
    "    metrics = {}\n",
    "    for h in EVAL_HORIZONS:\n",
    "        mae = acc[h][\"abs\"] / acc[h][\"count\"]\n",
    "        rmse = (acc[h][\"sq\"] / acc[h][\"count\"]) ** 0.5\n",
    "        metrics[h] = {\"MAE\": mae, \"RMSE\": rmse}\n",
    "    return metrics\n",
    "\n",
    "def print_metrics(title, metrics):\n",
    "    print(\"\\n\" + title)\n",
    "    for h in sorted(metrics.keys()):\n",
    "        print(f\"  {h:>3}h  MAE={metrics[h]['MAE']:.3f}  RMSE={metrics[h]['RMSE']:.3f}\")\n",
    "\n",
    "def avg_mae(metrics):\n",
    "    return float(np.mean([metrics[h][\"MAE\"] for h in metrics]))\n",
    "\n",
    "def train_gwn_baseline(\n",
    "    epochs=40,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    clip=5.0,\n",
    "    patience=8,\n",
    "):\n",
    "    model = GraphWaveNetTimeAware(\n",
    "        num_nodes=X.shape[1],\n",
    "        in_dim=X.shape[2],\n",
    "        out_len=OUT_LEN,\n",
    "        supports=supports,\n",
    "        residual_channels=32,\n",
    "        dilation_channels=32,\n",
    "        skip_channels=64,\n",
    "        end_channels=128,\n",
    "        kernel_size=2,\n",
    "        blocks=2,\n",
    "        layers_per_block=4,\n",
    "        gcn_order=1,\n",
    "        dropout=0.1,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.SmoothL1Loss(beta=1.0)\n",
    "\n",
    "    best_score = float(\"inf\")\n",
    "    best_state = None\n",
    "    bad = 0\n",
    "\n",
    "    # IMPORTANT: disable AMP due to sparse graph ops\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "\n",
    "        for xb, yb, tfb in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False):\n",
    "            xb = xb.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "            tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            pred = model(xb, tfb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "\n",
    "            running += float(loss.item())\n",
    "\n",
    "        val_metrics = eval_horizons(model, val_loader)\n",
    "        score = avg_mae(val_metrics)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}: train_loss={running/len(train_loader):.6f}  val_avg_MAE={score:.3f}\")\n",
    "        print_metrics(\"Validation metrics\", val_metrics)\n",
    "\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                print(f\"\\nEarly stopping. Best val_avg_MAE={best_score:.3f}\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "gwn = train_gwn_baseline()\n",
    "\n",
    "val_m = eval_horizons(gwn, val_loader)\n",
    "test_m = eval_horizons(gwn, test_loader)\n",
    "\n",
    "print_metrics(\"GraphWaveNet Baseline — Validation\", val_m)\n",
    "print_metrics(\"GraphWaveNet Baseline — Test\", test_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f946c-7026-4c6a-9a14-7bf1180237e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_HORIZONS = [12, 24, 48, 72]\n",
    "h_idx = torch.tensor([h-1 for h in EVAL_HORIZONS], device=DEVICE)\n",
    "\n",
    "flow_std_t = torch.tensor(flow_std, dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "\n",
    "@torch.inference_mode()\n",
    "def eval_horizons_fast(model, loader):\n",
    "    model.eval()\n",
    "    acc = {h: {\"abs\": 0.0, \"sq\": 0.0, \"count\": 0} for h in EVAL_HORIZONS}\n",
    "\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Eval\", leave=True):\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        # pred, yb are SCALED\n",
    "        pred = model(xb, tfb)  # (B, OUT, N)\n",
    "\n",
    "        # Convert error to ORIGINAL units via * std\n",
    "        err = (pred[:, h_idx, :] - yb[:, h_idx, :]) * flow_std_t  # (B, H, N)\n",
    "\n",
    "        abs_err = err.abs()\n",
    "        sq_err  = err * err\n",
    "\n",
    "        for k, h in enumerate(EVAL_HORIZONS):\n",
    "            acc[h][\"abs\"]   += float(abs_err[:, k, :].sum())\n",
    "            acc[h][\"sq\"]    += float(sq_err[:, k, :].sum())\n",
    "            acc[h][\"count\"] += abs_err[:, k, :].numel()\n",
    "\n",
    "    metrics = {}\n",
    "    for h in EVAL_HORIZONS:\n",
    "        mae  = acc[h][\"abs\"] / acc[h][\"count\"]\n",
    "        rmse = (acc[h][\"sq\"] / acc[h][\"count\"]) ** 0.5\n",
    "        metrics[h] = {\"MAE\": mae, \"RMSE\": rmse}\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4749b364-909d-4efa-aa64-f015dc975372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T08:12:41.689897Z",
     "iopub.status.busy": "2026-02-08T08:12:41.689558Z",
     "iopub.status.idle": "2026-02-08T08:13:14.713574Z",
     "shell.execute_reply": "2026-02-08T08:13:14.712352Z",
     "shell.execute_reply.started": "2026-02-08T08:12:41.689873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on TEST set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7263bf4f321448dbe3823794e1ec74e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GraphWaveNet Baseline — Test\n",
      "   12h  MAE=132.135  RMSE=263.511\n",
      "   24h  MAE=132.739  RMSE=266.139\n",
      "   48h  MAE=142.070  RMSE=285.151\n",
      "   72h  MAE=146.225  RMSE=292.688\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on TEST set...\")\n",
    "test_m = eval_horizons_fast(gwn, test_loader)\n",
    "\n",
    "print_metrics(\"GraphWaveNet Baseline — Test\", test_m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf88281-66c5-4424-9a82-8dd204ab0f03",
   "metadata": {},
   "source": [
    "# GraphWaveNet-RNN Ablations\n",
    "\n",
    "We extend the GraphWaveNet encoder with optional recurrent layers applied to node embeddings:\n",
    "\n",
    "Ablations:\n",
    "1) GWN (baseline): use_gru=False, use_lstm=False\n",
    "2) GWN+GRU:       use_gru=True,  use_lstm=False\n",
    "3) GWN+LSTM:      use_gru=False, use_lstm=True\n",
    "4) GWN+GRU+LSTM:  use_gru=True,  use_lstm=True  (proposed)\n",
    "\n",
    "All experiments share:\n",
    "- same dataset, splits, adjacency, loaders\n",
    "- same evaluation horizons + metrics\n",
    "- same early stopping rule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d25732e-53ad-4bbf-a97e-8fe0d9a45d5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T18:25:26.541285Z",
     "iopub.status.busy": "2026-02-08T18:25:26.540986Z",
     "iopub.status.idle": "2026-02-08T18:25:26.558274Z",
     "shell.execute_reply": "2026-02-08T18:25:26.557478Z",
     "shell.execute_reply.started": "2026-02-08T18:25:26.541260Z"
    }
   },
   "outputs": [],
   "source": [
    "class GraphWaveNetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Returns node embeddings across time: (B, end_channels, N, T)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes,\n",
    "        in_dim,\n",
    "        supports,\n",
    "        residual_channels=32,\n",
    "        dilation_channels=32,\n",
    "        skip_channels=64,\n",
    "        end_channels=128,\n",
    "        kernel_size=2,\n",
    "        blocks=2,\n",
    "        layers_per_block=4,\n",
    "        gcn_order=1,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.kernel_size = kernel_size\n",
    "        self.blocks = blocks\n",
    "        self.layers_per_block = layers_per_block\n",
    "\n",
    "        # receptive field\n",
    "        receptive_field = 1\n",
    "        for _ in range(blocks):\n",
    "            for i in range(layers_per_block):\n",
    "                receptive_field += (kernel_size - 1) * (2 ** i)\n",
    "        self.receptive_field = receptive_field\n",
    "\n",
    "        self.start_conv = nn.Conv2d(in_dim, residual_channels, kernel_size=(1, 1))\n",
    "\n",
    "        self.filter_convs = nn.ModuleList()\n",
    "        self.gate_convs   = nn.ModuleList()\n",
    "        self.skip_convs   = nn.ModuleList()\n",
    "        self.bn           = nn.ModuleList()\n",
    "        self.gconvs       = nn.ModuleList()\n",
    "\n",
    "        for _ in range(blocks):\n",
    "            for i in range(layers_per_block):\n",
    "                dilation = 2 ** i\n",
    "                self.filter_convs.append(CausalConv2d(residual_channels, dilation_channels, kernel_size, dilation))\n",
    "                self.gate_convs.append(CausalConv2d(residual_channels, dilation_channels, kernel_size, dilation))\n",
    "\n",
    "                self.skip_convs.append(nn.Conv2d(dilation_channels, skip_channels, kernel_size=(1, 1)))\n",
    "                self.gconvs.append(DiffusionGraphConv(dilation_channels, residual_channels, supports, order=gcn_order, dropout=dropout))\n",
    "                self.bn.append(nn.BatchNorm2d(residual_channels))\n",
    "\n",
    "        self.end_conv_1 = nn.Conv2d(skip_channels, end_channels, kernel_size=(1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, F, N, IN_LEN)\n",
    "        returns: (B, end_channels, N, T)\n",
    "        \"\"\"\n",
    "        if x.size(-1) < self.receptive_field:\n",
    "            pad_len = self.receptive_field - x.size(-1)\n",
    "            x = F.pad(x, (pad_len, 0, 0, 0))\n",
    "\n",
    "        x = self.start_conv(x)\n",
    "        skip = None\n",
    "\n",
    "        for i in range(len(self.filter_convs)):\n",
    "            residual = x\n",
    "\n",
    "            filt = torch.tanh(self.filter_convs[i](x))\n",
    "            gate = torch.sigmoid(self.gate_convs[i](x))\n",
    "            x = filt * gate\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "            s = self.skip_convs[i](x)\n",
    "            skip = s if skip is None else (skip + s)\n",
    "\n",
    "            x = self.gconvs[i](x)\n",
    "            x = x + residual\n",
    "            x = self.bn[i](x)\n",
    "\n",
    "        x = F.relu(skip)\n",
    "        x = F.relu(self.end_conv_1(x))\n",
    "        return x  # (B, end_channels, N, T)\n",
    "\n",
    "\n",
    "class GraphWaveNetRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    GraphWaveNet encoder + optional GRU/LSTM over time for each node.\n",
    "    Time-aware head using future calendar covariates.\n",
    "\n",
    "    Output: (B, OUT_LEN, N)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes,\n",
    "        in_dim,\n",
    "        out_len,\n",
    "        supports,\n",
    "        end_channels=128,\n",
    "        use_gru=False,\n",
    "        use_lstm=False,\n",
    "        rnn_hidden=128,\n",
    "        dropout=0.1,\n",
    "        **encoder_kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.out_len = out_len\n",
    "        self.use_gru = use_gru\n",
    "        self.use_lstm = use_lstm\n",
    "\n",
    "        self.encoder = GraphWaveNetEncoder(\n",
    "            num_nodes=num_nodes,\n",
    "            in_dim=in_dim,\n",
    "            supports=supports,\n",
    "            end_channels=end_channels,\n",
    "            dropout=dropout,\n",
    "            **encoder_kwargs\n",
    "        )\n",
    "\n",
    "        # RNN operates on per-node sequences: (B*N, T, C)\n",
    "        if use_gru:\n",
    "            self.gru = nn.GRU(input_size=end_channels, hidden_size=rnn_hidden, batch_first=True)\n",
    "        else:\n",
    "            self.gru = None\n",
    "\n",
    "        if use_lstm:\n",
    "            self.lstm = nn.LSTM(input_size=(rnn_hidden if use_gru else end_channels),\n",
    "                                hidden_size=rnn_hidden,\n",
    "                                batch_first=True)\n",
    "        else:\n",
    "            self.lstm = None\n",
    "\n",
    "        # final node embedding size after RNN(s)\n",
    "        final_dim = rnn_hidden if (use_gru or use_lstm) else end_channels\n",
    "\n",
    "        # time-aware head\n",
    "        self.time_embed = nn.Linear(4, final_dim)\n",
    "        self.horizon_out = nn.Linear(final_dim, 1)\n",
    "\n",
    "    def forward(self, x, tf_future):\n",
    "        \"\"\"\n",
    "        x: (B, F, N, IN_LEN)\n",
    "        tf_future: (B, OUT_LEN, 4)\n",
    "        \"\"\"\n",
    "        h = self.encoder(x)              # (B, C, N, T)\n",
    "        B, C, N, T = h.shape\n",
    "\n",
    "        # Take full temporal sequence per node\n",
    "        h_seq = h.permute(0, 2, 3, 1).contiguous()   # (B, N, T, C)\n",
    "        h_seq = h_seq.view(B*N, T, C)                # (B*N, T, C)\n",
    "\n",
    "        # Optional GRU then optional LSTM\n",
    "        if self.gru is not None:\n",
    "            out_gru, _ = self.gru(h_seq)             # (B*N, T, H)\n",
    "            h_seq2 = out_gru\n",
    "        else:\n",
    "            h_seq2 = h_seq\n",
    "\n",
    "        if self.lstm is not None:\n",
    "            out_lstm, (hn, cn) = self.lstm(h_seq2)   # (B*N, T, H)\n",
    "            last = out_lstm[:, -1, :]                # (B*N, H)\n",
    "        else:\n",
    "            last = h_seq2[:, -1, :]                  # (B*N, C or H)\n",
    "\n",
    "        # Reshape back to (B, N, D)\n",
    "        z = last.view(B, N, -1)                      # (B, N, D)\n",
    "\n",
    "        # time embedding for each horizon\n",
    "        te = self.time_embed(tf_future)              # (B, OUT_LEN, D)\n",
    "\n",
    "        # combine\n",
    "        out = F.relu(z.unsqueeze(1) + te.unsqueeze(2))  # (B, OUT_LEN, N, D)\n",
    "        out = self.horizon_out(out).squeeze(-1)         # (B, OUT_LEN, N)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c95637e0-852d-4e05-ae39-cec00425cbac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T18:25:32.324829Z",
     "iopub.status.busy": "2026-02-08T18:25:32.324190Z",
     "iopub.status.idle": "2026-02-08T18:25:32.354276Z",
     "shell.execute_reply": "2026-02-08T18:25:32.353544Z",
     "shell.execute_reply.started": "2026-02-08T18:25:32.324802Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Horizons we report in the paper\n",
    "EVAL_HORIZONS = [12, 24, 48, 72]\n",
    "h_idx = torch.tensor([h - 1 for h in EVAL_HORIZONS], device=DEVICE)\n",
    "\n",
    "# For converting scaled error -> original units (multiply by std)\n",
    "flow_std_t = torch.tensor(flow_std, dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "\n",
    "def print_metrics(title, metrics):\n",
    "    print(\"\\n\" + title)\n",
    "    for h in sorted(metrics.keys()):\n",
    "        print(f\"  {h:>3}h  MAE={metrics[h]['MAE']:.3f}  RMSE={metrics[h]['RMSE']:.3f}\")\n",
    "\n",
    "def avg_mae(metrics):\n",
    "    return float(np.mean([metrics[h][\"MAE\"] for h in metrics]))\n",
    "\n",
    "@torch.inference_mode()\n",
    "def eval_horizons_fast(model, loader):\n",
    "    \"\"\"\n",
    "    Works for both:\n",
    "      - GraphWaveNetTimeAware (forward(x, tf_future))\n",
    "      - GraphWaveNetRNN      (forward(x, tf_future))\n",
    "    Assumes y is scaled and predictions are scaled.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    acc = {h: {\"abs\": 0.0, \"sq\": 0.0, \"count\": 0} for h in EVAL_HORIZONS}\n",
    "\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Eval\", leave=True):\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        pred = model(xb, tfb)  # (B, OUT, N) scaled\n",
    "\n",
    "        # Original-units error at selected horizons: (pred - true) * std\n",
    "        err = (pred[:, h_idx, :] - yb[:, h_idx, :]) * flow_std_t  # (B, H, N)\n",
    "\n",
    "        abs_err = err.abs()\n",
    "        sq_err = err * err\n",
    "\n",
    "        for k, h in enumerate(EVAL_HORIZONS):\n",
    "            acc[h][\"abs\"] += float(abs_err[:, k, :].sum())\n",
    "            acc[h][\"sq\"]  += float(sq_err[:, k, :].sum())\n",
    "            acc[h][\"count\"] += abs_err[:, k, :].numel()\n",
    "\n",
    "    metrics = {}\n",
    "    for h in EVAL_HORIZONS:\n",
    "        mae = acc[h][\"abs\"] / acc[h][\"count\"]\n",
    "        rmse = (acc[h][\"sq\"] / acc[h][\"count\"]) ** 0.5\n",
    "        metrics[h] = {\"MAE\": mae, \"RMSE\": rmse}\n",
    "    return metrics\n",
    "\n",
    "def train_gwn_baseline_fast(\n",
    "    model,\n",
    "    epochs=40,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    clip=5.0,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generic trainer for:\n",
    "      - GraphWaveNet baseline\n",
    "      - GraphWaveNet+GRU/LSTM variants\n",
    "\n",
    "    Uses:\n",
    "      - SmoothL1Loss on scaled targets\n",
    "      - Early stopping on avg validation MAE (original units)\n",
    "      - Evaluates every `eval_every` epochs to save time\n",
    "    \"\"\"\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.SmoothL1Loss(beta=1.0)\n",
    "\n",
    "    best_score = float(\"inf\")\n",
    "    best_state = None\n",
    "    bad = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "\n",
    "        for xb, yb, tfb in tqdm(train_loader, desc=f\"Train {epoch}/{epochs}\", leave=True):\n",
    "            xb = xb.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "            tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            pred = model(xb, tfb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "\n",
    "            running += float(loss.item())\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}: train_loss={running/len(train_loader):.6f}\")\n",
    "\n",
    "        # Validate periodically\n",
    "        if (epoch % eval_every == 0) or (epoch == epochs):\n",
    "            val_metrics = eval_horizons_fast(model, val_loader)\n",
    "            score = avg_mae(val_metrics)\n",
    "\n",
    "            print(f\"Epoch {epoch}: val_avg_MAE={score:.3f}\")\n",
    "            print_metrics(\"Validation metrics\", val_metrics)\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= patience:\n",
    "                    print(f\"\\nEarly stopping. Best val_avg_MAE={best_score:.3f}\")\n",
    "                    break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "759d61d2-79c2-48b3-8125-3d558e898697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T18:25:37.555562Z",
     "iopub.status.busy": "2026-02-08T18:25:37.554931Z",
     "iopub.status.idle": "2026-02-08T18:25:37.571850Z",
     "shell.execute_reply": "2026-02-08T18:25:37.571116Z",
     "shell.execute_reply.started": "2026-02-08T18:25:37.555537Z"
    }
   },
   "outputs": [],
   "source": [
    "gwn_base = GraphWaveNetRNN(\n",
    "    num_nodes=X.shape[1],\n",
    "    in_dim=X.shape[2],\n",
    "    out_len=OUT_LEN,\n",
    "    supports=supports,\n",
    "    end_channels=128,\n",
    "    use_gru=False,\n",
    "    use_lstm=False,\n",
    "    rnn_hidden=128,\n",
    "    dropout=0.1,\n",
    "    residual_channels=32,\n",
    "    dilation_channels=32,\n",
    "    skip_channels=64,\n",
    "    kernel_size=2,\n",
    "    blocks=2,\n",
    "    layers_per_block=4,\n",
    "    gcn_order=1,\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edc13997-3b00-49a7-a86a-9cf3e412e5f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T18:25:42.495644Z",
     "iopub.status.busy": "2026-02-08T18:25:42.494865Z",
     "iopub.status.idle": "2026-02-08T18:25:42.571073Z",
     "shell.execute_reply": "2026-02-08T18:25:42.570099Z",
     "shell.execute_reply.started": "2026-02-08T18:25:42.495619Z"
    }
   },
   "outputs": [],
   "source": [
    "gwn_gru = GraphWaveNetRNN(\n",
    "    num_nodes=X.shape[1],\n",
    "    in_dim=X.shape[2],\n",
    "    out_len=OUT_LEN,\n",
    "    supports=supports,\n",
    "\n",
    "    # RNN options\n",
    "    use_gru=True,\n",
    "    use_lstm=False,\n",
    "    rnn_hidden=128,   # you can try 64 later if needed\n",
    "\n",
    "    # encoder hyperparameters\n",
    "    end_channels=128,\n",
    "    dropout=0.1,\n",
    "\n",
    "    residual_channels=32,\n",
    "    dilation_channels=32,\n",
    "    skip_channels=64,\n",
    "    kernel_size=2,\n",
    "    blocks=2,\n",
    "    layers_per_block=4,\n",
    "    gcn_order=1,\n",
    ").to(DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ca72414-0301-4b4c-936f-b8dfdca19c41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T18:25:49.033789Z",
     "iopub.status.busy": "2026-02-08T18:25:49.033026Z",
     "iopub.status.idle": "2026-02-08T18:25:49.052355Z",
     "shell.execute_reply": "2026-02-08T18:25:49.051688Z",
     "shell.execute_reply.started": "2026-02-08T18:25:49.033762Z"
    }
   },
   "outputs": [],
   "source": [
    "gwn_lstm = GraphWaveNetRNN(\n",
    "    num_nodes=X.shape[1],\n",
    "    in_dim=X.shape[2],\n",
    "    out_len=OUT_LEN,\n",
    "    supports=supports,\n",
    "\n",
    "    # RNN options\n",
    "    use_gru=False,\n",
    "    use_lstm=True,\n",
    "    rnn_hidden=128,\n",
    "\n",
    "    # encoder hyperparameters\n",
    "    end_channels=128,\n",
    "    dropout=0.1,\n",
    "\n",
    "    residual_channels=32,\n",
    "    dilation_channels=32,\n",
    "    skip_channels=64,\n",
    "    kernel_size=2,\n",
    "    blocks=2,\n",
    "    layers_per_block=4,\n",
    "    gcn_order=1,\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd45820d-d424-407a-a174-56ec00000bd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T18:25:52.807291Z",
     "iopub.status.busy": "2026-02-08T18:25:52.806690Z",
     "iopub.status.idle": "2026-02-08T18:25:52.826744Z",
     "shell.execute_reply": "2026-02-08T18:25:52.826052Z",
     "shell.execute_reply.started": "2026-02-08T18:25:52.807265Z"
    }
   },
   "outputs": [],
   "source": [
    "gwn_gru_lstm = GraphWaveNetRNN(\n",
    "    num_nodes=X.shape[1],\n",
    "    in_dim=X.shape[2],\n",
    "    out_len=OUT_LEN,\n",
    "    supports=supports,\n",
    "\n",
    "    # RNN options (both ON)\n",
    "    use_gru=True,\n",
    "    use_lstm=True,\n",
    "    rnn_hidden=128,   # consider 64 if memory is tight\n",
    "\n",
    "    # encoder hyperparameters\n",
    "    end_channels=128,\n",
    "    dropout=0.1,\n",
    "\n",
    "    residual_channels=32,\n",
    "    dilation_channels=32,\n",
    "    skip_channels=64,\n",
    "    kernel_size=2,\n",
    "    blocks=2,\n",
    "    layers_per_block=4,\n",
    "    gcn_order=1,\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7ae4a-bbe4-4003-92a7-836e20337d11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T23:46:57.638648Z",
     "iopub.status.busy": "2026-02-08T23:46:57.638432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f5ce065c2a4c87808ad4ca06cd7b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: train_loss=0.069344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d30ce098934499b074a4d2f23b92a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 2/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.068216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7195a3b64604a30aa11f2069c8baa3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: val_avg_MAE=142.784\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=122.702  RMSE=250.600\n",
      "   24h  MAE=133.762  RMSE=270.968\n",
      "   48h  MAE=153.171  RMSE=305.410\n",
      "   72h  MAE=161.501  RMSE=323.483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c928c698df0496d91c4409e7f5bdeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 3/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: train_loss=0.067949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59556d96ac34f2293256763a1ec79f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 4/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=0.067564\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc37f2dfef945dd95f7467bbe3468d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: val_avg_MAE=145.270\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=122.212  RMSE=245.460\n",
      "   24h  MAE=135.322  RMSE=270.348\n",
      "   48h  MAE=156.585  RMSE=308.799\n",
      "   72h  MAE=166.961  RMSE=330.038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eefecfdaf6f45e6bed723551563cbbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 5/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: train_loss=0.067505\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ae9d836e04463c9d70a725cbb6190d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 6/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: train_loss=0.067179\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a23979dfd1e450098aa2086f09b4775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: val_avg_MAE=138.746\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=118.996  RMSE=244.390\n",
      "   24h  MAE=130.782  RMSE=268.204\n",
      "   48h  MAE=149.420  RMSE=301.413\n",
      "   72h  MAE=155.786  RMSE=314.527\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54abb3c59b894ec3bb8a972955952cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 7/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: train_loss=0.066889\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110ae51d503a46aeb1da917e6ee735d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 8/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: train_loss=0.066778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0784b3d462414eb0863c78c35c4dc079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: val_avg_MAE=136.142\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=121.889  RMSE=239.475\n",
      "   24h  MAE=127.331  RMSE=256.420\n",
      "   48h  MAE=144.405  RMSE=285.289\n",
      "   72h  MAE=150.942  RMSE=299.515\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c064d3ce8344d43b603eb260a49745a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 9/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: train_loss=0.067129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779dc7b76cfe4f0685179d7aee3e53ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 10/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: train_loss=0.066682\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e696290d5bc84a3a9e81221feb59c90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: val_avg_MAE=147.497\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=126.991  RMSE=251.459\n",
      "   24h  MAE=138.185  RMSE=275.211\n",
      "   48h  MAE=158.519  RMSE=311.785\n",
      "   72h  MAE=166.292  RMSE=327.812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59570cc6e9044f786188e5182dc8a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 11/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: train_loss=0.066730\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01325aa3464247d6b0b064f4b7cdf1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 12/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: train_loss=0.067255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b321930cdf44a4aac0a95c167ad202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: val_avg_MAE=152.662\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=138.393  RMSE=287.913\n",
      "   24h  MAE=144.928  RMSE=300.079\n",
      "   48h  MAE=160.973  RMSE=331.954\n",
      "   72h  MAE=166.352  RMSE=341.669\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e004817de944e0ab0a6e1c53628f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 13/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: train_loss=0.066909\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639436fd53be458a9d886d08e3044e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 14/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: train_loss=0.066567\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cf71fd2eef4fcbadaacd8e760d6a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: val_avg_MAE=142.554\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=122.701  RMSE=244.487\n",
      "   24h  MAE=132.333  RMSE=266.945\n",
      "   48h  MAE=153.941  RMSE=304.071\n",
      "   72h  MAE=161.242  RMSE=320.493\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462db4c113534e1aad0c26d806c3be3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 15/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: train_loss=0.066083\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b956439631f4c77a66cb5ae91218644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 16/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = gwn_gru\n",
    "model = train_gwn_baseline_fast(model, epochs=40, patience=6, eval_every=2)\n",
    "\n",
    "print(\"Evaluating on TEST set...\")\n",
    "test_m = eval_horizons_fast(model, test_loader)\n",
    "print_metrics(\"GraphWaveNet+GRU — Test\", test_m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3a917-20c6-40dc-a158-5f6a9c1f78da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gwn_lstm\n",
    "model = train_gwn_baseline_fast(model, epochs=40, patience=6, eval_every=2)\n",
    "\n",
    "print(\"Evaluating on TEST set...\")\n",
    "test_m = eval_horizons_fast(model, test_loader)\n",
    "print_metrics(\"GraphWaveNet+GRU — Test\", test_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6afcf2e-5ebb-4103-8d91-58993081f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gwn_gru_lstm\n",
    "model = train_gwn_baseline_fast(model, epochs=40, patience=6, eval_every=2)\n",
    "\n",
    "print(\"Evaluating on TEST set...\")\n",
    "test_m = eval_horizons_fast(model, test_loader)\n",
    "print_metrics(\"GraphWaveNet+GRU — Test\", test_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83b391af-c2a4-49b6-92fb-f7a1d9090f5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T18:26:03.749601Z",
     "iopub.status.busy": "2026-02-08T18:26:03.749298Z",
     "iopub.status.idle": "2026-02-08T18:26:03.777774Z",
     "shell.execute_reply": "2026-02-08T18:26:03.777004Z",
     "shell.execute_reply.started": "2026-02-08T18:26:03.749576Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Choose Excel engine (xlsxwriter is much faster if available)\n",
    "def _excel_engine():\n",
    "    try:\n",
    "        import xlsxwriter  # noqa: F401\n",
    "        return \"xlsxwriter\"\n",
    "    except Exception:\n",
    "        return \"openpyxl\"\n",
    "\n",
    "def make_run_dir(model_name: str, root: str = \"artifacts/runs\") -> Path:\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    safe = \"\".join([c if c.isalnum() or c in \"-_.\" else \"_\" for c in model_name])\n",
    "    run_dir = Path(root) / f\"{ts}_{safe}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def save_json(obj, path: Path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, default=str)\n",
    "\n",
    "@torch.inference_mode()\n",
    "def collect_predictions_for_horizons(\n",
    "    model,\n",
    "    loader,\n",
    "    horizons=(12, 24, 48, 72),\n",
    "    stations=None,\n",
    "    timestamps=None,\n",
    "    in_len=None,\n",
    "    flow_mean=None,\n",
    "    flow_std=None,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Collect predictions/targets on loader for selected horizons.\n",
    "    Assumes y and pred are SCALED. Converts both to ORIGINAL units before saving.\n",
    "\n",
    "    Returns:\n",
    "      pred: (S, H, N) float32\n",
    "      true: (S, H, N) float32\n",
    "      times: (S, H) datetime64[ns]\n",
    "      horizons: list[int]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    horizons = list(horizons)\n",
    "    h_idx = np.array([h - 1 for h in horizons], dtype=np.int32)\n",
    "\n",
    "    # We rely on test_loader shuffle=False so order is dataset order\n",
    "    # Try to get starts from dataset (FastPemsWindowDataset had .starts)\n",
    "    ds = loader.dataset\n",
    "    if not hasattr(ds, \"starts\"):\n",
    "        raise AttributeError(\"loader.dataset must have attribute `.starts` to reconstruct timestamps per window.\")\n",
    "    starts = ds.starts\n",
    "\n",
    "    assert timestamps is not None and in_len is not None, \"Need timestamps and in_len to compute target times.\"\n",
    "    assert stations is not None, \"Need stations list for column labels.\"\n",
    "    assert flow_mean is not None and flow_std is not None, \"Need flow_mean/flow_std to unscale.\"\n",
    "\n",
    "    N = len(stations)\n",
    "    flow_mean = flow_mean.astype(np.float32)\n",
    "    flow_std  = flow_std.astype(np.float32)\n",
    "\n",
    "    preds_list, trues_list, times_list = [], [], []\n",
    "    offset = 0\n",
    "\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Collect preds\", leave=True):\n",
    "        B = xb.shape[0]\n",
    "\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        tfb = tfb.to(device, non_blocking=True)\n",
    "\n",
    "        pred_scaled = model(xb, tfb).detach().cpu().numpy().astype(np.float32)  # (B, OUT, N)\n",
    "\n",
    "        # yb is already on CPU typically; ensure numpy float32\n",
    "        true_scaled = yb.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "        # Select horizons\n",
    "        pred_sel_scaled = pred_scaled[:, h_idx, :]  # (B, H, N)\n",
    "        true_sel_scaled = true_scaled[:, h_idx, :]  # (B, H, N)\n",
    "\n",
    "        # Unscale to original units\n",
    "        pred_sel = pred_sel_scaled * flow_std[None, None, :] + flow_mean[None, None, :]\n",
    "        true_sel = true_sel_scaled * flow_std[None, None, :] + flow_mean[None, None, :]\n",
    "\n",
    "        preds_list.append(pred_sel.astype(np.float32))\n",
    "        trues_list.append(true_sel.astype(np.float32))\n",
    "\n",
    "        # target timestamps for each sample/horizon\n",
    "        batch_times = np.zeros((B, len(horizons)), dtype=\"datetime64[ns]\")\n",
    "        for j in range(B):\n",
    "            t0 = int(starts[offset + j])\n",
    "            target_indices = t0 + int(in_len) + h_idx\n",
    "            batch_times[j, :] = np.array(pd.to_datetime(timestamps[target_indices]).astype(\"datetime64[ns]\"))\n",
    "        times_list.append(batch_times)\n",
    "\n",
    "        offset += B\n",
    "\n",
    "    pred = np.concatenate(preds_list, axis=0)\n",
    "    true = np.concatenate(trues_list, axis=0)\n",
    "    times = np.concatenate(times_list, axis=0)\n",
    "    return pred, true, times, horizons\n",
    "\n",
    "def export_preds_to_excel(\n",
    "    excel_path: Path,\n",
    "    pred: np.ndarray,\n",
    "    true: np.ndarray,\n",
    "    times: np.ndarray,\n",
    "    horizons,\n",
    "    stations,\n",
    "    max_stations_excel: int | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Writes an Excel workbook:\n",
    "      - metrics sheet can be added separately\n",
    "      - pred_hXX and true_hXX sheets for each horizon\n",
    "\n",
    "    If max_stations_excel is set, only the first max_stations are exported (file smaller).\n",
    "    Full arrays should still be saved to NPZ.\n",
    "    \"\"\"\n",
    "    engine = _excel_engine()\n",
    "    stations = [str(s) for s in stations]\n",
    "\n",
    "    if max_stations_excel is not None:\n",
    "        stations = stations[:max_stations_excel]\n",
    "        pred = pred[:, :, :max_stations_excel]\n",
    "        true = true[:, :, :max_stations_excel]\n",
    "\n",
    "    with pd.ExcelWriter(excel_path, engine=engine) as writer:\n",
    "        # Also save station list\n",
    "        pd.DataFrame({\"station\": stations}).to_excel(writer, sheet_name=\"stations\", index=False)\n",
    "\n",
    "        # Save each horizon\n",
    "        for k, h in enumerate(horizons):\n",
    "            tcol = pd.to_datetime(times[:, k])\n",
    "            pred_df = pd.DataFrame(pred[:, k, :], columns=stations)\n",
    "            pred_df.insert(0, \"target_time\", tcol)\n",
    "\n",
    "            true_df = pd.DataFrame(true[:, k, :], columns=stations)\n",
    "            true_df.insert(0, \"target_time\", tcol)\n",
    "\n",
    "            pred_df.to_excel(writer, sheet_name=f\"pred_h{h}\", index=False)\n",
    "            true_df.to_excel(writer, sheet_name=f\"true_h{h}\", index=False)\n",
    "\n",
    "def append_summary_csv(summary_csv: Path, row: dict):\n",
    "    summary_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.DataFrame([row])\n",
    "    if summary_csv.exists():\n",
    "        old = pd.read_csv(summary_csv)\n",
    "        out = pd.concat([old, df], ignore_index=True)\n",
    "    else:\n",
    "        out = df\n",
    "    out.to_csv(summary_csv, index=False)\n",
    "\n",
    "def train_and_save_best(\n",
    "    model,\n",
    "    model_name: str,\n",
    "    run_dir: Path,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    eval_fn,                 # eval_horizons_fast\n",
    "    epochs=40,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    clip=5.0,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains model, saves:\n",
    "      - best checkpoint to run_dir/best.pt\n",
    "      - training history to run_dir/history.csv\n",
    "      - config to run_dir/config.json\n",
    "    Returns:\n",
    "      model (loaded with best checkpoint)\n",
    "      history_df\n",
    "      best_val_metrics\n",
    "    \"\"\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    config = dict(\n",
    "        model_name=model_name,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "        clip=clip,\n",
    "        patience=patience,\n",
    "        eval_every=eval_every,\n",
    "        timestamp=str(datetime.now()),\n",
    "    )\n",
    "    save_json(config, run_dir / \"config.json\")\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.SmoothL1Loss(beta=1.0)\n",
    "\n",
    "    best_score = float(\"inf\")\n",
    "    best_state = None\n",
    "    best_val_metrics = None\n",
    "    bad = 0\n",
    "\n",
    "    history = []\n",
    "    t_start = time.time()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "\n",
    "        for xb, yb, tfb in tqdm(train_loader, desc=f\"Train {epoch}/{epochs}\", leave=True):\n",
    "            xb = xb.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "            tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            pred = model(xb, tfb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "\n",
    "            running += float(loss.item())\n",
    "\n",
    "        train_loss = running / max(len(train_loader), 1)\n",
    "        row = {\"epoch\": epoch, \"train_loss\": train_loss}\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}: train_loss={train_loss:.6f}\")\n",
    "\n",
    "        if (epoch % eval_every == 0) or (epoch == epochs):\n",
    "            val_metrics = eval_fn(model, val_loader)\n",
    "            score = float(np.mean([val_metrics[h][\"MAE\"] for h in val_metrics]))\n",
    "\n",
    "            row[\"val_avg_MAE\"] = score\n",
    "            for h in sorted(val_metrics.keys()):\n",
    "                row[f\"val_MAE_{h}h\"] = val_metrics[h][\"MAE\"]\n",
    "                row[f\"val_RMSE_{h}h\"] = val_metrics[h][\"RMSE\"]\n",
    "\n",
    "            print(f\"Epoch {epoch}: val_avg_MAE={score:.3f}\")\n",
    "\n",
    "            # Save best checkpoint\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_val_metrics = val_metrics\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"model_name\": model_name,\n",
    "                        \"epoch\": epoch,\n",
    "                        \"best_val_avg_MAE\": best_score,\n",
    "                        \"state_dict\": best_state,\n",
    "                    },\n",
    "                    run_dir / \"best.pt\",\n",
    "                )\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= patience:\n",
    "                    print(f\"\\nEarly stopping. Best val_avg_MAE={best_score:.3f}\")\n",
    "                    history.append(row)\n",
    "                    break\n",
    "\n",
    "        history.append(row)\n",
    "\n",
    "        # Write history every epoch so you don't lose it\n",
    "        pd.DataFrame(history).to_csv(run_dir / \"history.csv\", index=False)\n",
    "\n",
    "    # Load best checkpoint if exists\n",
    "    best_path = run_dir / \"best.pt\"\n",
    "    if best_path.exists():\n",
    "        ckpt = torch.load(best_path, map_location=\"cpu\")\n",
    "        model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    else:\n",
    "        print(\"Warning: best.pt not found; using current model weights.\")\n",
    "\n",
    "    elapsed = time.time() - t_start\n",
    "    save_json({\"train_seconds\": elapsed, \"best_val_avg_MAE\": best_score}, run_dir / \"train_summary.json\")\n",
    "\n",
    "    history_df = pd.read_csv(run_dir / \"history.csv\")\n",
    "    return model, history_df, best_val_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b9b501e-a236-49f1-a724-2a81fd422125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T18:26:08.426420Z",
     "iopub.status.busy": "2026-02-08T18:26:08.425759Z",
     "iopub.status.idle": "2026-02-08T20:02:44.866890Z",
     "shell.execute_reply": "2026-02-08T20:02:44.866096Z",
     "shell.execute_reply.started": "2026-02-08T18:26:08.426394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee3f8a516c84a68bcce499b074ccd31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: train_loss=0.167076\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c56ca93cd848c9b7bfbb3d8cc9fdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 2/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.116750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c1a0667c824cb3b1f67f1e30b77030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: val_avg_MAE=181.891\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb2bb7f843c4994bcbfcf232da9b8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 3/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: train_loss=0.100684\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0cd5122b7a412f8d739abe844ae3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 4/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=0.093186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50bc4b79c53495787f320b9bad3fc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: val_avg_MAE=170.453\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cea5e38cee40b79e7503da84c93be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 5/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: train_loss=0.088388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066dcd74b2554b39a97b1cfa1eca8eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 6/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: train_loss=0.085367\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc3def44bb4453c81164ab30ccdef50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: val_avg_MAE=156.216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b353d5d87b4f4b94b727819bb1d37b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 7/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: train_loss=0.082692\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85eeb5193bfd48e1a88a44565ff55640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 8/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: train_loss=0.080544\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161950c97dff4a3a8ab5d0ff32ff90cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: val_avg_MAE=153.305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba953b83bcb4759863fff66acab7459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 9/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: train_loss=0.079169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8559c42d9eff441381eca6cd742732e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 10/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: train_loss=0.077482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4cb16cdba4402588f4bf6cbe122e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: val_avg_MAE=160.192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ba6331301c42cabae19a71919f65d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 11/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: train_loss=0.076396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236edc577dcc468fb5af7c3782b50f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 12/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: train_loss=0.075392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df98f30cb8884c9fa83ae9c5faa2d0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: val_avg_MAE=147.165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a84ad9cb4344cc08c1ea711357d22f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 13/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: train_loss=0.074821\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e2522f593247b093de0bf39d00d4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 14/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: train_loss=0.074361\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7d5f8541254d98af825dfcd90b5d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: val_avg_MAE=149.617\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33fba77aae0475eaf22a95f250a0d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 15/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: train_loss=0.073265\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24b71f4a2444076a8d47ffe49fbabee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 16/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: train_loss=0.072879\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf536dbb248431aa59b1ff4c7cab37a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: val_avg_MAE=149.144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a02169bf44a4c5aa60d96cc32643fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 17/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17: train_loss=0.072138\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e9e5d60d3740a98e005f4493baedc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 18/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: train_loss=0.072228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eec99b6349c430eb3734edf5a6f070e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: val_avg_MAE=154.570\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96144a7c305e4cac8aa4b0e91c7e2f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 19/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: train_loss=0.071228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a908d108bcd5491db97b903998d8016d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 20/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: train_loss=0.070735\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccbd75b0cf044aa92c413364d9d8a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: val_avg_MAE=146.966\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de90fb700b14911a324f334dcb9a355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 21/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: train_loss=0.070750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ed0e21749a43a59833abbbd4f0a3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 22/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: train_loss=0.069830\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8cc5da72a5d4a89a9c88d034d2410cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: val_avg_MAE=150.344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965b088e11a441ebbebc7805c0e0149d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 23/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23: train_loss=0.069634\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1975bd7ce784e8c9483834ee8a9edb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 24/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: train_loss=0.069842\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b7e034cad24c569b8e7213df77ac7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: val_avg_MAE=145.888\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51bbd1a84a41435c9a05e84821fd0c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 25/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25: train_loss=0.069440\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b402244878440480c793c04561830a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 26/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: train_loss=0.068699\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1fd4f3c37e4d6eb8ffd00a125ceaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: val_avg_MAE=141.426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d49e2df5b6a4103bdc4f4a6fd44340a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 27/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27: train_loss=0.068965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfcc100d7824399adeeaf71520c30f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 28/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: train_loss=0.068485\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1691f6257c460ca0df2c634ddc87d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: val_avg_MAE=137.197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da64e4df6d54c45865618cb6852294d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 29/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29: train_loss=0.068209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef485b692bb49e68cc55dc432e28daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 30/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: train_loss=0.067903\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662ebedd444641e3b7fe05459342067d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: val_avg_MAE=143.328\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5097319446e346108449b82b9ba5bb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 31/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31: train_loss=0.067960\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25701d6a6938463e9ef113dd319c7463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 32/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: train_loss=0.067656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87d0c22a28b4b93bb3fe8afb6790286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: val_avg_MAE=143.007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6357cf13eec437c9cc80cda697f4615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 33/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33: train_loss=0.067636\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5f8bb4aad34656831ea80104d29e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 34/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: train_loss=0.067217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f2c91902cf407a8f4533bab29f1153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: val_avg_MAE=156.258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb4a319e17847e2942194051fb87196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 35/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35: train_loss=0.067948\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdf82ff8eaf45deb428202d885a210d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 36/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: train_loss=0.066877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae91dde648a34134be41fd5832286ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: val_avg_MAE=151.170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68d9216f59e46faa7131ef09f135295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 37/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37: train_loss=0.067017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7dc4c045224d7c8dabbc37094d58ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 38/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: train_loss=0.067049\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0aabb3cffd47579bf9c5af466e6d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: val_avg_MAE=145.086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6537f86f2954eb6ba13b248ba08baa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 39/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39: train_loss=0.066604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98bda9b4b5eb4e5ca137667c2d4cc124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 40/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40: train_loss=0.066550\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5819183bdfa64a6a9ad48f2a847e3775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: val_avg_MAE=141.399\n",
      "\n",
      "Early stopping. Best val_avg_MAE=137.197\n",
      "Evaluating on TEST set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c8e486f6ae4fe19ae99088edc498a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GraphWaveNet_GRU — Test\n",
      "   12h  MAE=122.689  RMSE=245.462\n",
      "   24h  MAE=127.521  RMSE=256.627\n",
      "   48h  MAE=138.532  RMSE=283.292\n",
      "   72h  MAE=143.747  RMSE=292.758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9530484d517e48d3830abe346446546e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collect preds:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved run outputs to: artifacts/runs/20260208_182608_GraphWaveNet_GRU\n",
      " - best checkpoint: artifacts/runs/20260208_182608_GraphWaveNet_GRU/best.pt\n",
      " - history: artifacts/runs/20260208_182608_GraphWaveNet_GRU/history.csv\n",
      " - test metrics: artifacts/runs/20260208_182608_GraphWaveNet_GRU/test_metrics.json\n",
      " - predictions (npz): artifacts/runs/20260208_182608_GraphWaveNet_GRU/test_pred_true_selected_horizons.npz\n",
      " - predictions (xlsx): artifacts/runs/20260208_182608_GraphWaveNet_GRU/test_pred_true_selected_horizons.xlsx\n",
      " - master summary: artifacts/results_summary.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"GraphWaveNet_GRU\"\n",
    "model = gwn_gru\n",
    "\n",
    "\n",
    "run_dir = make_run_dir(model_name)\n",
    "\n",
    "# Train and save best checkpoint + history\n",
    "model, history_df, best_val_metrics = train_and_save_best(\n",
    "    model=model,\n",
    "    model_name=model_name,\n",
    "    run_dir=run_dir,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    eval_fn=eval_horizons_fast,   # use your fast evaluator\n",
    "    epochs=40,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    ")\n",
    "\n",
    "print(\"Evaluating on TEST set...\")\n",
    "test_metrics = eval_horizons_fast(model, test_loader)\n",
    "print_metrics(f\"{model_name} — Test\", test_metrics)\n",
    "\n",
    "# Save metrics to JSON + Excel-friendly table\n",
    "metrics_row = {\"model_name\": model_name, \"run_dir\": str(run_dir)}\n",
    "for h in sorted(test_metrics.keys()):\n",
    "    metrics_row[f\"test_MAE_{h}h\"] = test_metrics[h][\"MAE\"]\n",
    "    metrics_row[f\"test_RMSE_{h}h\"] = test_metrics[h][\"RMSE\"]\n",
    "\n",
    "save_json({\"test_metrics\": test_metrics}, run_dir / \"test_metrics.json\")\n",
    "pd.DataFrame([metrics_row]).to_csv(run_dir / \"test_metrics.csv\", index=False)\n",
    "\n",
    "# Also append to a master summary file (so you have one file for all models)\n",
    "append_summary_csv(Path(\"artifacts/results_summary.csv\"), metrics_row)\n",
    "\n",
    "# Collect predictions + actuals on TEST set (original units), for paper horizons\n",
    "HORIZONS_TO_SAVE = [12, 24, 48, 72]\n",
    "\n",
    "pred, true, times, horizons = collect_predictions_for_horizons(\n",
    "    model=model,\n",
    "    loader=test_loader,\n",
    "    horizons=HORIZONS_TO_SAVE,\n",
    "    stations=stations,\n",
    "    timestamps=timestamps,\n",
    "    in_len=IN_LEN,\n",
    "    flow_mean=flow_mean,\n",
    "    flow_std=flow_std,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "# Save compact full arrays (best format for later plots)\n",
    "np.savez_compressed(\n",
    "    run_dir / \"test_pred_true_selected_horizons.npz\",\n",
    "    pred=pred,\n",
    "    true=true,\n",
    "    times=times,\n",
    "    horizons=np.array(horizons, dtype=np.int32),\n",
    "    stations=stations,\n",
    ")\n",
    "\n",
    "# Export to Excel (pred + true sheets for each horizon)\n",
    "# If Excel gets too heavy, set max_stations_excel=200 (or 500)\n",
    "excel_path = run_dir / \"test_pred_true_selected_horizons.xlsx\"\n",
    "export_preds_to_excel(\n",
    "    excel_path=excel_path,\n",
    "    pred=pred,\n",
    "    true=true,\n",
    "    times=times,\n",
    "    horizons=horizons,\n",
    "    stations=stations,\n",
    "    max_stations_excel=None,  \n",
    ")\n",
    "\n",
    "print(\"\\nSaved run outputs to:\", run_dir)\n",
    "print(\" - best checkpoint:\", run_dir / \"best.pt\")\n",
    "print(\" - history:\", run_dir / \"history.csv\")\n",
    "print(\" - test metrics:\", run_dir / \"test_metrics.json\")\n",
    "print(\" - predictions (npz):\", run_dir / \"test_pred_true_selected_horizons.npz\")\n",
    "print(\" - predictions (xlsx):\", excel_path)\n",
    "print(\" - master summary:\", Path(\"artifacts/results_summary.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbca1b17-02ea-42fa-954c-16bf3577137f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T20:02:44.870750Z",
     "iopub.status.busy": "2026-02-08T20:02:44.870540Z",
     "iopub.status.idle": "2026-02-08T21:49:19.894567Z",
     "shell.execute_reply": "2026-02-08T21:49:19.893855Z",
     "shell.execute_reply.started": "2026-02-08T20:02:44.870728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45f33ea6de7442bb694a2d26d3ca263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: train_loss=0.155551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6975aa66c842a1b8065ec29eafb94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 2/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.109867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d830c06ecc034775b24bfb42b951ff4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: val_avg_MAE=185.194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3fe0bd2886495eb6c27350b15cc358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 3/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: train_loss=0.099236\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e0a0dbcea046bd9167259a8c6fcb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 4/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=0.091060\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d97ff38ad64d1abf764888c944c236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: val_avg_MAE=180.625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97152f84f38348a99680fefcdee77893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 5/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: train_loss=0.086698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc6790562a3429f8dcb5780c62e719b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 6/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: train_loss=0.083360\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c2b84b757a41df835a1f2511595f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: val_avg_MAE=160.233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7285d2ad81458589fb781861b15b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 7/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: train_loss=0.080657\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf96b4786a984c4892569c19836ce699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 8/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: train_loss=0.078295\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22b6545893d4a8aa0c708728f45a2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: val_avg_MAE=150.111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f052fee65ab843f8a05600327e0d4350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 9/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: train_loss=0.077220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24fd7d530644c43bfa120f8a554c832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 10/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: train_loss=0.075237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445a7cc4fe5c4289a39ee32e9761d791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: val_avg_MAE=153.954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1e5aedbc66476496136ad727c6ea26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 11/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: train_loss=0.073782\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9112f1ac703648788977515eaba7c2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 12/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: train_loss=0.073607\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40572415ad42457b99b19e202ec78084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: val_avg_MAE=146.033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d329e0fcff83427d9f56a1312ec755c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 13/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: train_loss=0.072411\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a1029419804831ac0e7e1a0ae79ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 14/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: train_loss=0.071308\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b7713d62f84fa986c827d3961f3e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: val_avg_MAE=153.542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6632fdc1b8c64bdd850465b2f2b60e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 15/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: train_loss=0.072370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbf18716beb42019637c45a4d98c4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 16/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: train_loss=0.070219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a86098be684d4e8e0a0703cff118f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: val_avg_MAE=147.814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b58341e1336484582cbc8eaef92fabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 17/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17: train_loss=0.070281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eeba513a4d9425c861342ccdfa03c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 18/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: train_loss=0.068997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a94922ad894024bf3f95b03a403709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: val_avg_MAE=148.378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc8a7d968104908afea6e4444899837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 19/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: train_loss=0.068725\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75c80fb3f4640d3a790f75c11616dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 20/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: train_loss=0.068504\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69613153c3714755a99b2c10bd45a18e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: val_avg_MAE=146.096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2ccb5ef17e4e5fb23e2cbeb609b2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 21/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: train_loss=0.068134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abda1ac79d14d199028604ddebd471d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 22/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: train_loss=0.067596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14bfbec7ddad4d65bfa0033c9099b10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: val_avg_MAE=145.132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a9a9c13ce54d8ab30542c1bbfcd97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 23/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23: train_loss=0.067309\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3f431b820543009c2ef97408d39597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 24/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: train_loss=0.067599\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3eabf207b754cb29d929e88fa4d1bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: val_avg_MAE=139.573\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6cdeaa6f96c4a2da6dc63b2155f0520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 25/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25: train_loss=0.066927\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00cb2b1e3f04c049b01ade11d6fcaaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 26/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: train_loss=0.066799\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a623994ab46e453caaff1a8dc2030688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: val_avg_MAE=154.140\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca91c686a0ea4cb49d601cd79de03f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 27/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27: train_loss=0.066406\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6b9604613e415c9a345af16c1bbabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 28/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: train_loss=0.066337\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d758493daf394f3499ceed98739073b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: val_avg_MAE=148.620\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71090b9b8c194046a3cfd1b2117adbfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 29/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29: train_loss=0.065917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e1f0c114a14da79e46ee0c35de87ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 30/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: train_loss=0.066229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b2725b20d044b3a281c5ab66f34f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: val_avg_MAE=136.750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace146a01c23455ea606cdde0bf1f64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 31/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31: train_loss=0.065791\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068d05a8716e4625b49c5c0cf30b70a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 32/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: train_loss=0.065526\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5df7ef14713484eae683fc7e758f600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: val_avg_MAE=140.470\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7e5d62c3034f2f8ae6e712a7747dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 33/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33: train_loss=0.065260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627298d412754c83adeb18bb95aa383e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 34/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: train_loss=0.066075\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bacbd4b4724d4ca9724bf4bf519c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: val_avg_MAE=148.643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5705221df35c466e908da5b80b5ecf39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 35/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35: train_loss=0.064958\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f5e186ed534472ade248fc4265aaa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 36/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: train_loss=0.065093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09e87f223cd46679531ed5220b08182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: val_avg_MAE=137.769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72093490bd24d9f96628b5579191c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 37/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37: train_loss=0.064704\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a29edf6d5145678a549c53448c3bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 38/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: train_loss=0.065052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c66e7101b6426aa15bbb217a838cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: val_avg_MAE=137.614\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172496ac69694d72b80cbb46fe4da8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 39/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39: train_loss=0.064986\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ca2c57f5c940e890efa224f36a025a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 40/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40: train_loss=0.064698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5534fb66d5bc463cba11afa8de852958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: val_avg_MAE=143.630\n",
      "Evaluating on TEST set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2adc6d8c77db4eb093647e8e0844b4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GraphWaveNet_LSTM — Test\n",
      "   12h  MAE=123.368  RMSE=246.555\n",
      "   24h  MAE=125.954  RMSE=252.869\n",
      "   48h  MAE=135.831  RMSE=277.550\n",
      "   72h  MAE=142.286  RMSE=289.365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5270ec70eb4e4b8af3c5d20c5fb00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collect preds:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved run outputs to: artifacts/runs/20260208_200244_GraphWaveNet_LSTM\n",
      " - best checkpoint: artifacts/runs/20260208_200244_GraphWaveNet_LSTM/best.pt\n",
      " - history: artifacts/runs/20260208_200244_GraphWaveNet_LSTM/history.csv\n",
      " - test metrics: artifacts/runs/20260208_200244_GraphWaveNet_LSTM/test_metrics.json\n",
      " - predictions (npz): artifacts/runs/20260208_200244_GraphWaveNet_LSTM/test_pred_true_selected_horizons.npz\n",
      " - predictions (xlsx): artifacts/runs/20260208_200244_GraphWaveNet_LSTM/test_pred_true_selected_horizons.xlsx\n",
      " - master summary: artifacts/results_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# --------- USER EDITS THESE TWO LINES PER MODEL ----------\n",
    "model_name = \"GraphWaveNet_LSTM\"\n",
    "model = gwn_lstm\n",
    "# --------------------------------------------------------\n",
    "\n",
    "run_dir = make_run_dir(model_name)\n",
    "\n",
    "# Train and save best checkpoint + history\n",
    "model, history_df, best_val_metrics = train_and_save_best(\n",
    "    model=model,\n",
    "    model_name=model_name,\n",
    "    run_dir=run_dir,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    eval_fn=eval_horizons_fast,   # use your fast evaluator\n",
    "    epochs=40,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    ")\n",
    "\n",
    "print(\"Evaluating on TEST set...\")\n",
    "test_metrics = eval_horizons_fast(model, test_loader)\n",
    "print_metrics(f\"{model_name} — Test\", test_metrics)\n",
    "\n",
    "# Save metrics to JSON + Excel-friendly table\n",
    "metrics_row = {\"model_name\": model_name, \"run_dir\": str(run_dir)}\n",
    "for h in sorted(test_metrics.keys()):\n",
    "    metrics_row[f\"test_MAE_{h}h\"] = test_metrics[h][\"MAE\"]\n",
    "    metrics_row[f\"test_RMSE_{h}h\"] = test_metrics[h][\"RMSE\"]\n",
    "\n",
    "save_json({\"test_metrics\": test_metrics}, run_dir / \"test_metrics.json\")\n",
    "pd.DataFrame([metrics_row]).to_csv(run_dir / \"test_metrics.csv\", index=False)\n",
    "\n",
    "# Also append to a master summary file (so you have one file for all models)\n",
    "append_summary_csv(Path(\"artifacts/results_summary.csv\"), metrics_row)\n",
    "\n",
    "# Collect predictions + actuals on TEST set (original units), for paper horizons\n",
    "HORIZONS_TO_SAVE = [12, 24, 48, 72]\n",
    "\n",
    "pred, true, times, horizons = collect_predictions_for_horizons(\n",
    "    model=model,\n",
    "    loader=test_loader,\n",
    "    horizons=HORIZONS_TO_SAVE,\n",
    "    stations=stations,\n",
    "    timestamps=timestamps,\n",
    "    in_len=IN_LEN,\n",
    "    flow_mean=flow_mean,\n",
    "    flow_std=flow_std,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "# Save compact full arrays (best format for later plots)\n",
    "np.savez_compressed(\n",
    "    run_dir / \"test_pred_true_selected_horizons.npz\",\n",
    "    pred=pred,\n",
    "    true=true,\n",
    "    times=times,\n",
    "    horizons=np.array(horizons, dtype=np.int32),\n",
    "    stations=stations,\n",
    ")\n",
    "\n",
    "# Export to Excel (pred + true sheets for each horizon)\n",
    "# If Excel gets too heavy, set max_stations_excel=200 (or 500)\n",
    "excel_path = run_dir / \"test_pred_true_selected_horizons.xlsx\"\n",
    "export_preds_to_excel(\n",
    "    excel_path=excel_path,\n",
    "    pred=pred,\n",
    "    true=true,\n",
    "    times=times,\n",
    "    horizons=horizons,\n",
    "    stations=stations,\n",
    "    max_stations_excel=None,  \n",
    "\n",
    "print(\"\\nSaved run outputs to:\", run_dir)\n",
    "print(\" - best checkpoint:\", run_dir / \"best.pt\")\n",
    "print(\" - history:\", run_dir / \"history.csv\")\n",
    "print(\" - test metrics:\", run_dir / \"test_metrics.json\")\n",
    "print(\" - predictions (npz):\", run_dir / \"test_pred_true_selected_horizons.npz\")\n",
    "print(\" - predictions (xlsx):\", excel_path)\n",
    "print(\" - master summary:\", Path(\"artifacts/results_summary.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79db58d2-8273-42d4-b5ac-2f9bf7618718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T21:49:19.898419Z",
     "iopub.status.busy": "2026-02-08T21:49:19.898213Z",
     "iopub.status.idle": "2026-02-08T23:46:57.634815Z",
     "shell.execute_reply": "2026-02-08T23:46:57.634118Z",
     "shell.execute_reply.started": "2026-02-08T21:49:19.898396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0edbe75ccfd1405783ed87cf2ab06614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: train_loss=0.169730\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c855f22d961c425cafa294356025253b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 2/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.119613\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839eade5a70841369d74423eb183da9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: val_avg_MAE=190.120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b292adf5bc349aaa0568ce12d02f6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 3/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: train_loss=0.102975\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4334c3e3215148d986ff40be29479f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 4/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=0.097156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2995cfafeb2b4083b0e519934637ccb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: val_avg_MAE=178.502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c781c7522d204baf837b05cede627058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 5/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: train_loss=0.093715\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab10dbd81c246949c173a57fb8bf5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 6/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: train_loss=0.097541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8080826ad28f4ba2b0b0bd1d00eb6829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: val_avg_MAE=176.582\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c37c21e34b46dea34bd904fcaf2024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 7/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: train_loss=0.087460\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1969c691c1f54e3fba78a8c5afbff225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 8/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: train_loss=0.084724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660f7c205d974539a9f404e878235d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: val_avg_MAE=170.203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b22c4ec6e04642aba2f0e6701462e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 9/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: train_loss=0.083168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4486bc33fe4e9d8694f7b5df67ee71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 10/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: train_loss=0.081871\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b1800f72924affade5a796a0376c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: val_avg_MAE=163.213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a889c82f5ad44db8a4754c73891ee543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 11/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: train_loss=0.081001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bf10c44507415590869fb911503d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 12/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: train_loss=0.080082\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a602e786b2f40d09a7ba277cab8dd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: val_avg_MAE=163.116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a318e416e4a40ec8c31c40a3b854187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 13/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: train_loss=0.079269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4b773052404d3c9bd6bc035dcf5423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 14/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: train_loss=0.078608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e92aef32a9480f9ffd12267d27b0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: val_avg_MAE=154.176\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903bc43b17594abab895d074d3b1358e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 15/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: train_loss=0.077285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e30271972a4d70bf9f4348d7d7eb76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 16/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: train_loss=0.076048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94d6a7c0962437c95f6faf59da152b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: val_avg_MAE=155.512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911a3902299b4e2e89078c232b60803f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 17/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17: train_loss=0.075317\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14d069f9d13412da6ac6ea53ad991a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 18/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: train_loss=0.074346\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7b9bc0785d49d59139fe0d5ab456ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: val_avg_MAE=152.205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770fd9ff11ae4840b8d3decc60049a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 19/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: train_loss=0.073666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960fa04d9e1f406ca6436e47cb75ff53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 20/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: train_loss=0.073199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4577cc2c7bd8435783bacc980d02ce95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: val_avg_MAE=156.183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5dbe9744d946098063e758f364dd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 21/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: train_loss=0.072152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3f8fb2b97546c9ad0146460d9334d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 22/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: train_loss=0.071850\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15d98e8af80444d865dcbead4e3cfa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: val_avg_MAE=144.455\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b56c1ddbe564871ba40f727425873a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 23/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23: train_loss=0.071661\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33c2a227d7c4e72a61b36313e087823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 24/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: train_loss=0.070736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d02b27a05bb46d6bafd2d69ec776c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: val_avg_MAE=147.032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5490c0748984100b2b72ddb252467bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 25/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25: train_loss=0.070533\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57892f104ed6402db8ca2b8b01e0ec3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 26/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: train_loss=0.069998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4a13119c2e41f995f8267e8e124671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: val_avg_MAE=144.378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6704fc0bdd5a4fd6b1ea4bdf464fb786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 27/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27: train_loss=0.069685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2cf7ba5cbb4f5b945b2d30f8619af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 28/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: train_loss=0.069719\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849e1b4ca405468e926b182ef45a9a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: val_avg_MAE=156.022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050d355ad1e24db6b08c502d3fa850dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 29/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29: train_loss=0.069103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcac339da0848e2b7a81ea3b0e1b363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 30/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: train_loss=0.068630\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e842798fe6465785b7a7ef89b77940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: val_avg_MAE=153.476\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b373f0973b467bb8ec4bf680e3501c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 31/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31: train_loss=0.068539\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d23dd8487e44258002749fc0fe7ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 32/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: train_loss=0.067885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c9b480a1374be79b629993d4986520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: val_avg_MAE=148.778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a6ee750c364dc3885d9487bcfb4241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 33/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33: train_loss=0.067969\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd86f8df77949a7880757b1205689e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 34/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: train_loss=0.068308\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362199a09d784719abd535094c516c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: val_avg_MAE=141.396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba80651a24e49668a0794ceddf20d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 35/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35: train_loss=0.067742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd43f2649db419a845d7d97c2a9838c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 36/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: train_loss=0.067355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525cd5aa01564427959d3702057eab32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: val_avg_MAE=152.712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ad08b50de74382a42c40af6657036f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 37/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37: train_loss=0.067230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7a400b22004b6d95e15952e004ab2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 38/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: train_loss=0.067206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2536802e3b4c398c6d260c3780b377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: val_avg_MAE=136.619\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d261fbea2a464fa010942a4a8f0f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 39/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39: train_loss=0.066833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c99cd649a68462ebf909e86528ef01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 40/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40: train_loss=0.067344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e8a8ccdd6949adbd9d8fba7830f71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: val_avg_MAE=139.761\n",
      "Evaluating on TEST set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add7966c3b3245c094b6f5e5de92908f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GraphWaveNet_GRU_LSTM — Test\n",
      "   12h  MAE=119.049  RMSE=241.427\n",
      "   24h  MAE=125.124  RMSE=253.402\n",
      "   48h  MAE=135.325  RMSE=278.629\n",
      "   72h  MAE=141.891  RMSE=291.309\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21fb7c7b54f646f1af0f295c6999d9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collect preds:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved run outputs to: artifacts/runs/20260208_214919_GraphWaveNet_GRU_LSTM\n",
      " - best checkpoint: artifacts/runs/20260208_214919_GraphWaveNet_GRU_LSTM/best.pt\n",
      " - history: artifacts/runs/20260208_214919_GraphWaveNet_GRU_LSTM/history.csv\n",
      " - test metrics: artifacts/runs/20260208_214919_GraphWaveNet_GRU_LSTM/test_metrics.json\n",
      " - predictions (npz): artifacts/runs/20260208_214919_GraphWaveNet_GRU_LSTM/test_pred_true_selected_horizons.npz\n",
      " - predictions (xlsx): artifacts/runs/20260208_214919_GraphWaveNet_GRU_LSTM/test_pred_true_selected_horizons.xlsx\n",
      " - master summary: artifacts/results_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# --------- USER EDITS THESE TWO LINES PER MODEL ----------\n",
    "model_name = \"GraphWaveNet_GRU_LSTM\"\n",
    "model = gwn_gru_lstm\n",
    "# --------------------------------------------------------\n",
    "\n",
    "run_dir = make_run_dir(model_name)\n",
    "\n",
    "# Train and save best checkpoint + history\n",
    "model, history_df, best_val_metrics = train_and_save_best(\n",
    "    model=model,\n",
    "    model_name=model_name,\n",
    "    run_dir=run_dir,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    eval_fn=eval_horizons_fast,   # use your fast evaluator\n",
    "    epochs=40,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    ")\n",
    "\n",
    "print(\"Evaluating on TEST set...\")\n",
    "test_metrics = eval_horizons_fast(model, test_loader)\n",
    "print_metrics(f\"{model_name} — Test\", test_metrics)\n",
    "\n",
    "# Save metrics to JSON + Excel-friendly table\n",
    "metrics_row = {\"model_name\": model_name, \"run_dir\": str(run_dir)}\n",
    "for h in sorted(test_metrics.keys()):\n",
    "    metrics_row[f\"test_MAE_{h}h\"] = test_metrics[h][\"MAE\"]\n",
    "    metrics_row[f\"test_RMSE_{h}h\"] = test_metrics[h][\"RMSE\"]\n",
    "\n",
    "save_json({\"test_metrics\": test_metrics}, run_dir / \"test_metrics.json\")\n",
    "pd.DataFrame([metrics_row]).to_csv(run_dir / \"test_metrics.csv\", index=False)\n",
    "\n",
    "# Also append to a master summary file (so you have one file for all models)\n",
    "append_summary_csv(Path(\"artifacts/results_summary.csv\"), metrics_row)\n",
    "\n",
    "# Collect predictions + actuals on TEST set (original units), for paper horizons\n",
    "HORIZONS_TO_SAVE = [12, 24, 48, 72]\n",
    "\n",
    "pred, true, times, horizons = collect_predictions_for_horizons(\n",
    "    model=model,\n",
    "    loader=test_loader,\n",
    "    horizons=HORIZONS_TO_SAVE,\n",
    "    stations=stations,\n",
    "    timestamps=timestamps,\n",
    "    in_len=IN_LEN,\n",
    "    flow_mean=flow_mean,\n",
    "    flow_std=flow_std,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "# Save compact full arrays (best format for later plots)\n",
    "np.savez_compressed(\n",
    "    run_dir / \"test_pred_true_selected_horizons.npz\",\n",
    "    pred=pred,\n",
    "    true=true,\n",
    "    times=times,\n",
    "    horizons=np.array(horizons, dtype=np.int32),\n",
    "    stations=stations,\n",
    ")\n",
    "\n",
    "# Export to Excel (pred + true sheets for each horizon)\n",
    "# If Excel gets too heavy, set max_stations_excel=200 (or 500)\n",
    "excel_path = run_dir / \"test_pred_true_selected_horizons.xlsx\"\n",
    "export_preds_to_excel(\n",
    "    excel_path=excel_path,\n",
    "    pred=pred,\n",
    "    true=true,\n",
    "    times=times,\n",
    "    horizons=horizons,\n",
    "    stations=stations,\n",
    "    max_stations_excel=None,  # set to 200 if you want smaller files\n",
    ")\n",
    "\n",
    "print(\"\\nSaved run outputs to:\", run_dir)\n",
    "print(\" - best checkpoint:\", run_dir / \"best.pt\")\n",
    "print(\" - history:\", run_dir / \"history.csv\")\n",
    "print(\" - test metrics:\", run_dir / \"test_metrics.json\")\n",
    "print(\" - predictions (npz):\", run_dir / \"test_pred_true_selected_horizons.npz\")\n",
    "print(\" - predictions (xlsx):\", excel_path)\n",
    "print(\" - master summary:\", Path(\"artifacts/results_summary.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd6637f-2a15-4dd8-ac68-5bd25a8a40f8",
   "metadata": {},
   "source": [
    "### STGCN MODELS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d28cd65-db4a-447b-844a-4df832a5276e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T01:21:46.792644Z",
     "iopub.status.busy": "2026-02-09T01:21:46.792306Z",
     "iopub.status.idle": "2026-02-09T01:21:47.741072Z",
     "shell.execute_reply": "2026-02-09T01:21:47.740001Z",
     "shell.execute_reply.started": "2026-02-09T01:21:46.792622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded strict dataset\n",
      "X: (2208, 1821, 6) Y: (2208, 1821)\n",
      "IN_LEN: 24 OUT_LEN: 72\n",
      "starts: 1009 289 673\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATASET_STRICT = Path(\"artifacts/pems_graph_dataset_strict.npz\")\n",
    "assert DATASET_STRICT.exists(), f\"Missing: {DATASET_STRICT}. Check artifacts folder.\"\n",
    "\n",
    "d = np.load(DATASET_STRICT, allow_pickle=True)\n",
    "\n",
    "X = d[\"X\"].astype(np.float32)           # (T,N,F)\n",
    "Y = d[\"Y\"].astype(np.float32)           # (T,N)\n",
    "stations = d[\"stations\"]\n",
    "timestamps = pd.to_datetime(d[\"timestamps\"])\n",
    "\n",
    "train_starts = d[\"train_starts\"]\n",
    "val_starts   = d[\"val_starts\"]\n",
    "test_starts  = d[\"test_starts\"]\n",
    "\n",
    "IN_LEN  = int(d[\"in_len\"][0])\n",
    "OUT_LEN = int(d[\"out_len\"][0])\n",
    "\n",
    "flow_mean = d[\"flow_mean\"].astype(np.float32)\n",
    "flow_std  = d[\"flow_std\"].astype(np.float32)\n",
    "speed_mean = d[\"speed_mean\"].astype(np.float32)\n",
    "speed_std  = d[\"speed_std\"].astype(np.float32)\n",
    "\n",
    "print(\"Loaded strict dataset\")\n",
    "print(\"X:\", X.shape, \"Y:\", Y.shape)\n",
    "print(\"IN_LEN:\", IN_LEN, \"OUT_LEN:\", OUT_LEN)\n",
    "print(\"starts:\", len(train_starts), len(val_starts), len(test_starts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca327d55-cdda-4b2d-81a2-0a5950dbd616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T01:22:47.204024Z",
     "iopub.status.busy": "2026-02-09T01:22:47.203612Z",
     "iopub.status.idle": "2026-02-09T01:22:47.208233Z",
     "shell.execute_reply": "2026-02-09T01:22:47.207353Z",
     "shell.execute_reply.started": "2026-02-09T01:22:47.203999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: ['X', 'Y', 'A', 'stations', 'timestamps', 'train_starts', 'val_starts', 'test_starts', 'in_len', 'out_len', 'flow_mean', 'flow_std', 'speed_mean', 'speed_std']\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys:\", d.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa9975f-9fe9-4149-b2e4-143b813b222b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T01:23:39.772394Z",
     "iopub.status.busy": "2026-02-09T01:23:39.771417Z",
     "iopub.status.idle": "2026-02-09T01:23:39.830599Z",
     "shell.execute_reply": "2026-02-09T01:23:39.830027Z",
     "shell.execute_reply.started": "2026-02-09T01:23:39.772367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: (1821, 1821) density: 0.0023693916932872663\n"
     ]
    }
   ],
   "source": [
    "A = d[\"A\"].astype(np.float32)\n",
    "print(\"A:\", A.shape, \"density:\", float((A > 0).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5873a043-a93c-4b57-b9f6-e7a359e01a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T01:24:37.891019Z",
     "iopub.status.busy": "2026-02-09T01:24:37.890420Z",
     "iopub.status.idle": "2026-02-09T01:24:38.723541Z",
     "shell.execute_reply": "2026-02-09T01:24:38.722867Z",
     "shell.execute_reply.started": "2026-02-09T01:24:37.890995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "Supports nnz: [7856, 7856]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "def row_normalize_dense(A, eps=1e-6):\n",
    "    d = A.sum(axis=1, keepdims=True)\n",
    "    return A / (d + eps)\n",
    "\n",
    "def dense_to_sparse(A, device):\n",
    "    idx = np.nonzero(A)\n",
    "    values = A[idx].astype(np.float32)\n",
    "    indices = np.vstack(idx)\n",
    "    return torch.sparse_coo_tensor(\n",
    "        torch.tensor(indices, dtype=torch.long, device=device),\n",
    "        torch.tensor(values, dtype=torch.float32, device=device),\n",
    "        size=A.shape,\n",
    "        device=device\n",
    "    ).coalesce()\n",
    "\n",
    "A_rw  = row_normalize_dense(A)\n",
    "A_rwT = row_normalize_dense(A.T)\n",
    "supports = [dense_to_sparse(A_rw, DEVICE), dense_to_sparse(A_rwT, DEVICE)]\n",
    "\n",
    "print(\"Supports nnz:\", [int(s._nnz()) for s in supports])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da2b388f-ab16-4d7a-899e-4cbf95723708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T01:25:02.073250Z",
     "iopub.status.busy": "2026-02-09T01:25:02.072966Z",
     "iopub.status.idle": "2026-02-09T01:25:02.529479Z",
     "shell.execute_reply": "2026-02-09T01:25:02.527859Z",
     "shell.execute_reply.started": "2026-02-09T01:25:02.073228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x: torch.Size([8, 6, 1821, 24]) Batch y: torch.Size([8, 72, 1821]) Batch tf: torch.Size([8, 72, 4])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def time_encoding(dt_index: pd.DatetimeIndex) -> np.ndarray:\n",
    "    hours = dt_index.hour.values\n",
    "    dow   = dt_index.dayofweek.values\n",
    "    hour_sin = np.sin(2*np.pi*hours/24.0)\n",
    "    hour_cos = np.cos(2*np.pi*hours/24.0)\n",
    "    dow_sin  = np.sin(2*np.pi*dow/7.0)\n",
    "    dow_cos  = np.cos(2*np.pi*dow/7.0)\n",
    "    return np.stack([hour_sin, hour_cos, dow_sin, dow_cos], axis=1).astype(np.float32)\n",
    "\n",
    "# Pre-scale once\n",
    "X_scaled = X.copy()\n",
    "X_scaled[:, :, 0] = (X_scaled[:, :, 0] - flow_mean[None, :]) / flow_std[None, :]\n",
    "X_scaled[:, :, 1] = (X_scaled[:, :, 1] - speed_mean[None, :]) / speed_std[None, :]\n",
    "\n",
    "Y_scaled = (Y - flow_mean[None, :]) / flow_std[None, :]\n",
    "\n",
    "X_fnt = np.transpose(X_scaled, (2, 1, 0)).copy()  # (F,N,T)\n",
    "TF_all = time_encoding(pd.DatetimeIndex(timestamps))\n",
    "\n",
    "class FastPemsWindowDataset(Dataset):\n",
    "    def __init__(self, X_fnt, Y_scaled, TF_all, starts, in_len, out_len):\n",
    "        self.X_fnt = X_fnt\n",
    "        self.Ys = Y_scaled\n",
    "        self.TF = TF_all\n",
    "        self.starts = starts.astype(np.int32)\n",
    "        self.in_len = int(in_len)\n",
    "        self.out_len = int(out_len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.starts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = int(self.starts[idx])\n",
    "        x = self.X_fnt[:, :, t:t+self.in_len]  # (F,N,IN)\n",
    "        y = self.Ys[t+self.in_len:t+self.in_len+self.out_len, :]  # (OUT,N)\n",
    "        tf = self.TF[t+self.in_len:t+self.in_len+self.out_len, :] # (OUT,4)\n",
    "        return torch.from_numpy(x), torch.from_numpy(y), torch.from_numpy(tf)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_ds = FastPemsWindowDataset(X_fnt, Y_scaled, TF_all, train_starts, IN_LEN, OUT_LEN)\n",
    "val_ds   = FastPemsWindowDataset(X_fnt, Y_scaled, TF_all, val_starts,   IN_LEN, OUT_LEN)\n",
    "test_ds  = FastPemsWindowDataset(X_fnt, Y_scaled, TF_all, test_starts,  IN_LEN, OUT_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True, persistent_workers=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True, persistent_workers=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "print(\"Batch x:\", xb.shape, \"Batch y:\", yb.shape, \"Batch tf:\", tfb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50bba764-2419-446e-9aa7-bf3060c02f6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T01:25:45.768994Z",
     "iopub.status.busy": "2026-02-09T01:25:45.768479Z",
     "iopub.status.idle": "2026-02-09T01:25:45.786701Z",
     "shell.execute_reply": "2026-02-09T01:25:45.785985Z",
     "shell.execute_reply.started": "2026-02-09T01:25:45.768971Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---- Sparse node convolution (safe for CUDA sparse mm; uses float32 internally) ----\n",
    "class NConv(nn.Module):\n",
    "    def forward(self, x, A_sp):\n",
    "        # x: (B,C,N,T), A_sp: sparse (N,N)\n",
    "        B, C, N, T = x.shape\n",
    "        x_r = x.permute(2, 0, 1, 3).reshape(N, -1)     # (N, B*C*T)\n",
    "        out = torch.sparse.mm(A_sp, x_r.float())       # float32 for sparse-mm\n",
    "        out = out.reshape(N, B, C, T).permute(1, 2, 0, 3)\n",
    "        return out.to(dtype=x.dtype)\n",
    "\n",
    "class SimpleGraphConv(nn.Module):\n",
    "    \"\"\"\n",
    "    STGCN-style graph conv: concat [x, A1x, A2x, ...] then 1x1 conv\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out, supports, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.nconv = NConv()\n",
    "        self.supports = supports\n",
    "        self.mlp = nn.Conv2d(c_in * (1 + len(supports)), c_out, kernel_size=(1,1))\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = [x]\n",
    "        for A in self.supports:\n",
    "            out.append(self.nconv(x, A))\n",
    "        h = torch.cat(out, dim=1)\n",
    "        h = self.mlp(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        return h\n",
    "\n",
    "class CausalTemporalGLU(nn.Module):\n",
    "    \"\"\"\n",
    "    Causal temporal convolution + GLU gating (STGCN temporal block).\n",
    "    Preserves time length via left padding.\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out, kernel_size=3, dilation=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.pad = (kernel_size - 1) * dilation\n",
    "        self.conv = nn.Conv2d(\n",
    "            c_in, 2*c_out,\n",
    "            kernel_size=(1, kernel_size),\n",
    "            dilation=(1, dilation)\n",
    "        )\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,C,N,T)\n",
    "        x = F.pad(x, (self.pad, 0, 0, 0))  # left pad time only\n",
    "        h = self.conv(x)                   # (B,2C,N,T)\n",
    "        a, b = torch.chunk(h, 2, dim=1)\n",
    "        out = a * torch.sigmoid(b)         # GLU\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        return out\n",
    "\n",
    "class STConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    TemporalGLU -> GraphConv -> TemporalGLU -> BN\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out, supports, kt=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temp1 = CausalTemporalGLU(c_in, c_out, kernel_size=kt, dropout=dropout)\n",
    "        self.gconv = SimpleGraphConv(c_out, c_out, supports, dropout=dropout)\n",
    "        self.temp2 = CausalTemporalGLU(c_out, c_out, kernel_size=kt, dropout=dropout)\n",
    "        self.bn = nn.BatchNorm2d(c_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.temp1(x)\n",
    "        x = self.gconv(x)\n",
    "        x = self.temp2(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "class STGCNEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encodes x -> (B, C, N, T)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim,\n",
    "        supports,\n",
    "        hidden=64,\n",
    "        end_channels=128,\n",
    "        blocks=2,\n",
    "        kt=3,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.start = nn.Conv2d(in_dim, hidden, kernel_size=(1,1))\n",
    "        self.blocks = nn.ModuleList([\n",
    "            STConvBlock(hidden, hidden, supports, kt=kt, dropout=dropout)\n",
    "            for _ in range(blocks)\n",
    "        ])\n",
    "        self.end = nn.Conv2d(hidden, end_channels, kernel_size=(1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,F,N,T)\n",
    "        x = self.start(x)\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = F.relu(self.end(x))\n",
    "        return x  # (B,end_channels,N,T)\n",
    "\n",
    "class STGCNForecast(nn.Module):\n",
    "    \"\"\"\n",
    "    STGCN + optional GRU/LSTM per-node over time + time-aware horizon head.\n",
    "    Output: (B, OUT_LEN, N)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes,\n",
    "        in_dim,\n",
    "        out_len,\n",
    "        supports,\n",
    "        hidden=64,\n",
    "        end_channels=128,\n",
    "        st_blocks=2,\n",
    "        kt=3,\n",
    "        dropout=0.1,\n",
    "        use_gru=False,\n",
    "        use_lstm=False,\n",
    "        rnn_hidden=128,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.out_len = out_len\n",
    "        self.use_gru = use_gru\n",
    "        self.use_lstm = use_lstm\n",
    "\n",
    "        self.encoder = STGCNEncoder(\n",
    "            in_dim=in_dim,\n",
    "            supports=supports,\n",
    "            hidden=hidden,\n",
    "            end_channels=end_channels,\n",
    "            blocks=st_blocks,\n",
    "            kt=kt,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        # RNNs operate on (B*N, T, C)\n",
    "        if use_gru:\n",
    "            self.gru = nn.GRU(end_channels, rnn_hidden, batch_first=True)\n",
    "        else:\n",
    "            self.gru = None\n",
    "\n",
    "        if use_lstm:\n",
    "            self.lstm = nn.LSTM(\n",
    "                (rnn_hidden if use_gru else end_channels),\n",
    "                rnn_hidden,\n",
    "                batch_first=True\n",
    "            )\n",
    "        else:\n",
    "            self.lstm = None\n",
    "\n",
    "        final_dim = rnn_hidden if (use_gru or use_lstm) else end_channels\n",
    "\n",
    "        self.time_embed = nn.Linear(4, final_dim)\n",
    "        self.horizon_out = nn.Linear(final_dim, 1)\n",
    "\n",
    "    def forward(self, x, tf_future):\n",
    "        \"\"\"\n",
    "        x: (B,F,N,T_in)\n",
    "        tf_future: (B, OUT_LEN, 4)\n",
    "        \"\"\"\n",
    "        h = self.encoder(x)  # (B,C,N,T)\n",
    "        B, C, N, T = h.shape\n",
    "\n",
    "        # per-node sequences\n",
    "        seq = h.permute(0, 2, 3, 1).contiguous().view(B*N, T, C)  # (B*N,T,C)\n",
    "\n",
    "        if self.gru is not None:\n",
    "            seq, _ = self.gru(seq)           # (B*N,T,H)\n",
    "\n",
    "        if self.lstm is not None:\n",
    "            seq, _ = self.lstm(seq)          # (B*N,T,H)\n",
    "\n",
    "        last = seq[:, -1, :]                 # (B*N,D)\n",
    "        z = last.view(B, N, -1)              # (B,N,D)\n",
    "\n",
    "        te = self.time_embed(tf_future)      # (B,OUT,D)\n",
    "        out = F.relu(z.unsqueeze(1) + te.unsqueeze(2))  # (B,OUT,N,D)\n",
    "        out = self.horizon_out(out).squeeze(-1)         # (B,OUT,N)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3e193cb-b8cc-4c50-992d-6bd1b848d34e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T01:25:49.939321Z",
     "iopub.status.busy": "2026-02-09T01:25:49.938805Z",
     "iopub.status.idle": "2026-02-09T01:25:49.987564Z",
     "shell.execute_reply": "2026-02-09T01:25:49.986892Z",
     "shell.execute_reply.started": "2026-02-09T01:25:49.939297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Recommended starting hyperparams\n",
    "ST_HIDDEN = 64\n",
    "ST_END = 128\n",
    "ST_BLOCKS = 2\n",
    "KT = 3\n",
    "DROP = 0.1\n",
    "RNN_H = 128  # if slow/memory heavy, drop to 64\n",
    "\n",
    "stgcn_base = STGCNForecast(\n",
    "    num_nodes=X.shape[1],\n",
    "    in_dim=X.shape[2],\n",
    "    out_len=OUT_LEN,\n",
    "    supports=supports,\n",
    "    hidden=ST_HIDDEN,\n",
    "    end_channels=ST_END,\n",
    "    st_blocks=ST_BLOCKS,\n",
    "    kt=KT,\n",
    "    dropout=DROP,\n",
    "    use_gru=False,\n",
    "    use_lstm=False,\n",
    "    rnn_hidden=RNN_H,\n",
    ").to(DEVICE)\n",
    "\n",
    "stgcn_gru = STGCNForecast(\n",
    "    num_nodes=X.shape[1],\n",
    "    in_dim=X.shape[2],\n",
    "    out_len=OUT_LEN,\n",
    "    supports=supports,\n",
    "    hidden=ST_HIDDEN,\n",
    "    end_channels=ST_END,\n",
    "    st_blocks=ST_BLOCKS,\n",
    "    kt=KT,\n",
    "    dropout=DROP,\n",
    "    use_gru=True,\n",
    "    use_lstm=False,\n",
    "    rnn_hidden=RNN_H,\n",
    ").to(DEVICE)\n",
    "\n",
    "stgcn_lstm = STGCNForecast(\n",
    "    num_nodes=X.shape[1],\n",
    "    in_dim=X.shape[2],\n",
    "    out_len=OUT_LEN,\n",
    "    supports=supports,\n",
    "    hidden=ST_HIDDEN,\n",
    "    end_channels=ST_END,\n",
    "    st_blocks=ST_BLOCKS,\n",
    "    kt=KT,\n",
    "    dropout=DROP,\n",
    "    use_gru=False,\n",
    "    use_lstm=True,\n",
    "    rnn_hidden=RNN_H,\n",
    ").to(DEVICE)\n",
    "\n",
    "stgcn_gru_lstm = STGCNForecast(\n",
    "    num_nodes=X.shape[1],\n",
    "    in_dim=X.shape[2],\n",
    "    out_len=OUT_LEN,\n",
    "    supports=supports,\n",
    "    hidden=ST_HIDDEN,\n",
    "    end_channels=ST_END,\n",
    "    st_blocks=ST_BLOCKS,\n",
    "    kt=KT,\n",
    "    dropout=DROP,\n",
    "    use_gru=True,\n",
    "    use_lstm=True,\n",
    "    rnn_hidden=RNN_H,\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a364199-09ac-43c7-9c99-819350520dc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T01:27:00.507907Z",
     "iopub.status.busy": "2026-02-09T01:27:00.507486Z",
     "iopub.status.idle": "2026-02-09T01:27:00.833232Z",
     "shell.execute_reply": "2026-02-09T01:27:00.832435Z",
     "shell.execute_reply.started": "2026-02-09T01:27:00.507872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 72, 1821])\n"
     ]
    }
   ],
   "source": [
    "xb, yb, tfb = next(iter(train_loader))\n",
    "out = stgcn_base(xb.to(DEVICE), tfb.to(DEVICE))\n",
    "print(out.shape)  # (B, OUT_LEN, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "065b6b67-1384-4f7e-a345-0f5982d0c837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T01:28:44.588036Z",
     "iopub.status.busy": "2026-02-09T01:28:44.587609Z",
     "iopub.status.idle": "2026-02-09T01:28:44.592751Z",
     "shell.execute_reply": "2026-02-09T01:28:44.591819Z",
     "shell.execute_reply.started": "2026-02-09T01:28:44.588002Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"STGCN\"\n",
    "model = stgcn_base\n",
    "# run your existing train_and_save_best / export block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db4871de-e27d-44d6-8ad8-863d31ae14ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T01:31:05.350459Z",
     "iopub.status.busy": "2026-02-09T01:31:05.349631Z",
     "iopub.status.idle": "2026-02-09T01:31:05.354241Z",
     "shell.execute_reply": "2026-02-09T01:31:05.353392Z",
     "shell.execute_reply.started": "2026-02-09T01:31:05.350431Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"STGCN_GRU\"\n",
    "model = stgcn_gru\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "129c2895-2c10-48ad-abf8-84809da936c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T01:31:32.283244Z",
     "iopub.status.busy": "2026-02-09T01:31:32.282964Z",
     "iopub.status.idle": "2026-02-09T01:31:32.286875Z",
     "shell.execute_reply": "2026-02-09T01:31:32.286148Z",
     "shell.execute_reply.started": "2026-02-09T01:31:32.283223Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"STGCN_LSTM\"\n",
    "model = stgcn_lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff0c265f-bb10-4a6a-a6e4-7e6496f69d46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T01:56:08.740649Z",
     "iopub.status.busy": "2026-02-09T01:56:08.740340Z",
     "iopub.status.idle": "2026-02-09T01:56:08.764103Z",
     "shell.execute_reply": "2026-02-09T01:56:08.763371Z",
     "shell.execute_reply.started": "2026-02-09T01:56:08.740625Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Horizons reported in paper\n",
    "EVAL_HORIZONS = [12, 24, 48, 72]\n",
    "h_idx = torch.tensor([h - 1 for h in EVAL_HORIZONS], device=DEVICE)\n",
    "\n",
    "# Convert scaled error -> original units using std\n",
    "flow_std_t = torch.tensor(flow_std, dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "\n",
    "def print_metrics(title, metrics):\n",
    "    print(\"\\n\" + title)\n",
    "    for h in sorted(metrics.keys()):\n",
    "        print(f\"  {h:>3}h  MAE={metrics[h]['MAE']:.3f}  RMSE={metrics[h]['RMSE']:.3f}\")\n",
    "\n",
    "@torch.inference_mode()\n",
    "def eval_horizons_fast(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluates MAE/RMSE at specific horizons in ORIGINAL units.\n",
    "    Assumes:\n",
    "      - yb is scaled target\n",
    "      - model output is scaled predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    acc = {h: {\"abs\": 0.0, \"sq\": 0.0, \"count\": 0} for h in EVAL_HORIZONS}\n",
    "\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Eval\", leave=True):\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        pred = model(xb, tfb)  # (B, OUT_LEN, N), scaled\n",
    "\n",
    "        # Original units error at selected horizons\n",
    "        err = (pred[:, h_idx, :] - yb[:, h_idx, :]) * flow_std_t  # (B, H, N)\n",
    "\n",
    "        abs_err = err.abs()\n",
    "        sq_err  = err * err\n",
    "\n",
    "        for k, h in enumerate(EVAL_HORIZONS):\n",
    "            acc[h][\"abs\"]   += float(abs_err[:, k, :].sum())\n",
    "            acc[h][\"sq\"]    += float(sq_err[:, k, :].sum())\n",
    "            acc[h][\"count\"] += abs_err[:, k, :].numel()\n",
    "\n",
    "    metrics = {}\n",
    "    for h in EVAL_HORIZONS:\n",
    "        mae  = acc[h][\"abs\"] / acc[h][\"count\"]\n",
    "        rmse = (acc[h][\"sq\"] / acc[h][\"count\"]) ** 0.5\n",
    "        metrics[h] = {\"MAE\": mae, \"RMSE\": rmse}\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c91912f-d63b-4f4a-949b-2b557d006176",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T01:50:13.522873Z",
     "iopub.status.busy": "2026-02-09T01:50:13.522580Z",
     "iopub.status.idle": "2026-02-09T01:50:13.556092Z",
     "shell.execute_reply": "2026-02-09T01:50:13.555215Z",
     "shell.execute_reply.started": "2026-02-09T01:50:13.522839Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ---------- File/Run utilities ----------\n",
    "def make_run_dir(model_name: str, root: str = \"artifacts/runs\") -> Path:\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    safe = \"\".join([c if c.isalnum() or c in \"-_.\" else \"_\" for c in model_name])\n",
    "    run_dir = Path(root) / f\"{ts}_{safe}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def save_json(path: Path, obj: dict):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, default=str)\n",
    "\n",
    "def append_summary_csv(summary_csv: Path, row: dict):\n",
    "    summary_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.DataFrame([row])\n",
    "    if summary_csv.exists():\n",
    "        old = pd.read_csv(summary_csv)\n",
    "        out = pd.concat([old, df], ignore_index=True)\n",
    "    else:\n",
    "        out = df\n",
    "    out.to_csv(summary_csv, index=False)\n",
    "\n",
    "def _excel_engine():\n",
    "    try:\n",
    "        import xlsxwriter  # noqa: F401\n",
    "        return \"xlsxwriter\"\n",
    "    except Exception:\n",
    "        return \"openpyxl\"\n",
    "\n",
    "def export_preds_to_excel(\n",
    "    excel_path: Path,\n",
    "    pred: np.ndarray,\n",
    "    true: np.ndarray,\n",
    "    times: np.ndarray,\n",
    "    horizons,\n",
    "    stations,\n",
    "    max_stations_excel: int | None = 300,\n",
    "):\n",
    "    engine = _excel_engine()\n",
    "    stations = [str(s) for s in stations]\n",
    "\n",
    "    if max_stations_excel is not None:\n",
    "        stations = stations[:max_stations_excel]\n",
    "        pred = pred[:, :, :max_stations_excel]\n",
    "        true = true[:, :, :max_stations_excel]\n",
    "\n",
    "    with pd.ExcelWriter(excel_path, engine=engine) as writer:\n",
    "        pd.DataFrame({\"station\": stations}).to_excel(writer, sheet_name=\"stations\", index=False)\n",
    "        for k, h in enumerate(horizons):\n",
    "            tcol = pd.to_datetime(times[:, k])\n",
    "\n",
    "            pred_df = pd.DataFrame(pred[:, k, :], columns=stations)\n",
    "            pred_df.insert(0, \"target_time\", tcol)\n",
    "            pred_df.to_excel(writer, sheet_name=f\"pred_h{h}\", index=False)\n",
    "\n",
    "            true_df = pd.DataFrame(true[:, k, :], columns=stations)\n",
    "            true_df.insert(0, \"target_time\", tcol)\n",
    "            true_df.to_excel(writer, sheet_name=f\"true_h{h}\", index=False)\n",
    "\n",
    "# ---------- Trainer (uses your eval_horizons_fast) ----------\n",
    "def train_and_save_best(\n",
    "    model,\n",
    "    model_name: str,\n",
    "    run_dir: Path,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    eval_fn,   # eval_horizons_fast\n",
    "    device: str,\n",
    "    epochs=40,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    clip=5.0,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    "):\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    save_json(run_dir / \"config.json\", {\n",
    "        \"model_name\": model_name,\n",
    "        \"epochs\": epochs,\n",
    "        \"lr\": lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"clip\": clip,\n",
    "        \"patience\": patience,\n",
    "        \"eval_every\": eval_every,\n",
    "        \"timestamp\": str(datetime.now()),\n",
    "    })\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.SmoothL1Loss(beta=1.0)\n",
    "\n",
    "    best_score = float(\"inf\")\n",
    "    best_state = None\n",
    "    best_val_metrics = None\n",
    "    bad = 0\n",
    "\n",
    "    history = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "\n",
    "        for xb, yb, tfb in tqdm(train_loader, desc=f\"Train {epoch}/{epochs}\", leave=True):\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            tfb = tfb.to(device, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            pred = model(xb, tfb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "            running += float(loss.item())\n",
    "\n",
    "        row = {\"epoch\": epoch, \"train_loss\": running / max(len(train_loader), 1)}\n",
    "        print(f\"\\nEpoch {epoch}: train_loss={row['train_loss']:.6f}\")\n",
    "\n",
    "        if (epoch % eval_every == 0) or (epoch == epochs):\n",
    "            val_metrics = eval_fn(model, val_loader)\n",
    "            val_avg = float(np.mean([val_metrics[h][\"MAE\"] for h in val_metrics]))\n",
    "            row[\"val_avg_MAE\"] = val_avg\n",
    "            for h in sorted(val_metrics.keys()):\n",
    "                row[f\"val_MAE_{h}h\"] = float(val_metrics[h][\"MAE\"])\n",
    "                row[f\"val_RMSE_{h}h\"] = float(val_metrics[h][\"RMSE\"])\n",
    "            print(f\"Epoch {epoch}: val_avg_MAE={val_avg:.3f}\")\n",
    "\n",
    "            if val_avg < best_score:\n",
    "                best_score = val_avg\n",
    "                best_val_metrics = val_metrics\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "                torch.save(\n",
    "                    {\"model_name\": model_name, \"epoch\": epoch, \"best_val_avg_MAE\": best_score, \"state_dict\": best_state},\n",
    "                    run_dir / \"best.pt\"\n",
    "                )\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= patience:\n",
    "                    print(f\"\\nEarly stopping. Best val_avg_MAE={best_score:.3f}\")\n",
    "                    history.append(row)\n",
    "                    break\n",
    "\n",
    "        history.append(row)\n",
    "        pd.DataFrame(history).to_csv(run_dir / \"history.csv\", index=False)\n",
    "\n",
    "    # load best checkpoint\n",
    "    best_path = run_dir / \"best.pt\"\n",
    "    if best_path.exists():\n",
    "        ckpt = torch.load(best_path, map_location=\"cpu\")\n",
    "        model.load_state_dict(ckpt[\"state_dict\"])\n",
    "\n",
    "    save_json(run_dir / \"train_summary.json\", {\n",
    "        \"train_seconds\": time.time() - t0,\n",
    "        \"best_val_avg_MAE\": best_score\n",
    "    })\n",
    "    return model, pd.read_csv(run_dir / \"history.csv\"), best_val_metrics\n",
    "\n",
    "# ---------- Prediction collector (selected horizons) ----------\n",
    "@torch.inference_mode()\n",
    "def collect_predictions_for_horizons(\n",
    "    model,\n",
    "    loader,\n",
    "    horizons,\n",
    "    stations,\n",
    "    timestamps,\n",
    "    in_len,\n",
    "    flow_mean,\n",
    "    flow_std,\n",
    "    device,\n",
    "):\n",
    "    horizons = list(horizons)\n",
    "    h_idx = np.array([h - 1 for h in horizons], dtype=np.int32)\n",
    "\n",
    "    ds = loader.dataset\n",
    "    if not hasattr(ds, \"starts\"):\n",
    "        raise AttributeError(\"loader.dataset must have attribute `.starts` to reconstruct timestamps per window.\")\n",
    "    starts = ds.starts\n",
    "\n",
    "    flow_mean = flow_mean.astype(np.float32)\n",
    "    flow_std  = flow_std.astype(np.float32)\n",
    "\n",
    "    preds_list, trues_list, times_list = [], [], []\n",
    "    offset = 0\n",
    "\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Collect preds\", leave=True):\n",
    "        B = xb.shape[0]\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        tfb = tfb.to(device, non_blocking=True)\n",
    "\n",
    "        pred_scaled = model(xb, tfb).detach().cpu().numpy().astype(np.float32)  # (B, OUT, N)\n",
    "        true_scaled = yb.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "        pred_sel = pred_scaled[:, h_idx, :] * flow_std[None, None, :] + flow_mean[None, None, :]\n",
    "        true_sel = true_scaled[:, h_idx, :] * flow_std[None, None, :] + flow_mean[None, None, :]\n",
    "\n",
    "        preds_list.append(pred_sel.astype(np.float32))\n",
    "        trues_list.append(true_sel.astype(np.float32))\n",
    "\n",
    "        batch_times = np.zeros((B, len(horizons)), dtype=\"datetime64[ns]\")\n",
    "        for j in range(B):\n",
    "            t0 = int(starts[offset + j])\n",
    "            target_indices = t0 + int(in_len) + h_idx\n",
    "            batch_times[j, :] = np.array(pd.to_datetime(timestamps[target_indices]).astype(\"datetime64[ns]\"))\n",
    "        times_list.append(batch_times)\n",
    "\n",
    "        offset += B\n",
    "\n",
    "    pred = np.concatenate(preds_list, axis=0)\n",
    "    true = np.concatenate(trues_list, axis=0)\n",
    "    times = np.concatenate(times_list, axis=0)\n",
    "    return pred, true, times, horizons\n",
    "\n",
    "# ---------- One-call experiment runner ----------\n",
    "def run_experiment_and_save(\n",
    "    model_name: str,\n",
    "    model,\n",
    "    device: str,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    eval_fn,             # eval_horizons_fast\n",
    "    print_metrics_fn,    # print_metrics\n",
    "    stations,\n",
    "    timestamps,\n",
    "    in_len,\n",
    "    flow_mean,\n",
    "    flow_std,\n",
    "    epochs=40,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    "    horizons_to_save=(12, 24, 48, 72),\n",
    "    max_stations_excel=300,\n",
    "):\n",
    "    run_dir = make_run_dir(model_name)\n",
    "    print(\"Run dir:\", run_dir)\n",
    "\n",
    "    # 1) Train\n",
    "    model = model.to(device)\n",
    "    model, history_df, best_val_metrics = train_and_save_best(\n",
    "        model=model,\n",
    "        model_name=model_name,\n",
    "        run_dir=run_dir,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        eval_fn=eval_fn,\n",
    "        device=device,\n",
    "        epochs=epochs,\n",
    "        patience=patience,\n",
    "        eval_every=eval_every,\n",
    "    )\n",
    "\n",
    "    # 2) Test metrics saved immediately\n",
    "    print(\"Evaluating on TEST set...\")\n",
    "    test_metrics = eval_fn(model, test_loader)\n",
    "    print_metrics_fn(f\"{model_name} — Test\", test_metrics)\n",
    "    save_json(run_dir / \"test_metrics.json\", {\"test_metrics\": test_metrics})\n",
    "    pd.DataFrame([{\n",
    "        \"model_name\": model_name,\n",
    "        \"run_dir\": str(run_dir),\n",
    "        **{f\"test_MAE_{h}h\": float(test_metrics[h][\"MAE\"]) for h in sorted(test_metrics.keys())},\n",
    "        **{f\"test_RMSE_{h}h\": float(test_metrics[h][\"RMSE\"]) for h in sorted(test_metrics.keys())},\n",
    "    }]).to_csv(run_dir / \"test_metrics.csv\", index=False)\n",
    "\n",
    "    # master summary\n",
    "    row = {\"model_name\": model_name, \"run_dir\": str(run_dir)}\n",
    "    for h in sorted(test_metrics.keys()):\n",
    "        row[f\"test_MAE_{h}h\"] = float(test_metrics[h][\"MAE\"])\n",
    "        row[f\"test_RMSE_{h}h\"] = float(test_metrics[h][\"RMSE\"])\n",
    "    append_summary_csv(Path(\"artifacts/results_summary.csv\"), row)\n",
    "\n",
    "    # 3) Predictions (NPZ always), Excel best-effort\n",
    "    try:\n",
    "        pred, true, times, horizons = collect_predictions_for_horizons(\n",
    "            model=model,\n",
    "            loader=test_loader,\n",
    "            horizons=horizons_to_save,\n",
    "            stations=stations,\n",
    "            timestamps=timestamps,\n",
    "            in_len=in_len,\n",
    "            flow_mean=flow_mean,\n",
    "            flow_std=flow_std,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        np.savez_compressed(\n",
    "            run_dir / \"test_pred_true_selected_horizons.npz\",\n",
    "            pred=pred, true=true, times=times,\n",
    "            horizons=np.array(horizons, dtype=np.int32),\n",
    "            stations=stations,\n",
    "        )\n",
    "\n",
    "        export_preds_to_excel(\n",
    "            excel_path=run_dir / \"test_pred_true_selected_horizons.xlsx\",\n",
    "            pred=pred, true=true, times=times,\n",
    "            horizons=horizons, stations=stations,\n",
    "            max_stations_excel=max_stations_excel,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Prediction export failed (metrics already saved):\", repr(e))\n",
    "        with open(run_dir / \"pred_export_error.txt\", \"w\") as f:\n",
    "            f.write(repr(e))\n",
    "\n",
    "    print(\"\\nDONE. Saved outputs in:\", run_dir)\n",
    "    return run_dir, test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5e61812-836a-4a99-8ddc-4780784d1696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T01:56:38.275877Z",
     "iopub.status.busy": "2026-02-09T01:56:38.275558Z",
     "iopub.status.idle": "2026-02-09T02:07:35.462403Z",
     "shell.execute_reply": "2026-02-09T02:07:35.461314Z",
     "shell.execute_reply.started": "2026-02-09T01:56:38.275854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run dir: artifacts/runs/20260209_015638_STGCN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117a93bdc00648a59a2dab1873662918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: train_loss=0.197108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4847b5a6bdac43f5944fe41dd801a09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 2/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.127995\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5061d3f87e482aaf71a0dfd0a5ecab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: val_avg_MAE=7263.597\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ffd9e22fd54398b1b3023671ba54ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 3/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: train_loss=0.113510\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3adefddeac724bfc8406a8e7dba6089b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 4/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=0.105284\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cb43da2de64ff892b0316b8c009fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: val_avg_MAE=29297.267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e16f31834b410d9cd909546ed851ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 5/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: train_loss=0.100544\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddacd84099ea40cc9404f0b93b7ec91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 6/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: train_loss=0.097170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8433c3c91f24dd3a1b676d6cfeae10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: val_avg_MAE=24280.974\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4cb9053f152409da083045be4715696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 7/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: train_loss=0.094620\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c16e7d3fcb47f79a41ce161159d111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 8/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: train_loss=0.093069\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f264465bbc8c484fac299a9ac1089981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: val_avg_MAE=17905.704\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224781235b424b429654e605a468bde5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 9/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: train_loss=0.091367\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c5bbd4d7af4180a831f6d509979ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 10/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: train_loss=0.090104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7546acb4d614aab91201bb00b2b8d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: val_avg_MAE=29436.580\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0f9f6cadf34c3dadc5e6572b6aeb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 11/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: train_loss=0.089176\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67617e9587d449618449903cb1c568b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 12/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: train_loss=0.088238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702ceb5477064f4f964e670875c1fcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: val_avg_MAE=37901.065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0fbcd6e3a6c4f53b9c8085751265f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 13/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: train_loss=0.087290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa8ff998a934ef784b03e0bd91f34fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 14/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: train_loss=0.087152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd6707ed64a43dfbecc654f11ed190b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: val_avg_MAE=36249.339\n",
      "\n",
      "Early stopping. Best val_avg_MAE=7263.597\n",
      "Evaluating on TEST set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b391757eca54bafbd6dbe40bd5b15d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STGCN — Test\n",
      "   12h  MAE=8775.112  RMSE=295355.097\n",
      "   24h  MAE=8771.100  RMSE=295357.880\n",
      "   48h  MAE=8771.417  RMSE=295357.973\n",
      "   72h  MAE=8770.536  RMSE=295358.391\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358c25dacfab4677b58673f6834709ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collect preds:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE. Saved outputs in: artifacts/runs/20260209_015638_STGCN\n"
     ]
    }
   ],
   "source": [
    "model_name = \"STGCN\"\n",
    "model = stgcn_base\n",
    "\n",
    "run_dir, test_metrics = run_experiment_and_save(\n",
    "    model_name=model_name,\n",
    "    model=model,\n",
    "    device=DEVICE,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    eval_fn=eval_horizons_fast,\n",
    "    print_metrics_fn=print_metrics,\n",
    "    stations=stations,\n",
    "    timestamps=timestamps,\n",
    "    in_len=IN_LEN,\n",
    "    flow_mean=flow_mean,\n",
    "    flow_std=flow_std,\n",
    "    epochs=40,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    "    horizons_to_save=(12, 24, 48, 72),\n",
    "    max_stations_excel=300,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239d9c40-304e-458b-a0d0-8a2dcc1eef32",
   "metadata": {},
   "source": [
    "# STGCN Models (Baseline + Ablations)\n",
    "\n",
    "This notebook trains and evaluates:\n",
    "- STGCN\n",
    "- STGCN-GRU\n",
    "- STGCN-LSTM\n",
    "- STGCN-GRU-LSTM\n",
    "\n",
    "We use the same dataset artifact, splits, scaling, and evaluation horizons as the GraphWaveNet experiments.\n",
    "All outputs are saved under `artifacts/runs/` so results are not lost across Paperspace sessions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a43091db-ff19-41ad-b224-2a10ff4c09b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T02:35:36.979809Z",
     "iopub.status.busy": "2026-02-09T02:35:36.979443Z",
     "iopub.status.idle": "2026-02-09T02:35:36.986873Z",
     "shell.execute_reply": "2026-02-09T02:35:36.986092Z",
     "shell.execute_reply.started": "2026-02-09T02:35:36.979781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.1.1+cu121\n",
      "Device: cuda\n",
      "GPU: Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Device:\", DEVICE)\n",
    "if DEVICE == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34ca912f-9943-4872-9199-340c63cfb248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T02:36:05.338766Z",
     "iopub.status.busy": "2026-02-09T02:36:05.338375Z",
     "iopub.status.idle": "2026-02-09T02:36:05.906290Z",
     "shell.execute_reply": "2026-02-09T02:36:05.905218Z",
     "shell.execute_reply.started": "2026-02-09T02:36:05.338728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: artifacts/pems_graph_dataset_strict.npz\n",
      "Keys: ['X', 'Y', 'A', 'stations', 'timestamps', 'train_starts', 'val_starts', 'test_starts', 'in_len', 'out_len', 'flow_mean', 'flow_std', 'speed_mean', 'speed_std']\n",
      "\n",
      "Shapes:\n",
      "X: (2208, 1821, 6) (T,N,F)\n",
      "Y: (2208, 1821) (T,N)\n",
      "Stations: 1821\n",
      "Timestamp range: 2024-10-01 00:00:00 → 2024-12-31 23:00:00\n",
      "IN_LEN: 24 OUT_LEN: 72\n",
      "Window starts: 1009 289 673\n",
      "A: (1821, 1821) density: 0.0023693916932872663\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = Path(\"artifacts/pems_graph_dataset_strict.npz\")\n",
    "if not DATASET_PATH.exists():\n",
    "    # fallback (if strict doesn't exist)\n",
    "    DATASET_PATH = Path(\"artifacts/pems_graph_dataset.npz\")\n",
    "\n",
    "assert DATASET_PATH.exists(), f\"Dataset file not found: {DATASET_PATH}\"\n",
    "\n",
    "d = np.load(DATASET_PATH, allow_pickle=True)\n",
    "print(\"Loaded:\", DATASET_PATH)\n",
    "print(\"Keys:\", d.files)\n",
    "\n",
    "X = d[\"X\"].astype(np.float32)                 # (T, N, F)\n",
    "Y = d[\"Y\"].astype(np.float32)                 # (T, N)\n",
    "stations = d[\"stations\"]\n",
    "timestamps = pd.to_datetime(d[\"timestamps\"])\n",
    "\n",
    "train_starts = d[\"train_starts\"].astype(np.int32)\n",
    "val_starts   = d[\"val_starts\"].astype(np.int32)\n",
    "test_starts  = d[\"test_starts\"].astype(np.int32)\n",
    "\n",
    "IN_LEN  = int(d[\"in_len\"][0])\n",
    "OUT_LEN = int(d[\"out_len\"][0])\n",
    "\n",
    "flow_mean  = d[\"flow_mean\"].astype(np.float32)\n",
    "flow_std   = d[\"flow_std\"].astype(np.float32)\n",
    "speed_mean = d[\"speed_mean\"].astype(np.float32)\n",
    "speed_std  = d[\"speed_std\"].astype(np.float32)\n",
    "\n",
    "print(\"\\nShapes:\")\n",
    "print(\"X:\", X.shape, \"(T,N,F)\")\n",
    "print(\"Y:\", Y.shape, \"(T,N)\")\n",
    "print(\"Stations:\", len(stations))\n",
    "print(\"Timestamp range:\", timestamps.min(), \"→\", timestamps.max())\n",
    "print(\"IN_LEN:\", IN_LEN, \"OUT_LEN:\", OUT_LEN)\n",
    "print(\"Window starts:\", len(train_starts), len(val_starts), len(test_starts))\n",
    "\n",
    "# Adjacency matrix (if present)\n",
    "A = None\n",
    "if \"A\" in d.files:\n",
    "    A = d[\"A\"].astype(np.float32)\n",
    "    print(\"A:\", A.shape, \"density:\", float((A > 0).mean()))\n",
    "else:\n",
    "    print(\"WARNING: 'A' not in dataset npz. You must rebuild adjacency supports separately.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88029b34-ecc8-45fd-a539-c34ed40477d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T02:36:39.501376Z",
     "iopub.status.busy": "2026-02-09T02:36:39.500934Z",
     "iopub.status.idle": "2026-02-09T02:36:39.615895Z",
     "shell.execute_reply": "2026-02-09T02:36:39.615062Z",
     "shell.execute_reply.started": "2026-02-09T02:36:39.501341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supports nnz: [7852, 7852]\n"
     ]
    }
   ],
   "source": [
    "def dense_to_sparse(A_dense: np.ndarray, device: str):\n",
    "    idx = np.nonzero(A_dense)\n",
    "    values = A_dense[idx].astype(np.float32)\n",
    "    indices = np.vstack(idx)\n",
    "    sp = torch.sparse_coo_tensor(\n",
    "        torch.tensor(indices, dtype=torch.long, device=device),\n",
    "        torch.tensor(values, dtype=torch.float32, device=device),\n",
    "        size=A_dense.shape,\n",
    "        device=device\n",
    "    ).coalesce()\n",
    "    return sp\n",
    "\n",
    "def row_normalize(A_dense: np.ndarray, eps=1e-6):\n",
    "    d = A_dense.sum(axis=1, keepdims=True)\n",
    "    return A_dense / (d + eps)\n",
    "\n",
    "assert A is not None, \"Adjacency A not found in NPZ. Rebuild A first, then come back here.\"\n",
    "\n",
    "# Add self-loops (important for stability in many GNNs)\n",
    "A_hat = A + np.eye(A.shape[0], dtype=np.float32)\n",
    "\n",
    "# Keep same style as earlier (directed supports)\n",
    "A_rw  = row_normalize(A_hat)\n",
    "A_rwT = row_normalize(A_hat.T)\n",
    "\n",
    "supports = [dense_to_sparse(A_rw, DEVICE), dense_to_sparse(A_rwT, DEVICE)]\n",
    "print(\"Supports nnz:\", [int(s._nnz()) for s in supports])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55479141-549d-47a4-940b-32f6b3a02a92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T02:36:52.237133Z",
     "iopub.status.busy": "2026-02-09T02:36:52.236734Z",
     "iopub.status.idle": "2026-02-09T02:36:52.570598Z",
     "shell.execute_reply": "2026-02-09T02:36:52.569767Z",
     "shell.execute_reply.started": "2026-02-09T02:36:52.237095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_fnt: (6, 1821, 2208) Y_scaled: (2208, 1821) TF_all: (2208, 4)\n"
     ]
    }
   ],
   "source": [
    "def time_encoding(dt_index: pd.DatetimeIndex) -> np.ndarray:\n",
    "    hours = dt_index.hour.values\n",
    "    dow   = dt_index.dayofweek.values\n",
    "    hour_sin = np.sin(2*np.pi*hours/24.0)\n",
    "    hour_cos = np.cos(2*np.pi*hours/24.0)\n",
    "    dow_sin  = np.sin(2*np.pi*dow/7.0)\n",
    "    dow_cos  = np.cos(2*np.pi*dow/7.0)\n",
    "    return np.stack([hour_sin, hour_cos, dow_sin, dow_cos], axis=1).astype(np.float32)\n",
    "\n",
    "TF_all = time_encoding(pd.DatetimeIndex(timestamps))\n",
    "\n",
    "# Scale X channels: assume channel0=flow, channel1=speed (as in your pipeline)\n",
    "X_scaled = X.copy()\n",
    "X_scaled[:, :, 0] = (X_scaled[:, :, 0] - flow_mean[None, :]) / flow_std[None, :]\n",
    "X_scaled[:, :, 1] = (X_scaled[:, :, 1] - speed_mean[None, :]) / speed_std[None, :]\n",
    "\n",
    "# Scale targets (flow)\n",
    "Y_scaled = (Y - flow_mean[None, :]) / flow_std[None, :]\n",
    "\n",
    "# Store X as (F, N, T) for fast slicing\n",
    "X_fnt = np.transpose(X_scaled, (2, 1, 0)).copy()  # (F,N,T)\n",
    "print(\"X_fnt:\", X_fnt.shape, \"Y_scaled:\", Y_scaled.shape, \"TF_all:\", TF_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a046ae8b-4e8b-48c8-846f-6ad00f2e8187",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T02:37:23.226190Z",
     "iopub.status.busy": "2026-02-09T02:37:23.225493Z",
     "iopub.status.idle": "2026-02-09T02:37:23.428569Z",
     "shell.execute_reply": "2026-02-09T02:37:23.426676Z",
     "shell.execute_reply.started": "2026-02-09T02:37:23.226158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x: torch.Size([8, 6, 1821, 24]) Batch y: torch.Size([8, 72, 1821]) Batch tf: torch.Size([8, 72, 4])\n"
     ]
    }
   ],
   "source": [
    "class FastPemsWindowDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      x  = (F, N, IN_LEN)\n",
    "      y  = (OUT_LEN, N)\n",
    "      tf = (OUT_LEN, 4)\n",
    "    \"\"\"\n",
    "    def __init__(self, X_fnt, Y_scaled, TF_all, starts, in_len, out_len):\n",
    "        self.X_fnt = X_fnt\n",
    "        self.Ys = Y_scaled\n",
    "        self.TF = TF_all\n",
    "        self.starts = starts.astype(np.int32)\n",
    "        self.in_len = int(in_len)\n",
    "        self.out_len = int(out_len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.starts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = int(self.starts[idx])\n",
    "        x = self.X_fnt[:, :, t:t+self.in_len]\n",
    "        y = self.Ys[t+self.in_len:t+self.in_len+self.out_len, :]\n",
    "        tf = self.TF[t+self.in_len:t+self.in_len+self.out_len, :]\n",
    "        return torch.from_numpy(x), torch.from_numpy(y), torch.from_numpy(tf)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "train_ds = FastPemsWindowDataset(X_fnt, Y_scaled, TF_all, train_starts, IN_LEN, OUT_LEN)\n",
    "val_ds   = FastPemsWindowDataset(X_fnt, Y_scaled, TF_all, val_starts,   IN_LEN, OUT_LEN)\n",
    "test_ds  = FastPemsWindowDataset(X_fnt, Y_scaled, TF_all, test_starts,  IN_LEN, OUT_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True,\n",
    "                          persistent_workers=(NUM_WORKERS > 0))\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True,\n",
    "                          persistent_workers=(NUM_WORKERS > 0))\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True,\n",
    "                          persistent_workers=(NUM_WORKERS > 0))\n",
    "\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "print(\"Batch x:\", xb.shape, \"Batch y:\", yb.shape, \"Batch tf:\", tfb.shape)\n",
    "# Expect: x=(B,F,N,IN_LEN), y=(B,OUT_LEN,N), tf=(B,OUT_LEN,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b30bb04-d098-444e-8bec-322b8b37ee24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T02:38:03.373931Z",
     "iopub.status.busy": "2026-02-09T02:38:03.372941Z",
     "iopub.status.idle": "2026-02-09T02:38:03.402482Z",
     "shell.execute_reply": "2026-02-09T02:38:03.401482Z",
     "shell.execute_reply.started": "2026-02-09T02:38:03.373867Z"
    }
   },
   "outputs": [],
   "source": [
    "EVAL_HORIZONS = [12, 24, 48, 72]\n",
    "h_idx = torch.tensor([h - 1 for h in EVAL_HORIZONS], device=DEVICE)\n",
    "flow_std_t = torch.tensor(flow_std, dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "\n",
    "def print_metrics(title, metrics):\n",
    "    print(\"\\n\" + title)\n",
    "    for h in sorted(metrics.keys()):\n",
    "        print(f\"  {h:>3}h  MAE={metrics[h]['MAE']:.3f}  RMSE={metrics[h]['RMSE']:.3f}\")\n",
    "\n",
    "@torch.inference_mode()\n",
    "def eval_horizons_fast(model, loader):\n",
    "    model.eval()\n",
    "    acc = {h: {\"abs\": 0.0, \"sq\": 0.0, \"count\": 0} for h in EVAL_HORIZONS}\n",
    "\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Eval\", leave=True):\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        pred = model(xb, tfb)  # scaled (B,OUT,N)\n",
    "\n",
    "        err = (pred[:, h_idx, :] - yb[:, h_idx, :]) * flow_std_t  # original units\n",
    "        abs_err = err.abs()\n",
    "        sq_err  = err * err\n",
    "\n",
    "        for k, h in enumerate(EVAL_HORIZONS):\n",
    "            acc[h][\"abs\"] += float(abs_err[:, k, :].sum())\n",
    "            acc[h][\"sq\"]  += float(sq_err[:, k, :].sum())\n",
    "            acc[h][\"count\"] += abs_err[:, k, :].numel()\n",
    "\n",
    "    metrics = {}\n",
    "    for h in EVAL_HORIZONS:\n",
    "        mae = acc[h][\"abs\"] / acc[h][\"count\"]\n",
    "        rmse = (acc[h][\"sq\"] / acc[h][\"count\"]) ** 0.5\n",
    "        metrics[h] = {\"MAE\": mae, \"RMSE\": rmse}\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d981ca68-ed08-46da-b2a9-202015a9a6ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T02:38:28.800016Z",
     "iopub.status.busy": "2026-02-09T02:38:28.799738Z",
     "iopub.status.idle": "2026-02-09T02:38:28.828774Z",
     "shell.execute_reply": "2026-02-09T02:38:28.827907Z",
     "shell.execute_reply.started": "2026-02-09T02:38:28.799995Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_run_dir(model_name: str, root: str = \"artifacts/runs\") -> Path:\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    safe = \"\".join([c if c.isalnum() or c in \"-_.\" else \"_\" for c in model_name])\n",
    "    run_dir = Path(root) / f\"{ts}_{safe}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def save_json(path: Path, obj: dict):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, default=str)\n",
    "\n",
    "def append_summary_csv(summary_csv: Path, row: dict):\n",
    "    summary_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.DataFrame([row])\n",
    "    if summary_csv.exists():\n",
    "        old = pd.read_csv(summary_csv)\n",
    "        out = pd.concat([old, df], ignore_index=True)\n",
    "    else:\n",
    "        out = df\n",
    "    out.to_csv(summary_csv, index=False)\n",
    "\n",
    "def _excel_engine():\n",
    "    try:\n",
    "        import xlsxwriter  # noqa: F401\n",
    "        return \"xlsxwriter\"\n",
    "    except Exception:\n",
    "        return \"openpyxl\"\n",
    "\n",
    "def export_preds_to_excel(excel_path: Path, pred, true, times, horizons, stations, max_stations_excel=300):\n",
    "    engine = _excel_engine()\n",
    "    stations = [str(s) for s in stations]\n",
    "\n",
    "    if max_stations_excel is not None:\n",
    "        stations = stations[:max_stations_excel]\n",
    "        pred = pred[:, :, :max_stations_excel]\n",
    "        true = true[:, :, :max_stations_excel]\n",
    "\n",
    "    with pd.ExcelWriter(excel_path, engine=engine) as writer:\n",
    "        pd.DataFrame({\"station\": stations}).to_excel(writer, sheet_name=\"stations\", index=False)\n",
    "        for k, h in enumerate(horizons):\n",
    "            tcol = pd.to_datetime(times[:, k])\n",
    "\n",
    "            pred_df = pd.DataFrame(pred[:, k, :], columns=stations)\n",
    "            pred_df.insert(0, \"target_time\", tcol)\n",
    "            pred_df.to_excel(writer, sheet_name=f\"pred_h{h}\", index=False)\n",
    "\n",
    "            true_df = pd.DataFrame(true[:, k, :], columns=stations)\n",
    "            true_df.insert(0, \"target_time\", tcol)\n",
    "            true_df.to_excel(writer, sheet_name=f\"true_h{h}\", index=False)\n",
    "\n",
    "@torch.inference_mode()\n",
    "def collect_predictions_for_horizons(model, loader, horizons, stations, timestamps, in_len, flow_mean, flow_std):\n",
    "    horizons = list(horizons)\n",
    "    h_idx_np = np.array([h - 1 for h in horizons], dtype=np.int32)\n",
    "\n",
    "    ds = loader.dataset\n",
    "    starts = ds.starts\n",
    "\n",
    "    preds_list, trues_list, times_list = [], [], []\n",
    "    offset = 0\n",
    "\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Collect preds\", leave=True):\n",
    "        B = xb.shape[0]\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        pred_scaled = model(xb, tfb).detach().cpu().numpy().astype(np.float32)  # (B,OUT,N)\n",
    "        true_scaled = yb.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "        pred_sel = pred_scaled[:, h_idx_np, :] * flow_std[None, None, :] + flow_mean[None, None, :]\n",
    "        true_sel = true_scaled[:, h_idx_np, :] * flow_std[None, None, :] + flow_mean[None, None, :]\n",
    "\n",
    "        preds_list.append(pred_sel)\n",
    "        trues_list.append(true_sel)\n",
    "\n",
    "        batch_times = np.zeros((B, len(horizons)), dtype=\"datetime64[ns]\")\n",
    "        for j in range(B):\n",
    "            t0 = int(starts[offset + j])\n",
    "            target_indices = t0 + int(in_len) + h_idx_np\n",
    "            batch_times[j, :] = np.array(pd.to_datetime(timestamps[target_indices]).astype(\"datetime64[ns]\"))\n",
    "        times_list.append(batch_times)\n",
    "\n",
    "        offset += B\n",
    "\n",
    "    pred = np.concatenate(preds_list, axis=0)\n",
    "    true = np.concatenate(trues_list, axis=0)\n",
    "    times = np.concatenate(times_list, axis=0)\n",
    "    return pred, true, times, horizons\n",
    "\n",
    "def train_and_save_best(model, model_name, run_dir, epochs=40, lr=1e-3, weight_decay=1e-4, clip=5.0, patience=6, eval_every=2):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.SmoothL1Loss(beta=1.0)\n",
    "\n",
    "    best_score = float(\"inf\")\n",
    "    best_state = None\n",
    "    bad = 0\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "\n",
    "        for xb, yb, tfb in tqdm(train_loader, desc=f\"Train {epoch}/{epochs}\", leave=True):\n",
    "            xb = xb.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "            tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            pred = model(xb, tfb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "            running += float(loss.item())\n",
    "\n",
    "        row = {\"epoch\": epoch, \"train_loss\": running / max(len(train_loader), 1)}\n",
    "        print(f\"\\nEpoch {epoch}: train_loss={row['train_loss']:.6f}\")\n",
    "\n",
    "        if (epoch % eval_every == 0) or (epoch == epochs):\n",
    "            val_metrics = eval_horizons_fast(model, val_loader)\n",
    "            val_avg = float(np.mean([val_metrics[h][\"MAE\"] for h in val_metrics]))\n",
    "            row[\"val_avg_MAE\"] = val_avg\n",
    "            print(f\"Epoch {epoch}: val_avg_MAE={val_avg:.3f}\")\n",
    "            print_metrics(\"Validation metrics\", val_metrics)\n",
    "\n",
    "            if val_avg < best_score:\n",
    "                best_score = val_avg\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                torch.save({\"model_name\": model_name, \"best_val_avg_MAE\": best_score, \"state_dict\": best_state}, run_dir / \"best.pt\")\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= patience:\n",
    "                    print(f\"\\nEarly stopping. Best val_avg_MAE={best_score:.3f}\")\n",
    "                    history.append(row)\n",
    "                    break\n",
    "\n",
    "        history.append(row)\n",
    "        pd.DataFrame(history).to_csv(run_dir / \"history.csv\", index=False)\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "def run_experiment_and_save(model_name, model, epochs=40, patience=6, eval_every=2, horizons_to_save=(12,24,48,72), max_stations_excel=300):\n",
    "    run_dir = make_run_dir(model_name)\n",
    "    print(\"Run dir:\", run_dir)\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # Train\n",
    "    model = train_and_save_best(model, model_name, run_dir, epochs=epochs, patience=patience, eval_every=eval_every)\n",
    "\n",
    "    # Test metrics (save immediately)\n",
    "    print(\"Evaluating on TEST set...\")\n",
    "    test_metrics = eval_horizons_fast(model, test_loader)\n",
    "    print_metrics(f\"{model_name} — Test\", test_metrics)\n",
    "    save_json(run_dir / \"test_metrics.json\", {\"test_metrics\": test_metrics})\n",
    "\n",
    "    row = {\"model_name\": model_name, \"run_dir\": str(run_dir)}\n",
    "    for h in sorted(test_metrics.keys()):\n",
    "        row[f\"test_MAE_{h}h\"] = float(test_metrics[h][\"MAE\"])\n",
    "        row[f\"test_RMSE_{h}h\"] = float(test_metrics[h][\"RMSE\"])\n",
    "    append_summary_csv(Path(\"artifacts/results_summary.csv\"), row)\n",
    "    pd.DataFrame([row]).to_csv(run_dir / \"test_metrics.csv\", index=False)\n",
    "\n",
    "    # Predictions export (best effort)\n",
    "    try:\n",
    "        pred, true, times, horizons = collect_predictions_for_horizons(\n",
    "            model, test_loader, horizons_to_save, stations, timestamps, IN_LEN, flow_mean, flow_std\n",
    "        )\n",
    "        np.savez_compressed(run_dir / \"test_pred_true_selected_horizons.npz\",\n",
    "                            pred=pred, true=true, times=times,\n",
    "                            horizons=np.array(horizons, dtype=np.int32), stations=stations)\n",
    "        export_preds_to_excel(run_dir / \"test_pred_true_selected_horizons.xlsx\",\n",
    "                              pred, true, times, horizons, stations,\n",
    "                              max_stations_excel=max_stations_excel)\n",
    "    except Exception as e:\n",
    "        print(\"Prediction export failed (metrics already saved):\", repr(e))\n",
    "        with open(run_dir / \"pred_export_error.txt\", \"w\") as f:\n",
    "            f.write(repr(e))\n",
    "\n",
    "    print(\"\\nDONE. Saved to:\", run_dir)\n",
    "    return run_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bad283ae-d7ae-48ae-90ea-2a56f91bacd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T02:38:58.380801Z",
     "iopub.status.busy": "2026-02-09T02:38:58.380441Z",
     "iopub.status.idle": "2026-02-09T02:38:58.403400Z",
     "shell.execute_reply": "2026-02-09T02:38:58.402424Z",
     "shell.execute_reply.started": "2026-02-09T02:38:58.380772Z"
    }
   },
   "outputs": [],
   "source": [
    "class NConv(nn.Module):\n",
    "    def forward(self, x, A_sp):\n",
    "        # x: (B,C,N,T)\n",
    "        B, C, N, T = x.shape\n",
    "        x_r = x.permute(2, 0, 1, 3).reshape(N, -1)\n",
    "        out = torch.sparse.mm(A_sp, x_r.float())  # keep float32 for sparse op\n",
    "        out = out.reshape(N, B, C, T).permute(1, 2, 0, 3)\n",
    "        return out.to(dtype=x.dtype)\n",
    "\n",
    "class SimpleGraphConv(nn.Module):\n",
    "    def __init__(self, c_in, c_out, supports, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.nconv = NConv()\n",
    "        self.supports = supports\n",
    "        self.mlp = nn.Conv2d(c_in * (1 + len(supports)), c_out, kernel_size=(1,1))\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = [x]\n",
    "        for A in self.supports:\n",
    "            out.append(self.nconv(x, A))\n",
    "        h = torch.cat(out, dim=1)\n",
    "        h = self.mlp(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        return h\n",
    "\n",
    "class CausalTemporalGLU(nn.Module):\n",
    "    def __init__(self, c_in, c_out, kernel_size=3, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.pad = kernel_size - 1\n",
    "        self.conv = nn.Conv2d(c_in, 2*c_out, kernel_size=(1, kernel_size))\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (self.pad, 0, 0, 0))  # left pad time\n",
    "        h = self.conv(x)\n",
    "        a, b = torch.chunk(h, 2, dim=1)\n",
    "        out = a * torch.sigmoid(b)\n",
    "        return F.dropout(out, p=self.dropout, training=self.training)\n",
    "\n",
    "class STConvBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_out, supports, kt=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.t1 = CausalTemporalGLU(c_in, c_out, kernel_size=kt, dropout=dropout)\n",
    "        self.g  = SimpleGraphConv(c_out, c_out, supports, dropout=dropout)\n",
    "        self.t2 = CausalTemporalGLU(c_out, c_out, kernel_size=kt, dropout=dropout)\n",
    "        self.bn = nn.BatchNorm2d(c_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.t1(x)\n",
    "        x = self.g(x)\n",
    "        x = self.t2(x)\n",
    "        return self.bn(x)\n",
    "\n",
    "class STGCNEncoder(nn.Module):\n",
    "    def __init__(self, in_dim, supports, hidden=64, end_channels=128, blocks=2, kt=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.start = nn.Conv2d(in_dim, hidden, kernel_size=(1,1))\n",
    "        self.blocks = nn.ModuleList([STConvBlock(hidden, hidden, supports, kt=kt, dropout=dropout) for _ in range(blocks)])\n",
    "        self.end = nn.Conv2d(hidden, end_channels, kernel_size=(1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.start(x)\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        return F.relu(self.end(x))  # (B,C,N,T)\n",
    "\n",
    "class STGCNForecast(nn.Module):\n",
    "    def __init__(self, num_nodes, in_dim, out_len, supports,\n",
    "                 hidden=64, end_channels=128, st_blocks=2, kt=3, dropout=0.1,\n",
    "                 use_gru=False, use_lstm=False, rnn_hidden=128):\n",
    "        super().__init__()\n",
    "        self.out_len = out_len\n",
    "        self.use_gru = use_gru\n",
    "        self.use_lstm = use_lstm\n",
    "\n",
    "        self.encoder = STGCNEncoder(in_dim, supports, hidden=hidden, end_channels=end_channels, blocks=st_blocks, kt=kt, dropout=dropout)\n",
    "\n",
    "        if use_gru:\n",
    "            self.gru = nn.GRU(end_channels, rnn_hidden, batch_first=True)\n",
    "        else:\n",
    "            self.gru = None\n",
    "\n",
    "        if use_lstm:\n",
    "            self.lstm = nn.LSTM((rnn_hidden if use_gru else end_channels), rnn_hidden, batch_first=True)\n",
    "        else:\n",
    "            self.lstm = None\n",
    "\n",
    "        final_dim = rnn_hidden if (use_gru or use_lstm) else end_channels\n",
    "        self.time_embed = nn.Linear(4, final_dim)\n",
    "        self.horizon_out = nn.Linear(final_dim, 1)\n",
    "\n",
    "    def forward(self, x, tf_future):\n",
    "        h = self.encoder(x)                  # (B,C,N,T)\n",
    "        B, C, N, T = h.shape\n",
    "\n",
    "        seq = h.permute(0, 2, 3, 1).contiguous().view(B*N, T, C)  # (B*N,T,C)\n",
    "\n",
    "        if self.gru is not None:\n",
    "            seq, _ = self.gru(seq)\n",
    "        if self.lstm is not None:\n",
    "            seq, _ = self.lstm(seq)\n",
    "\n",
    "        last = seq[:, -1, :]                 # (B*N,D)\n",
    "        z = last.view(B, N, -1)              # (B,N,D)\n",
    "\n",
    "        te = self.time_embed(tf_future)      # (B,OUT,D)\n",
    "        out = F.relu(z.unsqueeze(1) + te.unsqueeze(2))  # (B,OUT,N,D)\n",
    "        out = self.horizon_out(out).squeeze(-1)         # (B,OUT,N)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05b1c010-da84-4d6c-9a54-b30f33e0b886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T02:39:21.112879Z",
     "iopub.status.busy": "2026-02-09T02:39:21.111812Z",
     "iopub.status.idle": "2026-02-09T02:39:21.183206Z",
     "shell.execute_reply": "2026-02-09T02:39:21.182128Z",
     "shell.execute_reply.started": "2026-02-09T02:39:21.112854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward out: torch.Size([8, 72, 1821])\n"
     ]
    }
   ],
   "source": [
    "ST_HIDDEN = 64\n",
    "ST_END = 128\n",
    "ST_BLOCKS = 2\n",
    "KT = 3\n",
    "DROP = 0.1\n",
    "RNN_H = 128\n",
    "\n",
    "stgcn_base = STGCNForecast(\n",
    "    num_nodes=X.shape[1],\n",
    "    in_dim=X.shape[2],\n",
    "    out_len=OUT_LEN,\n",
    "    supports=supports,\n",
    "    hidden=ST_HIDDEN,\n",
    "    end_channels=ST_END,\n",
    "    st_blocks=ST_BLOCKS,\n",
    "    kt=KT,\n",
    "    dropout=DROP,\n",
    "    use_gru=False,\n",
    "    use_lstm=False,\n",
    "    rnn_hidden=RNN_H,\n",
    ").to(DEVICE)\n",
    "\n",
    "# sanity forward\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "out = stgcn_base(xb.to(DEVICE), tfb.to(DEVICE))\n",
    "print(\"Forward out:\", out.shape)  # (B, OUT_LEN, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d32b3b3f-28c8-4dd1-918f-e7f575006255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T02:52:48.638924Z",
     "iopub.status.busy": "2026-02-09T02:52:48.637978Z",
     "iopub.status.idle": "2026-02-09T02:52:48.645191Z",
     "shell.execute_reply": "2026-02-09T02:52:48.644301Z",
     "shell.execute_reply.started": "2026-02-09T02:52:48.638900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_starts: len=1009, min=0, max=1008, max_end=1104, T=2208\n",
      "val_starts: len=289, min=1080, max=1368, max_end=1464, T=2208\n",
      "test_starts: len=673, min=1440, max=2112, max_end=2208, T=2208\n",
      " starts are valid\n"
     ]
    }
   ],
   "source": [
    "T = X.shape[0]\n",
    "\n",
    "def check_starts(name, starts):\n",
    "    mx = int(starts.max())\n",
    "    mn = int(starts.min())\n",
    "    end = mx + IN_LEN + OUT_LEN\n",
    "    print(f\"{name}: len={len(starts)}, min={mn}, max={mx}, max_end={end}, T={T}\")\n",
    "    assert mn >= 0\n",
    "    assert end <= T, f\"{name} has out-of-range windows: max_start+IN+OUT={end} > T={T}\"\n",
    "\n",
    "check_starts(\"train_starts\", train_starts)\n",
    "check_starts(\"val_starts\", val_starts)\n",
    "check_starts(\"test_starts\", test_starts)\n",
    "print(\" starts are valid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "344777d9-6137-4414-8118-166099cb68e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T02:53:21.087200Z",
     "iopub.status.busy": "2026-02-09T02:53:21.086899Z",
     "iopub.status.idle": "2026-02-09T02:53:21.091784Z",
     "shell.execute_reply": "2026-02-09T02:53:21.091005Z",
     "shell.execute_reply.started": "2026-02-09T02:53:21.087178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0: torch.Size([6, 1821, 24]) y0: torch.Size([72, 1821]) tf0: torch.Size([72, 4])\n",
      " dataset __getitem__ works\n"
     ]
    }
   ],
   "source": [
    "x0, y0, tf0 = train_ds[0]\n",
    "print(\"x0:\", x0.shape, \"y0:\", y0.shape, \"tf0:\", tf0.shape)\n",
    "print(\" dataset __getitem__ works\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b82b2af-15c1-47da-bb49-ec7e55e9e798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T02:53:54.390835Z",
     "iopub.status.busy": "2026-02-09T02:53:54.390288Z",
     "iopub.status.idle": "2026-02-09T02:53:54.408414Z",
     "shell.execute_reply": "2026-02-09T02:53:54.407443Z",
     "shell.execute_reply.started": "2026-02-09T02:53:54.390808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x: torch.Size([8, 6, 1821, 24]) Batch y: torch.Size([8, 72, 1821]) Batch tf: torch.Size([8, 72, 4])\n",
      " DataLoader works with num_workers=0\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,          # key fix\n",
    "    pin_memory=False,       # also safer; we can turn back on later\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "print(\"Batch x:\", xb.shape, \"Batch y:\", yb.shape, \"Batch tf:\", tfb.shape)\n",
    "print(\" DataLoader works with num_workers=0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "855526f9-f9b8-4c9c-bfbf-c4f34385bb3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T02:54:23.109348Z",
     "iopub.status.busy": "2026-02-09T02:54:23.108805Z",
     "iopub.status.idle": "2026-02-09T03:07:04.608543Z",
     "shell.execute_reply": "2026-02-09T03:07:04.607037Z",
     "shell.execute_reply.started": "2026-02-09T02:54:23.109325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run dir: artifacts/runs/20260209_025423_STGCN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fc150d3079425c8c1811aa80e16821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: train_loss=0.122658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd63cf5effe415792d4002a95b12e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 2/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.106960\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf39877d0f264de7845fc0471c15f6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: val_avg_MAE=24947.003\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=24944.116  RMSE=787686.593\n",
      "   24h  MAE=24941.407  RMSE=787687.508\n",
      "   48h  MAE=24950.916  RMSE=787687.290\n",
      "   72h  MAE=24951.572  RMSE=787687.659\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7051fc2fb92409992bb3a0cbe989dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 3/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: train_loss=0.099522\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc9fccc642f49f2aa6f6693589d1d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 4/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=0.095018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b7f68bb3284a0f9c56958707e16395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: val_avg_MAE=4632.463\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=4631.190  RMSE=122150.499\n",
      "   24h  MAE=4623.557  RMSE=122142.468\n",
      "   48h  MAE=4636.045  RMSE=122142.950\n",
      "   72h  MAE=4639.059  RMSE=122142.454\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee3259048ed4a72a3842e6ef8071851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 5/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: train_loss=0.092440\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d595ef5b4aa4f64979fa18d173551ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 6/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: train_loss=0.090638\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e20f843c574717abec8ce5d2d145f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: val_avg_MAE=29694.880\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=29694.358  RMSE=969844.303\n",
      "   24h  MAE=29683.950  RMSE=969841.750\n",
      "   48h  MAE=29698.549  RMSE=969841.826\n",
      "   72h  MAE=29702.661  RMSE=969841.022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055e47a82cc34f4f85771b41fd26be8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 7/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: train_loss=0.089389\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653ef77394b14ec9b84c9d1ba7f66a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 8/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: train_loss=0.088278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5116956f5b274f5f81ba6be4d66f7c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: val_avg_MAE=15737.964\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=15737.883  RMSE=503787.702\n",
      "   24h  MAE=15727.043  RMSE=503785.292\n",
      "   48h  MAE=15742.061  RMSE=503785.437\n",
      "   72h  MAE=15744.869  RMSE=503785.055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd760c83d754db98af1fa94eb6856fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 9/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: train_loss=0.087326\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eeb47a7debd470c8151ab8ddf53cc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 10/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: train_loss=0.086552\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df73189c9f254e24a3a15d76c8756d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: val_avg_MAE=8177.184\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=8176.299  RMSE=266203.593\n",
      "   24h  MAE=8165.281  RMSE=266201.527\n",
      "   48h  MAE=8181.872  RMSE=266201.591\n",
      "   72h  MAE=8185.282  RMSE=266200.853\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4edc8976cf4c65954e4570683e6a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 11/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: train_loss=0.086058\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64672afda5bc43b9923d5dad89d773ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 12/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: train_loss=0.085822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba87f012d6bb457fbb11be6cf040713d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: val_avg_MAE=13813.572\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=13815.922  RMSE=466099.101\n",
      "   24h  MAE=13800.936  RMSE=466099.831\n",
      "   48h  MAE=13816.460  RMSE=466099.816\n",
      "   72h  MAE=13820.970  RMSE=466098.654\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d23ab119a8d433981d4a29244930d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 13/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: train_loss=0.084875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d6cfab9fa74133945f8a9a2480589e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 14/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: train_loss=0.084417\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c395e270eb34f2cbc32eb54d0a6d45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: val_avg_MAE=18132.726\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=18137.434  RMSE=561861.961\n",
      "   24h  MAE=18119.242  RMSE=561864.220\n",
      "   48h  MAE=18134.502  RMSE=561864.219\n",
      "   72h  MAE=18139.727  RMSE=561863.250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12c6f3d98f14f49b2425626cc55e1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 15/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: train_loss=0.084169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028f0fe2d9524bcda900523659eb20c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 16/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: train_loss=0.083938\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb294d710fda451a9d9ba9cc1a76b70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: val_avg_MAE=5477.790\n",
      "\n",
      "Validation metrics\n",
      "   12h  MAE=5469.164  RMSE=202127.674\n",
      "   24h  MAE=5469.919  RMSE=202124.106\n",
      "   48h  MAE=5484.458  RMSE=202123.825\n",
      "   72h  MAE=5487.620  RMSE=202123.465\n",
      "\n",
      "Early stopping. Best val_avg_MAE=4632.463\n",
      "Evaluating on TEST set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1eff82b149e4dc19dcba38d86a7b8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STGCN — Test\n",
      "   12h  MAE=4932.438  RMSE=122701.834\n",
      "   24h  MAE=4919.577  RMSE=122693.714\n",
      "   48h  MAE=4923.405  RMSE=122693.767\n",
      "   72h  MAE=4926.036  RMSE=122693.390\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da96bcd499c4913bf9b6683a953a899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collect preds:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x7f967c903380>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tqdm/std.py\", line 1149, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tqdm/notebook.py\", line 278, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE. Saved to: artifacts/runs/20260209_025423_STGCN\n"
     ]
    }
   ],
   "source": [
    "run_dir = run_experiment_and_save(\n",
    "    model_name=\"STGCN\",\n",
    "    model=stgcn_base,\n",
    "    epochs=40,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    "    horizons_to_save=(12, 24, 48, 72),\n",
    "    max_stations_excel=300\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2190b49-3d05-4b4f-9264-1ccd971a2139",
   "metadata": {},
   "source": [
    "## Working on STGCN models again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3169bbfc-d8ae-4ae9-9eb6-f45c0aa76006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T04:55:46.274618Z",
     "iopub.status.busy": "2026-02-09T04:55:46.274302Z",
     "iopub.status.idle": "2026-02-09T04:55:46.285229Z",
     "shell.execute_reply": "2026-02-09T04:55:46.284425Z",
     "shell.execute_reply.started": "2026-02-09T04:55:46.274596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.1.1+cu121\n",
      "Device: cuda\n",
      "GPU: Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "import os, json, time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ---------------- Repro ----------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Device:\", DEVICE)\n",
    "if DEVICE == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e78606a-12f6-4d74-94c1-a233cd0685df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T04:55:58.467811Z",
     "iopub.status.busy": "2026-02-09T04:55:58.467486Z",
     "iopub.status.idle": "2026-02-09T04:55:58.938140Z",
     "shell.execute_reply": "2026-02-09T04:55:58.937194Z",
     "shell.execute_reply.started": "2026-02-09T04:55:58.467774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: artifacts/pems_graph_dataset_strict.npz\n",
      "Keys: ['X', 'Y', 'A', 'stations', 'timestamps', 'train_starts', 'val_starts', 'test_starts', 'in_len', 'out_len', 'flow_mean', 'flow_std', 'speed_mean', 'speed_std']\n",
      "\n",
      "Shapes:\n",
      "X_raw: (2208, 1821, 6) (T,N,F)\n",
      "Y_raw: (2208, 1821) (T,N)\n",
      "A: (1821, 1821)\n",
      "IN_LEN: 24 OUT_LEN: 72\n",
      "train/val/test starts: 1009 289 673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44/190701963.py:18: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  IN_LEN  = int(data[\"in_len\"])\n",
      "/tmp/ipykernel_44/190701963.py:19: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  OUT_LEN = int(data[\"out_len\"])\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"artifacts/pems_graph_dataset_strict.npz\")\n",
    "assert DATA_PATH.exists(), f\"Missing {DATA_PATH}. Rebuild the dataset first.\"\n",
    "\n",
    "data = np.load(DATA_PATH, allow_pickle=True)\n",
    "print(\"Loaded:\", DATA_PATH)\n",
    "print(\"Keys:\", list(data.keys()))\n",
    "\n",
    "X_raw = data[\"X\"]            # (T, N, F)\n",
    "Y_raw = data[\"Y\"]            # (T, N)  (flow target)\n",
    "A = data[\"A\"]                # (N, N)\n",
    "stations = data[\"stations\"]\n",
    "timestamps = data[\"timestamps\"]\n",
    "\n",
    "train_starts = data[\"train_starts\"]\n",
    "val_starts   = data[\"val_starts\"]\n",
    "test_starts  = data[\"test_starts\"]\n",
    "\n",
    "IN_LEN  = int(data[\"in_len\"])\n",
    "OUT_LEN = int(data[\"out_len\"])\n",
    "\n",
    "flow_mean = data[\"flow_mean\"]   # (N,)\n",
    "flow_std  = data[\"flow_std\"]    # (N,)\n",
    "speed_mean = data[\"speed_mean\"] # (N,)\n",
    "speed_std  = data[\"speed_std\"]  # (N,)\n",
    "\n",
    "T, N, Fdim = X_raw.shape\n",
    "print(\"\\nShapes:\")\n",
    "print(\"X_raw:\", X_raw.shape, \"(T,N,F)\")\n",
    "print(\"Y_raw:\", Y_raw.shape, \"(T,N)\")\n",
    "print(\"A:\", A.shape)\n",
    "print(\"IN_LEN:\", IN_LEN, \"OUT_LEN:\", OUT_LEN)\n",
    "print(\"train/val/test starts:\", len(train_starts), len(val_starts), len(test_starts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af391282-7483-46d7-be5a-bf37c3c3084a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T04:56:24.201096Z",
     "iopub.status.busy": "2026-02-09T04:56:24.200683Z",
     "iopub.status.idle": "2026-02-09T04:56:24.541686Z",
     "shell.execute_reply": "2026-02-09T04:56:24.540635Z",
     "shell.execute_reply.started": "2026-02-09T04:56:24.201062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_fnt: (6, 1821, 2208) Y_scaled: (2208, 1821) TF_all: (2208, 4)\n",
      "Sanity (Y_scaled mean/std approx): -780.4212036132812 30666.189453125\n"
     ]
    }
   ],
   "source": [
    "def time_encoding(dt_index: pd.DatetimeIndex) -> np.ndarray:\n",
    "    hours = dt_index.hour.values\n",
    "    dow   = dt_index.dayofweek.values\n",
    "    hour_sin = np.sin(2*np.pi*hours/24.0)\n",
    "    hour_cos = np.cos(2*np.pi*hours/24.0)\n",
    "    dow_sin  = np.sin(2*np.pi*dow/7.0)\n",
    "    dow_cos  = np.cos(2*np.pi*dow/7.0)\n",
    "    return np.stack([hour_sin, hour_cos, dow_sin, dow_cos], axis=1).astype(np.float32)\n",
    "\n",
    "dt_idx = pd.to_datetime(timestamps)\n",
    "TF_all = time_encoding(dt_idx)         # (T,4)\n",
    "\n",
    "# ----- scale inputs -----\n",
    "X_scaled = X_raw.astype(np.float32).copy()\n",
    "X_scaled[:, :, 0] = (X_scaled[:, :, 0] - flow_mean[None, :]) / (flow_std[None, :] + 1e-6)\n",
    "X_scaled[:, :, 1] = (X_scaled[:, :, 1] - speed_mean[None, :]) / (speed_std[None, :] + 1e-6)\n",
    "\n",
    "# ----- scale targets (flow) -----\n",
    "Y_scaled = (Y_raw.astype(np.float32) - flow_mean[None, :]) / (flow_std[None, :] + 1e-6)\n",
    "\n",
    "# Store for fast slicing as (F,N,T)\n",
    "X_fnt = np.transpose(X_scaled, (2, 1, 0)).copy()  # (F,N,T)\n",
    "\n",
    "print(\"X_fnt:\", X_fnt.shape, \"Y_scaled:\", Y_scaled.shape, \"TF_all:\", TF_all.shape)\n",
    "print(\"Sanity (Y_scaled mean/std approx):\", float(Y_scaled.mean()), float(Y_scaled.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "641e1145-422c-4d8a-973b-00d6d783f153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T04:56:45.178022Z",
     "iopub.status.busy": "2026-02-09T04:56:45.177679Z",
     "iopub.status.idle": "2026-02-09T04:56:45.200342Z",
     "shell.execute_reply": "2026-02-09T04:56:45.199503Z",
     "shell.execute_reply.started": "2026-02-09T04:56:45.178000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x: torch.Size([8, 6, 1821, 24]) Batch y: torch.Size([8, 72, 1821]) Batch tf: torch.Size([8, 72, 4])\n"
     ]
    }
   ],
   "source": [
    "class FastPeMSWindowDataset(Dataset):\n",
    "    def __init__(self, X_fnt, Y_scaled, TF_all, starts, in_len, out_len):\n",
    "        self.X_fnt = X_fnt\n",
    "        self.Y = Y_scaled\n",
    "        self.TF = TF_all\n",
    "        self.starts = starts.astype(np.int64)\n",
    "        self.in_len = int(in_len)\n",
    "        self.out_len = int(out_len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.starts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = int(self.starts[idx])\n",
    "        x = self.X_fnt[:, :, t:t+self.in_len]  # (F,N,IN_LEN)\n",
    "        y = self.Y[t+self.in_len:t+self.in_len+self.out_len, :]  # (OUT_LEN,N)\n",
    "        tf = self.TF[t+self.in_len:t+self.in_len+self.out_len, :]  # (OUT_LEN,4)\n",
    "        return (\n",
    "            torch.from_numpy(x).float(),\n",
    "            torch.from_numpy(y).float(),\n",
    "            torch.from_numpy(tf).float()\n",
    "        )\n",
    "\n",
    "train_ds = FastPeMSWindowDataset(X_fnt, Y_scaled, TF_all, train_starts, IN_LEN, OUT_LEN)\n",
    "val_ds   = FastPeMSWindowDataset(X_fnt, Y_scaled, TF_all, val_starts,   IN_LEN, OUT_LEN)\n",
    "test_ds  = FastPeMSWindowDataset(X_fnt, Y_scaled, TF_all, test_starts,  IN_LEN, OUT_LEN)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0, pin_memory=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "print(\"Batch x:\", xb.shape, \"Batch y:\", yb.shape, \"Batch tf:\", tfb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d9fd0eb-93d5-46b6-b751-568f2db4a540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T04:57:09.622977Z",
     "iopub.status.busy": "2026-02-09T04:57:09.622633Z",
     "iopub.status.idle": "2026-02-09T04:57:09.722831Z",
     "shell.execute_reply": "2026-02-09T04:57:09.721591Z",
     "shell.execute_reply.started": "2026-02-09T04:57:09.622953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_sp nnz: 7856\n"
     ]
    }
   ],
   "source": [
    "def dense_to_sparse(A_dense: np.ndarray, device: str):\n",
    "    idx = np.nonzero(A_dense)\n",
    "    indices = torch.from_numpy(np.vstack(idx)).long()\n",
    "    values  = torch.from_numpy(A_dense[idx].astype(np.float32))\n",
    "    sp = torch.sparse_coo_tensor(indices, values, size=A_dense.shape, device=device)\n",
    "    return sp.coalesce()\n",
    "\n",
    "def scaled_laplacian(A: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build scaled Laplacian L_tilde = (2/lambda_max)*L - I.\n",
    "    We follow the common approximation lambda_max ≈ 2. :contentReference[oaicite:3]{index=3}\n",
    "    \"\"\"\n",
    "    A = A.astype(np.float32)\n",
    "    # Make undirected for STGCN (common choice)\n",
    "    A = np.maximum(A, A.T)\n",
    "\n",
    "    # Add self loops\n",
    "    A = A + np.eye(A.shape[0], dtype=np.float32)\n",
    "\n",
    "    d = A.sum(axis=1)\n",
    "    d_inv_sqrt = np.power(d, -0.5, where=(d > 0))\n",
    "    d_inv_sqrt[~np.isfinite(d_inv_sqrt)] = 0.0\n",
    "\n",
    "    A_norm = (d_inv_sqrt[:, None] * A) * d_inv_sqrt[None, :]\n",
    "    L = np.eye(A.shape[0], dtype=np.float32) - A_norm\n",
    "\n",
    "    lambda_max = 2.0\n",
    "    L_tilde = (2.0 / lambda_max) * L - np.eye(A.shape[0], dtype=np.float32)\n",
    "    return L_tilde\n",
    "\n",
    "L_tilde = scaled_laplacian(A)\n",
    "L_sp = dense_to_sparse(L_tilde, DEVICE)\n",
    "print(\"L_sp nnz:\", int(L_sp._nnz()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c867e03-0ed7-4de2-bb66-ff9ce03b2665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T04:57:33.038067Z",
     "iopub.status.busy": "2026-02-09T04:57:33.037341Z",
     "iopub.status.idle": "2026-02-09T04:57:33.064088Z",
     "shell.execute_reply": "2026-02-09T04:57:33.063164Z",
     "shell.execute_reply.started": "2026-02-09T04:57:33.038044Z"
    }
   },
   "outputs": [],
   "source": [
    "EVAL_HORIZONS = [12, 24, 48, 72]\n",
    "h_idx = torch.tensor([h-1 for h in EVAL_HORIZONS], device=DEVICE)\n",
    "\n",
    "flow_mean_t = torch.tensor(flow_mean, dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "flow_std_t  = torch.tensor(flow_std,  dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "\n",
    "def print_metrics(title, metrics):\n",
    "    print(\"\\n\" + title)\n",
    "    for h in sorted(metrics.keys()):\n",
    "        print(f\"  {h:>3}h  MAE={metrics[h]['MAE']:.3f}  RMSE={metrics[h]['RMSE']:.3f}\")\n",
    "\n",
    "def avg_mae(metrics):\n",
    "    return float(np.mean([metrics[h][\"MAE\"] for h in metrics]))\n",
    "\n",
    "@torch.inference_mode()\n",
    "def eval_horizons_fast(model, loader):\n",
    "    model.eval()\n",
    "    acc = {h: {\"abs\": 0.0, \"sq\": 0.0, \"count\": 0} for h in EVAL_HORIZONS}\n",
    "\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        pred = model(xb, tfb)  # MUST be scaled outputs (B,OUT_LEN,N)\n",
    "\n",
    "        pred_u = pred * flow_std_t + flow_mean_t\n",
    "        true_u = yb   * flow_std_t + flow_mean_t\n",
    "\n",
    "        # selected horizons\n",
    "        pred_sel = pred_u[:, h_idx, :]\n",
    "        true_sel = true_u[:, h_idx, :]\n",
    "        for i, h in enumerate(EVAL_HORIZONS):\n",
    "            err = pred_sel[:, i, :] - true_sel[:, i, :]\n",
    "            acc[h][\"abs\"] += float(err.abs().sum())\n",
    "            acc[h][\"sq\"]  += float((err ** 2).sum())\n",
    "            acc[h][\"count\"] += err.numel()\n",
    "\n",
    "    metrics = {}\n",
    "    for h in EVAL_HORIZONS:\n",
    "        mae = acc[h][\"abs\"] / acc[h][\"count\"]\n",
    "        rmse = (acc[h][\"sq\"] / acc[h][\"count\"]) ** 0.5\n",
    "        metrics[h] = {\"MAE\": mae, \"RMSE\": rmse}\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "410a1f7c-0e1f-4be9-934c-7f6d06d4f164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T04:57:54.804446Z",
     "iopub.status.busy": "2026-02-09T04:57:54.804135Z",
     "iopub.status.idle": "2026-02-09T04:57:54.821593Z",
     "shell.execute_reply": "2026-02-09T04:57:54.820388Z",
     "shell.execute_reply.started": "2026-02-09T04:57:54.804425Z"
    }
   },
   "outputs": [],
   "source": [
    "class NConv(nn.Module):\n",
    "    \"\"\"Sparse matrix multiply along node dimension.\"\"\"\n",
    "    def forward(self, x, A_sp):\n",
    "        # x: (B, C, N, T)\n",
    "        B, C, N, T = x.shape\n",
    "        x_r = x.permute(2, 0, 1, 3).reshape(N, -1).float()      # (N, B*C*T)\n",
    "        x_r = torch.sparse.mm(A_sp, x_r)                         # (N, B*C*T)\n",
    "        x_out = x_r.reshape(N, B, C, T).permute(1, 2, 0, 3)      # (B, C, N, T)\n",
    "        return x_out\n",
    "\n",
    "class ChebGraphConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Chebyshev graph conv using recurrence:\n",
    "      T0(X)=X\n",
    "      T1(X)=L~ X\n",
    "      Tk(X)=2 L~ T_{k-1}(X) - T_{k-2}(X)\n",
    "    Then 1x1 conv mixes the K stacks.\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out, K, L_sp):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.L_sp = L_sp\n",
    "        self.nconv = NConv()\n",
    "        self.mlp = nn.Conv2d(c_in * K, c_out, kernel_size=(1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,C,N,T)\n",
    "        out = [x]\n",
    "        if self.K > 1:\n",
    "            x1 = self.nconv(x, self.L_sp)\n",
    "            out.append(x1)\n",
    "        for k in range(2, self.K):\n",
    "            x2 = 2.0 * self.nconv(out[-1], self.L_sp) - out[-2]\n",
    "            out.append(x2)\n",
    "\n",
    "        h = torch.cat(out, dim=1)  # (B, C*K, N, T)\n",
    "        return self.mlp(h)\n",
    "\n",
    "class TemporalGLU(nn.Module):\n",
    "    \"\"\"Temporal convolution + GLU gating. No padding -> time shrinks.\"\"\"\n",
    "    def __init__(self, c_in, c_out, kt):\n",
    "        super().__init__()\n",
    "        self.kt = kt\n",
    "        self.conv = nn.Conv2d(c_in, 2*c_out, kernel_size=(1, kt))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,C,N,T)\n",
    "        z = self.conv(x)                 # (B,2C,N,T-kt+1)\n",
    "        P, Q = torch.chunk(z, 2, dim=1)  # each (B,C,N,T')\n",
    "        return P * torch.sigmoid(Q)\n",
    "\n",
    "class STConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    STGCN block: TemporalGLU -> ChebGraphConv -> ReLU -> TemporalGLU\n",
    "    + residual (time-aligned) + LayerNorm over channels\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_t, c_s, c_out, kt, Ks, L_sp, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.temporal1 = TemporalGLU(c_in, c_t, kt)\n",
    "        self.graphconv = ChebGraphConv(c_t, c_s, Ks, L_sp)\n",
    "        self.temporal2 = TemporalGLU(c_s, c_out, kt)\n",
    "\n",
    "        self.res_conv = None\n",
    "        if c_in != c_out:\n",
    "            self.res_conv = nn.Conv2d(c_in, c_out, kernel_size=(1,1))\n",
    "\n",
    "        self.ln = nn.LayerNorm(c_out)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        self.kt = kt\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,C_in,N,T)\n",
    "        x_in = x\n",
    "        x = self.temporal1(x)            # (B,c_t,N,T1)\n",
    "        x = self.graphconv(x)            # (B,c_s,N,T1)\n",
    "        x = F.relu(x)\n",
    "        x = self.temporal2(x)            # (B,c_out,N,T2)\n",
    "\n",
    "        # residual: align last T2 timesteps\n",
    "        T2 = x.shape[-1]\n",
    "        res = x_in[..., -T2:]\n",
    "        if self.res_conv is not None:\n",
    "            res = self.res_conv(res)\n",
    "        x = x + res\n",
    "\n",
    "        x = self.drop(x)\n",
    "\n",
    "        # LayerNorm over channels (per node per time)\n",
    "        x = x.permute(0, 2, 3, 1)        # (B,N,T,C)\n",
    "        x = self.ln(x)\n",
    "        x = x.permute(0, 3, 1, 2)        # (B,C,N,T)\n",
    "        return x\n",
    "\n",
    "class STGCN_MultiHorizon(nn.Module):\n",
    "    \"\"\"\n",
    "    STGCN encoder + multi-horizon head.\n",
    "    Output is (B, OUT_LEN, N) in SCALED space (no unscale inside).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_nodes, in_dim, out_len, L_sp,\n",
    "                 kt=3, Ks=3, dropout=0.1,\n",
    "                 c_t=64, c_s=16, c_out=64, blocks=2):\n",
    "        super().__init__()\n",
    "        self.out_len = out_len\n",
    "\n",
    "        layers = []\n",
    "        c_in = in_dim\n",
    "        for _ in range(blocks):\n",
    "            layers.append(STConvBlock(c_in, c_t=c_t, c_s=c_s, c_out=c_out,\n",
    "                                      kt=kt, Ks=Ks, L_sp=L_sp, dropout=dropout))\n",
    "            c_in = c_out\n",
    "        self.blocks = nn.ModuleList(layers)\n",
    "\n",
    "        # After blocks, time is reduced by blocks * 2*(kt-1)\n",
    "        # We will infer the remaining time at runtime and build head lazily if needed.\n",
    "        self.head = None\n",
    "        self.c_out = c_out\n",
    "\n",
    "    def _build_head(self, T_rem):\n",
    "        # Collapse time dimension into 1, output channels = out_len\n",
    "        self.head = nn.Conv2d(self.c_out, self.out_len, kernel_size=(1, T_rem))\n",
    "\n",
    "    def forward(self, x, tf_future=None):\n",
    "        # x: (B,F,N,IN_LEN)\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        T_rem = x.shape[-1]\n",
    "        if self.head is None:\n",
    "            self._build_head(T_rem)\n",
    "            self.head = self.head.to(x.device)\n",
    "\n",
    "        y = self.head(x)       # (B,OUT_LEN,N,1)\n",
    "        y = y.squeeze(-1)      # (B,OUT_LEN,N)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3ad7c7f-4a9c-4e5b-8bdb-50e5a2a0252d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T04:58:27.964665Z",
     "iopub.status.busy": "2026-02-09T04:58:27.964369Z",
     "iopub.status.idle": "2026-02-09T04:58:27.993413Z",
     "shell.execute_reply": "2026-02-09T04:58:27.992595Z",
     "shell.execute_reply.started": "2026-02-09T04:58:27.964642Z"
    }
   },
   "outputs": [],
   "source": [
    "ART_DIR = Path(\"artifacts\")\n",
    "RUNS_DIR = ART_DIR / \"runs\"\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def make_run_dir(model_name: str) -> Path:\n",
    "    ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = RUNS_DIR / f\"{ts}_{model_name}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def save_json(path: Path, obj: dict):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def metrics_to_flat_row(model_name: str, split: str, metrics: dict) -> dict:\n",
    "    row = {\"model_name\": model_name, \"split\": split}\n",
    "    for h in EVAL_HORIZONS:\n",
    "        row[f\"{split}_MAE_{h}h\"] = metrics[h][\"MAE\"]\n",
    "        row[f\"{split}_RMSE_{h}h\"] = metrics[h][\"RMSE\"]\n",
    "    row[f\"{split}_avg_MAE\"] = avg_mae(metrics)\n",
    "    return row\n",
    "\n",
    "def append_results_summary(row: dict, out_csv: Path = ART_DIR/\"results_summary.csv\"):\n",
    "    df_new = pd.DataFrame([row])\n",
    "    if out_csv.exists():\n",
    "        df_old = pd.read_csv(out_csv)\n",
    "        df = pd.concat([df_old, df_new], ignore_index=True)\n",
    "    else:\n",
    "        df = df_new\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return out_csv\n",
    "\n",
    "@torch.inference_mode()\n",
    "def collect_predictions_selected_horizons(model, loader, horizons=(12,24,48,72)):\n",
    "    model.eval()\n",
    "    h_idx_local = torch.tensor([h-1 for h in horizons], device=DEVICE)\n",
    "    preds_all = []\n",
    "    trues_all = []\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Collect preds\", leave=False):\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "        tfb = tfb.to(DEVICE)\n",
    "        pred = model(xb, tfb)  # scaled\n",
    "\n",
    "        pred_u = pred * flow_std_t + flow_mean_t\n",
    "        true_u = yb   * flow_std_t + flow_mean_t\n",
    "\n",
    "        preds_all.append(pred_u[:, h_idx_local, :].detach().cpu().numpy())\n",
    "        trues_all.append(true_u[:, h_idx_local, :].detach().cpu().numpy())\n",
    "\n",
    "    preds_all = np.concatenate(preds_all, axis=0)  # (Btot, Hsel, N)\n",
    "    trues_all = np.concatenate(trues_all, axis=0)\n",
    "    return preds_all, trues_all, horizons\n",
    "\n",
    "def save_predictions_excel(run_dir: Path, preds, trues, horizons, stations, max_stations=300):\n",
    "    N_total = preds.shape[-1]\n",
    "    N_use = min(max_stations, N_total)\n",
    "    st_sel = stations[:N_use]\n",
    "\n",
    "    out_xlsx = run_dir / \"test_pred_true_selected_horizons.xlsx\"\n",
    "    with pd.ExcelWriter(out_xlsx, engine=\"openpyxl\") as writer:\n",
    "        for hi, h in enumerate(horizons):\n",
    "            df = pd.DataFrame({\n",
    "                \"station\": np.repeat(st_sel, preds.shape[0]),\n",
    "                \"sample\":  np.tile(np.arange(preds.shape[0]), N_use),\n",
    "                \"true\":    trues[:, hi, :N_use].T.reshape(-1),\n",
    "                \"pred\":    preds[:, hi, :N_use].T.reshape(-1),\n",
    "            })\n",
    "            df.to_excel(writer, sheet_name=f\"h{h}\", index=False)\n",
    "    return out_xlsx\n",
    "\n",
    "def train_and_save_best(\n",
    "    model, model_name: str, run_dir: Path,\n",
    "    epochs=40, lr=1e-3, weight_decay=1e-4, clip=5.0,\n",
    "    patience=6, eval_every=2\n",
    "):\n",
    "    model = model.to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    best_score = float(\"inf\")\n",
    "    best_state = None\n",
    "    bad = 0\n",
    "\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        run_loss = 0.0\n",
    "\n",
    "        for xb, yb, tfb in tqdm(train_loader, desc=f\"Train {epoch}/{epochs}\", leave=False):\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            tfb = tfb.to(DEVICE)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            pred = model(xb, tfb)               # scaled\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "\n",
    "            run_loss += float(loss.item())\n",
    "\n",
    "        row = {\"epoch\": epoch, \"train_loss\": run_loss / max(1, len(train_loader))}\n",
    "        history.append(row)\n",
    "\n",
    "        # Evaluate every eval_every epochs\n",
    "        if epoch % eval_every == 0:\n",
    "            val_m = eval_horizons_fast(model, val_loader)\n",
    "            score = avg_mae(val_m)\n",
    "\n",
    "            print(f\"\\nEpoch {epoch}: train_loss={row['train_loss']:.6f} val_avg_MAE={score:.3f}\")\n",
    "            print_metrics(\"VAL\", val_m)\n",
    "\n",
    "            row.update({f\"val_MAE_{h}h\": val_m[h][\"MAE\"] for h in EVAL_HORIZONS})\n",
    "            row.update({f\"val_RMSE_{h}h\": val_m[h][\"RMSE\"] for h in EVAL_HORIZONS})\n",
    "            row[\"val_avg_MAE\"] = score\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                bad = 0\n",
    "                torch.save(best_state, run_dir / \"best.pt\")\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= patience:\n",
    "                    print(f\"\\nEarly stopping. Best val_avg_MAE={best_score:.3f}\")\n",
    "                    break\n",
    "\n",
    "    # Save history\n",
    "    hist_df = pd.DataFrame(history)\n",
    "    hist_df.to_csv(run_dir / \"history.csv\", index=False)\n",
    "    print(\"Saved history:\", run_dir / \"history.csv\")\n",
    "\n",
    "    # Load best\n",
    "    assert best_state is not None, \"best_state is None (evaluation never ran?)\"\n",
    "    model.load_state_dict(best_state)\n",
    "    return model, hist_df\n",
    "\n",
    "def run_experiment_and_save(\n",
    "    model_name: str,\n",
    "    model: nn.Module,\n",
    "    epochs=40, patience=6, eval_every=2,\n",
    "    horizons_to_save=(12,24,48,72),\n",
    "    max_stations_excel=300\n",
    "):\n",
    "    run_dir = make_run_dir(model_name)\n",
    "    print(\"Run dir:\", run_dir)\n",
    "\n",
    "    # Train\n",
    "    model, history_df = train_and_save_best(\n",
    "        model=model,\n",
    "        model_name=model_name,\n",
    "        run_dir=run_dir,\n",
    "        epochs=epochs,\n",
    "        patience=patience,\n",
    "        eval_every=eval_every,\n",
    "    )\n",
    "\n",
    "    # Test metrics\n",
    "    print(\"\\nEvaluating on TEST set...\")\n",
    "    test_m = eval_horizons_fast(model, test_loader)\n",
    "    print_metrics(f\"{model_name} — TEST\", test_m)\n",
    "\n",
    "    # Save test metrics\n",
    "    save_json(run_dir / \"test_metrics.json\", test_m)\n",
    "    pd.DataFrame([metrics_to_flat_row(model_name, \"test\", test_m)]).to_csv(run_dir / \"test_metrics.csv\", index=False)\n",
    "\n",
    "    # Collect & save predictions\n",
    "    preds, trues, horizons = collect_predictions_selected_horizons(model, test_loader, horizons=horizons_to_save)\n",
    "    np.savez_compressed(run_dir / \"test_pred_true_selected_horizons.npz\",\n",
    "                        preds=preds, trues=trues, horizons=np.array(horizons))\n",
    "    out_xlsx = save_predictions_excel(run_dir, preds, trues, horizons, stations, max_stations=max_stations_excel)\n",
    "\n",
    "    # Update master summary CSV\n",
    "    summary_row = metrics_to_flat_row(model_name, \"test\", test_m)\n",
    "    out_summary = append_results_summary(summary_row)\n",
    "\n",
    "    print(\"\\nSaved run outputs to:\", run_dir)\n",
    "    print(\" - best checkpoint:\", run_dir / \"best.pt\")\n",
    "    print(\" - history:\", run_dir / \"history.csv\")\n",
    "    print(\" - test metrics:\", run_dir / \"test_metrics.json\")\n",
    "    print(\" - predictions (npz):\", run_dir / \"test_pred_true_selected_horizons.npz\")\n",
    "    print(\" - predictions (xlsx):\", out_xlsx)\n",
    "    print(\" - master summary:\", out_summary)\n",
    "\n",
    "    return run_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "271eb768-dd27-4360-bf92-15bcd7178f52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T04:58:55.455545Z",
     "iopub.status.busy": "2026-02-09T04:58:55.455151Z",
     "iopub.status.idle": "2026-02-09T05:23:12.105658Z",
     "shell.execute_reply": "2026-02-09T05:23:12.105007Z",
     "shell.execute_reply.started": "2026-02-09T04:58:55.455512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward output: torch.Size([8, 72, 1821]) scaled pred stats: 0.04451674595475197 0.5800633430480957\n",
      "Run dir: artifacts/runs/20260209_045856_STGCN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691b16db657b4647865784860a203036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7602dee32f34e9eb3ff1a767fade369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 2/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7a515a9b0442c8b26dbbde98fefebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.250966 val_avg_MAE=162.807\n",
      "\n",
      "VAL\n",
      "   12h  MAE=147.694  RMSE=297.933\n",
      "   24h  MAE=150.905  RMSE=307.435\n",
      "   48h  MAE=165.279  RMSE=321.227\n",
      "   72h  MAE=187.351  RMSE=345.004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb34f0ffe614a819bd08fdfcae7fbdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 3/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1303e246666943f188b8952c7ec9313f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 4/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a24dad05b1945d4be165d776a233789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=0.198355 val_avg_MAE=151.319\n",
      "\n",
      "VAL\n",
      "   12h  MAE=126.232  RMSE=256.539\n",
      "   24h  MAE=136.581  RMSE=282.147\n",
      "   48h  MAE=158.525  RMSE=310.717\n",
      "   72h  MAE=183.936  RMSE=353.417\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332d4e7a1bdc44e98c344bd4f37cea9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 5/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6794a15c2bd40fe85288ddd084d8eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 6/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fceea6a44c471d8dc16ceb1826848c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: train_loss=0.185316 val_avg_MAE=150.038\n",
      "\n",
      "VAL\n",
      "   12h  MAE=123.796  RMSE=256.978\n",
      "   24h  MAE=138.322  RMSE=281.302\n",
      "   48h  MAE=161.329  RMSE=320.515\n",
      "   72h  MAE=176.704  RMSE=342.250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678cdaa749174dbab505aebcdfac13b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 7/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd40793917d4319b3d9ee5bfe7173cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 8/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5dd8feb29694ec8b1cecb4ae62b1398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: train_loss=0.177419 val_avg_MAE=151.114\n",
      "\n",
      "VAL\n",
      "   12h  MAE=125.383  RMSE=257.735\n",
      "   24h  MAE=133.466  RMSE=277.751\n",
      "   48h  MAE=162.796  RMSE=322.952\n",
      "   72h  MAE=182.812  RMSE=353.390\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef753aa69f7f4d88a8a80832686f98b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 9/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1d99cac64845ee9d5069dfdf5ed593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 10/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea82eff40f164f34b429bb01b143ab31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: train_loss=0.173663 val_avg_MAE=147.846\n",
      "\n",
      "VAL\n",
      "   12h  MAE=127.529  RMSE=263.337\n",
      "   24h  MAE=133.106  RMSE=271.559\n",
      "   48h  MAE=155.514  RMSE=311.491\n",
      "   72h  MAE=175.235  RMSE=343.807\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25f6ef73c8a4f40a3394e19ce4bc35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 11/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ddeac3714342989373d96fc61c4c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 12/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce06b46d574481daeb5bf76d56944e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: train_loss=0.170295 val_avg_MAE=143.184\n",
      "\n",
      "VAL\n",
      "   12h  MAE=123.229  RMSE=252.882\n",
      "   24h  MAE=127.686  RMSE=265.887\n",
      "   48h  MAE=156.364  RMSE=311.306\n",
      "   72h  MAE=165.456  RMSE=322.152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80da0541f644c74815c169dc70aeb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 13/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718856ddf3224ba3befdc3877f92a55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 14/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b09ee6c62343b891a5d522cd61aa1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: train_loss=0.166737 val_avg_MAE=143.280\n",
      "\n",
      "VAL\n",
      "   12h  MAE=117.789  RMSE=245.680\n",
      "   24h  MAE=128.483  RMSE=265.882\n",
      "   48h  MAE=157.306  RMSE=307.850\n",
      "   72h  MAE=169.542  RMSE=335.639\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89dc419319cc46c1b46e505042adcd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 15/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4727c10ce5149efbd00edfff392f42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 16/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f00f19926e4ae486bcbab75fb3a306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: train_loss=0.164811 val_avg_MAE=144.770\n",
      "\n",
      "VAL\n",
      "   12h  MAE=114.700  RMSE=243.654\n",
      "   24h  MAE=137.070  RMSE=273.928\n",
      "   48h  MAE=161.213  RMSE=310.414\n",
      "   72h  MAE=166.098  RMSE=318.674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93fa6c6fdc84fecbe648841204e8ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 17/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e634f3d53a74e7cab191484923c4ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 18/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c6dceb92e64c12a7cda48916fe6c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: train_loss=0.164994 val_avg_MAE=144.036\n",
      "\n",
      "VAL\n",
      "   12h  MAE=120.426  RMSE=247.997\n",
      "   24h  MAE=132.155  RMSE=274.025\n",
      "   48h  MAE=157.831  RMSE=313.536\n",
      "   72h  MAE=165.730  RMSE=328.414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef05d3a1630c4392bfc87faa45bbe68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 19/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439dc248b086446a81268b94bb84dcfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 20/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed3a5f182f74f549e3cb3ba956eea92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: train_loss=0.162928 val_avg_MAE=147.952\n",
      "\n",
      "VAL\n",
      "   12h  MAE=111.936  RMSE=241.293\n",
      "   24h  MAE=139.887  RMSE=280.909\n",
      "   48h  MAE=165.217  RMSE=321.430\n",
      "   72h  MAE=174.767  RMSE=338.671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e96ef16f2f4415aac92612e4e3b7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 21/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff62dfe40f3455d9a65eab2e5030485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 22/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c9d456d841457392a959af9202d3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: train_loss=0.161761 val_avg_MAE=146.622\n",
      "\n",
      "VAL\n",
      "   12h  MAE=122.780  RMSE=248.747\n",
      "   24h  MAE=128.076  RMSE=263.646\n",
      "   48h  MAE=162.222  RMSE=320.803\n",
      "   72h  MAE=173.412  RMSE=339.150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa28103474b41fea8a8e1c1827ee23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 23/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92cbab7172d4853b174e3c31109def2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 24/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a12439cf51494bb2bcacb5eb860565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: train_loss=0.161647 val_avg_MAE=140.516\n",
      "\n",
      "VAL\n",
      "   12h  MAE=122.143  RMSE=251.693\n",
      "   24h  MAE=123.930  RMSE=259.899\n",
      "   48h  MAE=151.445  RMSE=302.201\n",
      "   72h  MAE=164.544  RMSE=326.233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577756d411d040a6a4bd23fc10ca54ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 25/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb332e38263f4b8b9a773e1bce46b75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 26/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8741d0677040e588d2f36f2ce4a17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: train_loss=0.159943 val_avg_MAE=149.155\n",
      "\n",
      "VAL\n",
      "   12h  MAE=123.250  RMSE=255.677\n",
      "   24h  MAE=138.902  RMSE=280.275\n",
      "   48h  MAE=163.449  RMSE=319.669\n",
      "   72h  MAE=171.018  RMSE=334.956\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58658c82bda4b309e66b33a86152668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 27/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bff4ea6fa94982b0eb2257accc7f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 28/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40bb6bbbc05424e91e256a0f96c4837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: train_loss=0.159359 val_avg_MAE=142.014\n",
      "\n",
      "VAL\n",
      "   12h  MAE=111.286  RMSE=235.258\n",
      "   24h  MAE=130.740  RMSE=267.831\n",
      "   48h  MAE=158.796  RMSE=312.691\n",
      "   72h  MAE=167.233  RMSE=330.366\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f337efe25c407cad589482fc496c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 29/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c113ca3562b4c71958798254fdb1575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 30/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30ecf4f5b33466b9076b34e58259889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: train_loss=0.158898 val_avg_MAE=137.910\n",
      "\n",
      "VAL\n",
      "   12h  MAE=117.151  RMSE=244.578\n",
      "   24h  MAE=126.157  RMSE=265.732\n",
      "   48h  MAE=151.016  RMSE=301.190\n",
      "   72h  MAE=157.317  RMSE=310.011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e543d1a05e442d88603ba86981d6382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 31/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bad92ea95494ea981afef43303c898f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 32/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf0b87fa39d40c0bc44ef7d83c43fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: train_loss=0.158708 val_avg_MAE=136.992\n",
      "\n",
      "VAL\n",
      "   12h  MAE=115.324  RMSE=238.849\n",
      "   24h  MAE=124.163  RMSE=258.722\n",
      "   48h  MAE=149.866  RMSE=301.408\n",
      "   72h  MAE=158.613  RMSE=313.007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76667809fe4641fd8947140f6da60187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 33/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7976095688b84cc2880e0676054c18d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 34/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7191bea97d604235a159c9401762e781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: train_loss=0.157839 val_avg_MAE=142.080\n",
      "\n",
      "VAL\n",
      "   12h  MAE=113.515  RMSE=239.150\n",
      "   24h  MAE=125.888  RMSE=264.526\n",
      "   48h  MAE=156.802  RMSE=313.278\n",
      "   72h  MAE=172.115  RMSE=339.594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692cb1ee50be475cb3aaf9d07d561a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 35/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3ad91bf63643b79e4ebf4577c834c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 36/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6c151f404a405cab15e41522af9a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: train_loss=0.158052 val_avg_MAE=143.181\n",
      "\n",
      "VAL\n",
      "   12h  MAE=117.767  RMSE=245.907\n",
      "   24h  MAE=137.043  RMSE=282.010\n",
      "   48h  MAE=155.687  RMSE=307.704\n",
      "   72h  MAE=162.226  RMSE=317.296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081bb6614d01423cb551e0e3601fa56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 37/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357bae31631e466190e282b77551245d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 38/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf17100723c47ffad33d2c8d27c9916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: train_loss=0.156788 val_avg_MAE=143.783\n",
      "\n",
      "VAL\n",
      "   12h  MAE=118.535  RMSE=243.556\n",
      "   24h  MAE=128.388  RMSE=266.130\n",
      "   48h  MAE=156.430  RMSE=315.717\n",
      "   72h  MAE=171.780  RMSE=342.920\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97dd96e6b50648d386e93a63aee86665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 39/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0ddce79d1144b58bb68d71486cac6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 40/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4be5104e8914ed89a18fdf1e43e9af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40: train_loss=0.156351 val_avg_MAE=140.454\n",
      "\n",
      "VAL\n",
      "   12h  MAE=112.206  RMSE=237.664\n",
      "   24h  MAE=132.444  RMSE=273.634\n",
      "   48h  MAE=152.302  RMSE=303.295\n",
      "   72h  MAE=164.863  RMSE=323.979\n",
      "Saved history: artifacts/runs/20260209_045856_STGCN/history.csv\n",
      "\n",
      "Evaluating on TEST set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0808edafeaaf47829da3e674e6816a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STGCN — TEST\n",
      "   12h  MAE=119.126  RMSE=243.996\n",
      "   24h  MAE=121.787  RMSE=247.606\n",
      "   48h  MAE=139.610  RMSE=289.304\n",
      "   72h  MAE=148.542  RMSE=300.345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bc9a157b36452fb30869b86f7636ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collect preds:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved run outputs to: artifacts/runs/20260209_045856_STGCN\n",
      " - best checkpoint: artifacts/runs/20260209_045856_STGCN/best.pt\n",
      " - history: artifacts/runs/20260209_045856_STGCN/history.csv\n",
      " - test metrics: artifacts/runs/20260209_045856_STGCN/test_metrics.json\n",
      " - predictions (npz): artifacts/runs/20260209_045856_STGCN/test_pred_true_selected_horizons.npz\n",
      " - predictions (xlsx): artifacts/runs/20260209_045856_STGCN/test_pred_true_selected_horizons.xlsx\n",
      " - master summary: artifacts/results_summary.csv\n"
     ]
    }
   ],
   "source": [
    "stgcn_base = STGCN_MultiHorizon(\n",
    "    num_nodes=N,\n",
    "    in_dim=Fdim,\n",
    "    out_len=OUT_LEN,\n",
    "    L_sp=L_sp,\n",
    "    kt=3,       # temporal kernel\n",
    "    Ks=3,       # cheb order\n",
    "    dropout=0.1,\n",
    "    c_t=64, c_s=16, c_out=64,\n",
    "    blocks=2\n",
    ").to(DEVICE)\n",
    "\n",
    "# Sanity forward\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "with torch.no_grad():\n",
    "    out = stgcn_base(xb.to(DEVICE), tfb.to(DEVICE))\n",
    "print(\"Forward output:\", out.shape, \"scaled pred stats:\", float(out.mean()), float(out.std()))\n",
    "\n",
    "run_dir = run_experiment_and_save(\n",
    "    model_name=\"STGCN\",\n",
    "    model=stgcn_base,\n",
    "    epochs=40,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    "    horizons_to_save=(12,24,48,72),\n",
    "    max_stations_excel=300\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09be3d4-833f-4a44-bcdf-f6f5c355d0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4eb3f75-cbcd-4fbe-820b-1b1c6d788f27",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
