{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89513630-ec30-466f-b512-fcd1050f72a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.1+cu121\n",
      "CUDA available: True\n",
      "GPU: Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f9d8553-4c0d-4698-a4bd-7c236dbb911a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: artifacts/pems_graph_dataset_strict.npz\n",
      "Keys: ['X', 'Y', 'A', 'stations', 'timestamps', 'train_starts', 'val_starts', 'test_starts', 'in_len', 'out_len', 'flow_mean', 'flow_std', 'speed_mean', 'speed_std']\n",
      "X: (2208, 1821, 6) Y: (2208, 1821)\n",
      "A: (1821, 1821)\n",
      "IN_LEN: 24 OUT_LEN: 72\n",
      "Stations: 1821\n",
      "Time range: 2024-10-01 00:00:00 → 2024-12-31 23:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134/1765687619.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  IN_LEN  = int(data[\"in_len\"])\n",
      "/tmp/ipykernel_134/1765687619.py:22: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  OUT_LEN = int(data[\"out_len\"])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path(\"artifacts/pems_graph_dataset_strict.npz\")\n",
    "assert DATA_PATH.exists(), f\"Missing dataset: {DATA_PATH}\"\n",
    "\n",
    "data = np.load(DATA_PATH, allow_pickle=True)\n",
    "print(\"Loaded:\", DATA_PATH)\n",
    "print(\"Keys:\", list(data.keys()))\n",
    "\n",
    "X = data[\"X\"].astype(np.float32)          # (T,N,F)\n",
    "Y = data[\"Y\"].astype(np.float32)          # (T,N)\n",
    "A = data[\"A\"].astype(np.float32)          # (N,N)\n",
    "\n",
    "stations = data[\"stations\"]\n",
    "timestamps = pd.to_datetime(data[\"timestamps\"])\n",
    "\n",
    "train_starts = data[\"train_starts\"]\n",
    "val_starts   = data[\"val_starts\"]\n",
    "test_starts  = data[\"test_starts\"]\n",
    "\n",
    "IN_LEN  = int(data[\"in_len\"])\n",
    "OUT_LEN = int(data[\"out_len\"])\n",
    "\n",
    "flow_mean  = data[\"flow_mean\"]\n",
    "flow_std   = data[\"flow_std\"]\n",
    "speed_mean = data[\"speed_mean\"]\n",
    "speed_std  = data[\"speed_std\"]\n",
    "\n",
    "T, N, Fdim = X.shape\n",
    "print(\"X:\", X.shape, \"Y:\", Y.shape)\n",
    "print(\"A:\", A.shape)\n",
    "print(\"IN_LEN:\", IN_LEN, \"OUT_LEN:\", OUT_LEN)\n",
    "print(\"Stations:\", len(stations))\n",
    "print(\"Time range:\", timestamps.min(), \"→\", timestamps.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b7e727-63ad-42f0-8f9c-8fa91dadec11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_sp nnz: 7856\n"
     ]
    }
   ],
   "source": [
    "def scaled_laplacian(A):\n",
    "    A = np.maximum(A, A.T)                     # undirected\n",
    "    A = A + np.eye(A.shape[0], dtype=np.float32)\n",
    "\n",
    "    d = A.sum(axis=1)\n",
    "    d_inv_sqrt = np.power(d, -0.5, where=(d > 0))\n",
    "    d_inv_sqrt[~np.isfinite(d_inv_sqrt)] = 0.0\n",
    "\n",
    "    A_norm = (d_inv_sqrt[:, None] * A) * d_inv_sqrt[None, :]\n",
    "    L = np.eye(A.shape[0], dtype=np.float32) - A_norm\n",
    "\n",
    "    lambda_max = 2.0\n",
    "    L_tilde = (2.0 / lambda_max) * L - np.eye(A.shape[0], dtype=np.float32)\n",
    "    return L_tilde\n",
    "\n",
    "def dense_to_sparse(A_dense, device):\n",
    "    idx = np.nonzero(A_dense)\n",
    "    indices = torch.tensor(np.vstack(idx), dtype=torch.long)\n",
    "    values = torch.tensor(A_dense[idx], dtype=torch.float32)\n",
    "    return torch.sparse_coo_tensor(\n",
    "        indices, values, size=A_dense.shape, device=device\n",
    "    ).coalesce()\n",
    "\n",
    "L_tilde = scaled_laplacian(A)\n",
    "L_sp = dense_to_sparse(L_tilde, DEVICE)\n",
    "\n",
    "print(\"L_sp nnz:\", int(L_sp._nnz()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69bf968f-0273-4521-82ff-96a7521803af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x: torch.Size([8, 6, 1821, 24]) Batch y: torch.Size([8, 72, 1821])\n"
     ]
    }
   ],
   "source": [
    "class STGCNDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y, starts, in_len, out_len,\n",
    "                 flow_mean, flow_std, speed_mean, speed_std):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.starts = starts.astype(int)\n",
    "        self.in_len = in_len\n",
    "        self.out_len = out_len\n",
    "        self.flow_mean = flow_mean\n",
    "        self.flow_std = flow_std\n",
    "        self.speed_mean = speed_mean\n",
    "        self.speed_std = speed_std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.starts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = self.starts[idx]\n",
    "\n",
    "        x = self.X[t:t+self.in_len].copy()      # (IN,N,F)\n",
    "        y = self.Y[t+self.in_len:t+self.in_len+self.out_len].copy()\n",
    "\n",
    "        # scale\n",
    "        x[:, :, 0] = (x[:, :, 0] - self.flow_mean) / self.flow_std\n",
    "        x[:, :, 1] = (x[:, :, 1] - self.speed_mean) / self.speed_std\n",
    "        y = (y - self.flow_mean) / self.flow_std\n",
    "\n",
    "        x = np.transpose(x, (2,1,0))            # (F,N,IN)\n",
    "\n",
    "        return (\n",
    "            torch.tensor(x, dtype=torch.float32),\n",
    "            torch.tensor(y, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "train_ds = STGCNDataset(X, Y, train_starts, IN_LEN, OUT_LEN,\n",
    "                         flow_mean, flow_std, speed_mean, speed_std)\n",
    "val_ds   = STGCNDataset(X, Y, val_starts, IN_LEN, OUT_LEN,\n",
    "                         flow_mean, flow_std, speed_mean, speed_std)\n",
    "test_ds  = STGCNDataset(X, Y, test_starts, IN_LEN, OUT_LEN,\n",
    "                         flow_mean, flow_std, speed_mean, speed_std)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=0, pin_memory=False\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=0, pin_memory=False\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=0, pin_memory=False\n",
    ")\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"Batch x:\", xb.shape, \"Batch y:\", yb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b9ce7c-cc27-4b6e-8de8-5d263ef58a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IN_LEN  = int(np.array(data[\"in_len\"]).item())\n",
    "OUT_LEN = int(np.array(data[\"out_len\"]).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89519cd1-6e06-4b30-80de-4af91db3b4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd3d2b2a-699d-4103-bbda-5116fa04022e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json, time, gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "EVAL_HORIZONS = [12, 24, 48, 72]\n",
    "\n",
    "def print_metrics(title, metrics):\n",
    "    print(\"\\n\" + title)\n",
    "    for h in sorted(metrics.keys()):\n",
    "        print(f\"  {h:>3}h  MAE={metrics[h]['MAE']:.3f}  RMSE={metrics[h]['RMSE']:.3f}\")\n",
    "\n",
    "def avg_mae(metrics):\n",
    "    return float(np.mean([metrics[h][\"MAE\"] for h in metrics]))\n",
    "\n",
    "def _unscale(y_scaled, flow_mean_t, flow_std_t):\n",
    "    return y_scaled * flow_std_t + flow_mean_t\n",
    "\n",
    "@torch.inference_mode()\n",
    "def eval_horizons_fast(model, loader, device, flow_mean, flow_std, eval_horizons=EVAL_HORIZONS):\n",
    "    model.eval()\n",
    "    flow_mean_t = torch.tensor(flow_mean, dtype=torch.float32, device=device).view(1, 1, -1)\n",
    "    flow_std_t  = torch.tensor(flow_std,  dtype=torch.float32, device=device).view(1, 1, -1)\n",
    "    h_idx = torch.tensor([h - 1 for h in eval_horizons], device=device)\n",
    "\n",
    "    acc = {h: {\"abs\": 0.0, \"sq\": 0.0, \"count\": 0} for h in eval_horizons}\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        if len(batch) == 2:\n",
    "            xb, yb = batch\n",
    "            tfb = None\n",
    "        else:\n",
    "            xb, yb, tfb = batch\n",
    "\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "        if tfb is not None:\n",
    "            tfb = tfb.to(device, non_blocking=True)\n",
    "\n",
    "        pred = model(xb, tfb) if tfb is not None else model(xb)  # scaled\n",
    "\n",
    "        pred_u = _unscale(pred, flow_mean_t, flow_std_t)\n",
    "        true_u = _unscale(yb,   flow_mean_t, flow_std_t)\n",
    "\n",
    "        pred_h = pred_u[:, h_idx, :]  # (B, H, N)\n",
    "        true_h = true_u[:, h_idx, :]\n",
    "        err = pred_h - true_h\n",
    "\n",
    "        for i, h in enumerate(eval_horizons):\n",
    "            e = err[:, i, :]\n",
    "            acc[h][\"abs\"] += float(e.abs().sum().item())\n",
    "            acc[h][\"sq\"]  += float((e * e).sum().item())\n",
    "            acc[h][\"count\"] += e.numel()\n",
    "\n",
    "    metrics = {}\n",
    "    for h in eval_horizons:\n",
    "        mae = acc[h][\"abs\"] / acc[h][\"count\"]\n",
    "        rmse = (acc[h][\"sq\"] / acc[h][\"count\"]) ** 0.5\n",
    "        metrics[h] = {\"MAE\": float(mae), \"RMSE\": float(rmse)}\n",
    "    return metrics\n",
    "\n",
    "def make_run_dir(model_name, base_dir=\"artifacts/runs\"):\n",
    "    base = Path(base_dir)\n",
    "    base.mkdir(parents=True, exist_ok=True)\n",
    "    stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = base / f\"{stamp}_{model_name}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def save_json(path: Path, obj):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def metrics_to_flat_row(metrics, prefix):\n",
    "    row = {}\n",
    "    for h in sorted(metrics.keys()):\n",
    "        row[f\"{prefix}_MAE_{h}h\"]  = metrics[h][\"MAE\"]\n",
    "        row[f\"{prefix}_RMSE_{h}h\"] = metrics[h][\"RMSE\"]\n",
    "    return row\n",
    "\n",
    "def append_master_summary(row_dict, master_csv=\"artifacts/results_summary.csv\"):\n",
    "    master = Path(master_csv)\n",
    "    master.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_new = pd.DataFrame([row_dict])\n",
    "    if master.exists():\n",
    "        df_old = pd.read_csv(master)\n",
    "        df = pd.concat([df_old, df_new], ignore_index=True)\n",
    "    else:\n",
    "        df = df_new\n",
    "    df.to_csv(master, index=False)\n",
    "    return master\n",
    "\n",
    "@torch.inference_mode()\n",
    "def collect_preds_true_selected(model, loader, device, flow_mean, flow_std,\n",
    "                               horizons_to_save=(12, 24, 48, 72),\n",
    "                               stations_all=None,\n",
    "                               timestamps_all=None,\n",
    "                               in_len=None,\n",
    "                               max_stations=300):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      pred_u: (S, H, M)\n",
    "      true_u: (S, H, M)\n",
    "      horizons: list\n",
    "      station_ids: (M,)\n",
    "      ts_h: (S, H) timestamps for each sample/horizon if possible else None\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    flow_mean_t = torch.tensor(flow_mean, dtype=torch.float32, device=device).view(1, 1, -1)\n",
    "    flow_std_t  = torch.tensor(flow_std,  dtype=torch.float32, device=device).view(1, 1, -1)\n",
    "    horizons = list(horizons_to_save)\n",
    "    h_idx = torch.tensor([h - 1 for h in horizons], device=device)\n",
    "\n",
    "    # station subset\n",
    "    N = len(stations_all) if stations_all is not None else None\n",
    "    if (max_stations is None) or (N is None) or (max_stations >= N):\n",
    "        sel = None\n",
    "        station_ids = np.array(stations_all) if stations_all is not None else None\n",
    "    else:\n",
    "        sel = np.arange(max_stations, dtype=int)\n",
    "        station_ids = np.array(stations_all)[sel]\n",
    "\n",
    "    preds, trues = [], []\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Collect preds\", leave=False):\n",
    "        if len(batch) == 2:\n",
    "            xb, yb = batch\n",
    "            tfb = None\n",
    "        else:\n",
    "            xb, yb, tfb = batch\n",
    "\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "        if tfb is not None:\n",
    "            tfb = tfb.to(device, non_blocking=True)\n",
    "\n",
    "        pred = model(xb, tfb) if tfb is not None else model(xb)  # scaled\n",
    "\n",
    "        pred_u = _unscale(pred, flow_mean_t, flow_std_t)[:, h_idx, :]  # (B,H,N)\n",
    "        true_u = _unscale(yb,   flow_mean_t, flow_std_t)[:, h_idx, :]\n",
    "\n",
    "        if sel is not None:\n",
    "            pred_u = pred_u[:, :, sel]\n",
    "            true_u = true_u[:, :, sel]\n",
    "\n",
    "        preds.append(pred_u.detach().cpu())\n",
    "        trues.append(true_u.detach().cpu())\n",
    "\n",
    "    pred_u = torch.cat(preds, dim=0).numpy()\n",
    "    true_u = torch.cat(trues, dim=0).numpy()\n",
    "\n",
    "    # timestamps for each sample/horizon (optional)\n",
    "    ts_h = None\n",
    "    if (timestamps_all is not None) and (in_len is not None) and hasattr(loader.dataset, \"starts\"):\n",
    "        starts = np.array(loader.dataset.starts, dtype=int)  # (S,)\n",
    "        # For each horizon h, timestamp = timestamps[start + in_len + (h-1)]\n",
    "        ts_h = np.zeros((len(starts), len(horizons)), dtype=\"datetime64[ns]\")\n",
    "        ts_all = pd.to_datetime(timestamps_all).to_numpy()\n",
    "        for j, h in enumerate(horizons):\n",
    "            ts_h[:, j] = ts_all[starts + in_len + (h - 1)]\n",
    "\n",
    "    return pred_u, true_u, horizons, station_ids, ts_h\n",
    "\n",
    "def save_preds_to_excel_and_csv(run_dir: Path, pred_u, true_u, horizons, station_ids, ts_h=None):\n",
    "    # NPZ (always)\n",
    "    npz_path = run_dir / \"test_pred_true_selected_horizons.npz\"\n",
    "    np.savez_compressed(\n",
    "        npz_path,\n",
    "        pred=pred_u,\n",
    "        true=true_u,\n",
    "        horizons=np.array(horizons, dtype=int),\n",
    "        stations=np.array(station_ids) if station_ids is not None else None,\n",
    "        timestamps=ts_h\n",
    "    )\n",
    "\n",
    "    # Excel + CSV per horizon (readable)\n",
    "    xlsx_path = run_dir / \"test_pred_true_selected_horizons.xlsx\"\n",
    "    csv_dir = run_dir / \"preds_csv\"\n",
    "    csv_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with pd.ExcelWriter(xlsx_path, engine=\"openpyxl\") as writer:\n",
    "        for j, h in enumerate(horizons):\n",
    "            cols = [str(s) for s in station_ids] if station_ids is not None else [f\"node_{i}\" for i in range(pred_u.shape[2])]\n",
    "            df_pred = pd.DataFrame(pred_u[:, j, :], columns=cols)\n",
    "            df_true = pd.DataFrame(true_u[:, j, :], columns=cols)\n",
    "\n",
    "            if ts_h is not None:\n",
    "                df_pred.insert(0, \"timestamp\", pd.to_datetime(ts_h[:, j]))\n",
    "                df_true.insert(0, \"timestamp\", pd.to_datetime(ts_h[:, j]))\n",
    "\n",
    "            df_pred.to_excel(writer, sheet_name=f\"pred_{h}h\", index=False)\n",
    "            df_true.to_excel(writer, sheet_name=f\"true_{h}h\", index=False)\n",
    "\n",
    "            # CSV versions too\n",
    "            df_pred.to_csv(csv_dir / f\"pred_{h}h.csv\", index=False)\n",
    "            df_true.to_csv(csv_dir / f\"true_{h}h.csv\", index=False)\n",
    "\n",
    "    return npz_path, xlsx_path, csv_dir\n",
    "\n",
    "def train_and_save_best(model, model_name, run_dir: Path,\n",
    "                        train_loader, val_loader,\n",
    "                        device,\n",
    "                        flow_mean, flow_std,\n",
    "                        epochs=40, lr=1e-3, weight_decay=1e-4, clip=5.0,\n",
    "                        patience=6, eval_every=2):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.SmoothL1Loss(beta=1.0)\n",
    "\n",
    "    best_score = float(\"inf\")\n",
    "    best_state = None\n",
    "    bad = 0\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Train {epoch}/{epochs}\", leave=False):\n",
    "            if len(batch) == 2:\n",
    "                xb, yb = batch\n",
    "                tfb = None\n",
    "            else:\n",
    "                xb, yb, tfb = batch\n",
    "\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            if tfb is not None:\n",
    "                tfb = tfb.to(device, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            pred = model(xb, tfb) if tfb is not None else model(xb)  # scaled\n",
    "            loss = loss_fn(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "            running += float(loss.item())\n",
    "\n",
    "        train_loss = running / max(1, len(train_loader))\n",
    "\n",
    "        if epoch % eval_every == 0:\n",
    "            val_metrics = eval_horizons_fast(model, val_loader, device, flow_mean, flow_std)\n",
    "            score = avg_mae(val_metrics)\n",
    "\n",
    "            print(f\"\\nEpoch {epoch}: train_loss={train_loss:.6f} val_avg_MAE={score:.3f}\")\n",
    "            print_metrics(\"VAL\", val_metrics)\n",
    "\n",
    "            history.append({\"epoch\": epoch, \"train_loss\": train_loss, \"val_avg_MAE\": score, **metrics_to_flat_row(val_metrics, \"val\")})\n",
    "            pd.DataFrame(history).to_csv(run_dir / \"history.csv\", index=False)\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                torch.save(best_state, run_dir / \"best.pt\")\n",
    "                bad = 0\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= patience:\n",
    "                    print(f\"\\nEarly stopping. Best val_avg_MAE={best_score:.3f}\")\n",
    "                    break\n",
    "\n",
    "    if best_state is None:\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        torch.save(best_state, run_dir / \"best.pt\")\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "def run_experiment_and_save(model_name, model,\n",
    "                            train_loader, val_loader, test_loader,\n",
    "                            device,\n",
    "                            flow_mean, flow_std,\n",
    "                            stations, timestamps,\n",
    "                            in_len,\n",
    "                            epochs=40, patience=6, eval_every=2,\n",
    "                            horizons_to_save=(12, 24, 48, 72),\n",
    "                            max_stations_excel=300):\n",
    "    run_dir = make_run_dir(model_name)\n",
    "    print(\"Run dir:\", run_dir)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Train (and keep saving best.pt + history.csv)\n",
    "    model = train_and_save_best(\n",
    "        model=model,\n",
    "        model_name=model_name,\n",
    "        run_dir=run_dir,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        flow_mean=flow_mean,\n",
    "        flow_std=flow_std,\n",
    "        epochs=epochs,\n",
    "        patience=patience,\n",
    "        eval_every=eval_every\n",
    "    )\n",
    "\n",
    "    # TEST\n",
    "    print(\"\\nEvaluating on TEST set...\")\n",
    "    test_metrics = eval_horizons_fast(model, test_loader, device, flow_mean, flow_std)\n",
    "    print_metrics(f\"{model_name} — TEST\", test_metrics)\n",
    "\n",
    "    save_json(run_dir / \"test_metrics.json\", test_metrics)\n",
    "    pd.DataFrame([metrics_to_flat_row(test_metrics, \"test\")]).to_csv(run_dir / \"test_metrics.csv\", index=False)\n",
    "\n",
    "    # Save preds/true for selected horizons + subset of stations (NPZ + XLSX + CSV)\n",
    "    pred_u, true_u, horizons, station_ids, ts_h = collect_preds_true_selected(\n",
    "        model=model,\n",
    "        loader=test_loader,\n",
    "        device=device,\n",
    "        flow_mean=flow_mean,\n",
    "        flow_std=flow_std,\n",
    "        horizons_to_save=horizons_to_save,\n",
    "        stations_all=stations,\n",
    "        timestamps_all=timestamps,\n",
    "        in_len=in_len,\n",
    "        max_stations=max_stations_excel\n",
    "    )\n",
    "\n",
    "    npz_path, xlsx_path, csv_dir = save_preds_to_excel_and_csv(run_dir, pred_u, true_u, horizons, station_ids, ts_h)\n",
    "\n",
    "    # Append to master summary\n",
    "    row = {\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model_name\": model_name,\n",
    "        \"run_dir\": str(run_dir),\n",
    "        **metrics_to_flat_row(test_metrics, \"test\")\n",
    "    }\n",
    "    master = append_master_summary(row)\n",
    "\n",
    "    print(\"\\nSaved run outputs to:\", run_dir)\n",
    "    print(\" - best checkpoint:\", run_dir / \"best.pt\")\n",
    "    print(\" - history:\", run_dir / \"history.csv\")\n",
    "    print(\" - test metrics (json):\", run_dir / \"test_metrics.json\")\n",
    "    print(\" - test metrics (csv):\", run_dir / \"test_metrics.csv\")\n",
    "    print(\" - predictions (npz):\", npz_path)\n",
    "    print(\" - predictions (xlsx):\", xlsx_path)\n",
    "    print(\" - predictions (csv folder):\", csv_dir)\n",
    "    print(\" - master summary:\", master)\n",
    "\n",
    "    return run_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f70b0ef1-a15f-4c5c-a382-7f3650912c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STGCN_RNNHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrap a base STGCN model and refine its multi-horizon output using GRU/LSTM.\n",
    "    Base model must output (B, OUT_LEN, N) in *scaled* space.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model: nn.Module, out_len: int, rnn_hidden: int = 128,\n",
    "                 use_gru: bool = False, use_lstm: bool = False):\n",
    "        super().__init__()\n",
    "        assert use_gru or use_lstm, \"Turn on at least one of use_gru/use_lstm.\"\n",
    "        self.base = base_model\n",
    "        self.out_len = out_len\n",
    "\n",
    "        in_dim = 1  # we feed the STGCN scalar output sequence per node\n",
    "\n",
    "        self.gru = nn.GRU(in_dim, rnn_hidden, batch_first=True) if use_gru else None\n",
    "        rnn_in = rnn_hidden if use_gru else in_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(rnn_in, rnn_hidden, batch_first=True) if use_lstm else None\n",
    "        rnn_out = rnn_hidden if use_lstm else rnn_in\n",
    "\n",
    "        self.proj = nn.Linear(rnn_out, 1)\n",
    "\n",
    "    def forward(self, x, tf=None):\n",
    "        y0 = self.base(x, tf) if tf is not None else self.base(x)   # (B, T, N)\n",
    "        B, T, N = y0.shape\n",
    "\n",
    "        seq = y0.permute(0, 2, 1).contiguous().view(B * N, T, 1)     # (B*N, T, 1)\n",
    "\n",
    "        out = seq\n",
    "        if self.gru is not None:\n",
    "            out, _ = self.gru(out)\n",
    "        if self.lstm is not None:\n",
    "            out, _ = self.lstm(out)\n",
    "\n",
    "        out = self.proj(out)                                        # (B*N, T, 1)\n",
    "        out = out.view(B, N, T).permute(0, 2, 1).contiguous()        # (B, T, N)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813ac5f4-0f13-4f25-aec7-dce9ab87546b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_stgcn():\n",
    "    return STGCN_MultiHorizon(\n",
    "        num_nodes=N,\n",
    "        in_dim=Fdim,\n",
    "        out_len=OUT_LEN,\n",
    "        L_sp=L_sp,\n",
    "        kt=3,\n",
    "        Ks=3,\n",
    "        dropout=0.1,\n",
    "        c_t=64, c_s=16, c_out=64,\n",
    "        blocks=2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7dc5a59-53d5-4795-9fba-ebd9cb8de265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# -------------------------\n",
    "# Helpers: sparse node-mix\n",
    "# -------------------------\n",
    "def nconv_sparse(x: torch.Tensor, A_sp: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x: (B, C, N, T)\n",
    "    A_sp: sparse (N, N)\n",
    "    returns: (B, C, N, T)\n",
    "    \"\"\"\n",
    "    B, C, N, T = x.shape\n",
    "    x_r = x.permute(2, 0, 1, 3).reshape(N, -1)          # (N, B*C*T)\n",
    "    x_r = torch.sparse.mm(A_sp, x_r)                    # (N, B*C*T)\n",
    "    x_out = x_r.reshape(N, B, C, T).permute(1, 2, 0, 3) # (B,C,N,T)\n",
    "    return x_out\n",
    "\n",
    "\n",
    "class TemporalConvGLU(nn.Module):\n",
    "    \"\"\"\n",
    "    Causal temporal conv with GLU gating.\n",
    "    Input/Output: (B,C,N,T)\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in: int, c_out: int, kt: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.kt = kt\n",
    "        self.conv = nn.Conv2d(c_in, 2*c_out, kernel_size=(1, kt), bias=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # causal pad on the left in time dimension (last dim)\n",
    "        x = F.pad(x, (self.kt - 1, 0, 0, 0))     # pad time: (left, right, top, bottom) for last two dims\n",
    "        z = self.conv(x)                         # (B, 2*Cout, N, T)\n",
    "        a, b = z.chunk(2, dim=1)\n",
    "        out = a * torch.sigmoid(b)\n",
    "        return self.dropout(out)\n",
    "\n",
    "\n",
    "class ChebGraphConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Chebyshev graph convolution with Ks terms.\n",
    "    Uses sparse scaled Laplacian L_sp (N,N).\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in: int, c_out: int, Ks: int, L_sp: torch.Tensor):\n",
    "        super().__init__()\n",
    "        assert Ks >= 1\n",
    "        self.Ks = Ks\n",
    "        self.L_sp = L_sp\n",
    "        self.theta = nn.Conv2d(Ks * c_in, c_out, kernel_size=(1, 1), bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,C,N,T)\n",
    "        out = [x]  # T0\n",
    "        if self.Ks > 1:\n",
    "            x1 = nconv_sparse(x, self.L_sp)  # T1\n",
    "            out.append(x1)\n",
    "            for _ in range(2, self.Ks):\n",
    "                x2 = 2 * nconv_sparse(out[-1], self.L_sp) - out[-2]  # Tk\n",
    "                out.append(x2)\n",
    "\n",
    "        x_cat = torch.cat(out, dim=1)  # (B, Ks*C, N, T)\n",
    "        return self.theta(x_cat)\n",
    "\n",
    "\n",
    "class STConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ST block: TemporalConv -> GraphConv -> TemporalConv (+ residual)\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_t, c_s, c_out, kt, Ks, L_sp, dropout):\n",
    "        super().__init__()\n",
    "        self.temp1 = TemporalConvGLU(c_in,  c_t,  kt=kt, dropout=dropout)\n",
    "        self.gconv = ChebGraphConv(c_t, c_s, Ks=Ks, L_sp=L_sp)\n",
    "        self.temp2 = TemporalConvGLU(c_s,  c_out, kt=kt, dropout=dropout)\n",
    "\n",
    "        self.res = None\n",
    "        if c_in != c_out:\n",
    "            self.res = nn.Conv2d(c_in, c_out, kernel_size=(1,1))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "        x = self.temp1(x)\n",
    "        x = F.relu(self.gconv(x))\n",
    "        x = self.temp2(x)\n",
    "\n",
    "        if self.res is not None:\n",
    "            x_in = self.res(x_in)\n",
    "\n",
    "        x = F.relu(x + x_in)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class STGCN_MultiHorizon(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-horizon forecaster:\n",
    "      encode past window -> take last time state -> project to OUT_LEN for each node\n",
    "    forward(x, tf) keeps signature compatible (tf is ignored here).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes: int,\n",
    "        in_dim: int,\n",
    "        out_len: int,\n",
    "        L_sp: torch.Tensor,\n",
    "        kt: int = 3,\n",
    "        Ks: int = 3,\n",
    "        dropout: float = 0.1,\n",
    "        c_t: int = 64,\n",
    "        c_s: int = 16,\n",
    "        c_out: int = 64,\n",
    "        blocks: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.in_dim = in_dim\n",
    "        self.out_len = out_len\n",
    "        self.c_out = c_out\n",
    "\n",
    "        layers = []\n",
    "        c_in = in_dim\n",
    "        for _ in range(blocks):\n",
    "            layers.append(STConvBlock(\n",
    "                c_in=c_in, c_t=c_t, c_s=c_s, c_out=c_out,\n",
    "                kt=kt, Ks=Ks, L_sp=L_sp, dropout=dropout\n",
    "            ))\n",
    "            c_in = c_out\n",
    "        self.blocks = nn.ModuleList(layers)\n",
    "\n",
    "        # node-wise linear map: (B, c_out, N) -> (B, out_len, N)\n",
    "        self.head = nn.Conv1d(c_out, out_len, kernel_size=1)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # x: (B,F,N,T)\n",
    "        h = x\n",
    "        for blk in self.blocks:\n",
    "            h = blk(h)  # (B,c_out,N,T)\n",
    "        return h\n",
    "\n",
    "    def forward(self, x, tf=None):\n",
    "        h = self.encode(x)\n",
    "        h_last = h[:, :, :, -1]           # (B, c_out, N)\n",
    "        out = self.head(h_last)           # (B, out_len, N)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a630419-45ea-4577-a54d-34a79962cd92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class STGCN_RNNHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrap STGCN encoder with optional GRU and/or LSTM over the encoder time sequence per node.\n",
    "    If both are enabled: GRU -> LSTM (stacked).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        base: STGCN_MultiHorizon,\n",
    "        out_len: int,\n",
    "        rnn_hidden: int = 128,\n",
    "        use_gru: bool = False,\n",
    "        use_lstm: bool = False,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert use_gru or use_lstm, \"Enable at least one of GRU/LSTM\"\n",
    "        self.base = base\n",
    "        self.out_len = out_len\n",
    "        self.use_gru = use_gru\n",
    "        self.use_lstm = use_lstm\n",
    "        self.rnn_hidden = rnn_hidden\n",
    "\n",
    "        enc_dim = base.c_out\n",
    "\n",
    "        self.gru = None\n",
    "        self.lstm = None\n",
    "\n",
    "        if use_gru:\n",
    "            self.gru = nn.GRU(\n",
    "                input_size=enc_dim,\n",
    "                hidden_size=rnn_hidden,\n",
    "                num_layers=1,\n",
    "                batch_first=True,\n",
    "                dropout=0.0\n",
    "            )\n",
    "\n",
    "        if use_lstm:\n",
    "            lstm_in = rnn_hidden if use_gru else enc_dim\n",
    "            self.lstm = nn.LSTM(\n",
    "                input_size=lstm_in,\n",
    "                hidden_size=rnn_hidden,\n",
    "                num_layers=1,\n",
    "                batch_first=True,\n",
    "                dropout=0.0\n",
    "            )\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.head = nn.Conv1d(rnn_hidden, out_len, kernel_size=1)\n",
    "\n",
    "    def forward(self, x, tf=None):\n",
    "        # Encode: (B,C,N,T)\n",
    "        feat = self.base.encode(x)\n",
    "        B, C, N, T = feat.shape\n",
    "\n",
    "        # per-node sequences: (B*N, T, C)\n",
    "        seq = feat.permute(0, 2, 3, 1).contiguous().view(B*N, T, C)\n",
    "\n",
    "        if self.use_gru:\n",
    "            seq, _ = self.gru(seq)  # (B*N, T, H)\n",
    "\n",
    "        if self.use_lstm:\n",
    "            seq, _ = self.lstm(seq) # (B*N, T, H)\n",
    "\n",
    "        last = seq[:, -1, :]                    # (B*N, H)\n",
    "        last = self.drop(last)\n",
    "        last = last.view(B, N, self.rnn_hidden).permute(0, 2, 1)  # (B,H,N)\n",
    "\n",
    "        out = self.head(last)                   # (B,out_len,N)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98de8f6d-3b60-499e-8841-079fa50e00fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def save_pred_true_csv_long(\n",
    "    out_csv: Path,\n",
    "    pred_u: np.ndarray,   # (S, H, N)\n",
    "    true_u: np.ndarray,   # (S, H, N)\n",
    "    horizons: list[int],\n",
    "    station_ids: list[str] | None = None,\n",
    "    max_stations: int = 300,\n",
    "):\n",
    "    \"\"\"\n",
    "    Saves long-form CSV:\n",
    "      sample, horizon, station, y_true, y_pred\n",
    "    To keep it sane, we limit to first max_stations.\n",
    "    \"\"\"\n",
    "    S, H, N = pred_u.shape\n",
    "    assert H == len(horizons)\n",
    "\n",
    "    take = min(N, max_stations)\n",
    "    stations = station_ids[:take] if station_ids is not None else [f\"node_{i}\" for i in range(take)]\n",
    "\n",
    "    rows = []\n",
    "    for hi, h in enumerate(horizons):\n",
    "        # (S, take)\n",
    "        p = pred_u[:, hi, :take]\n",
    "        t = true_u[:, hi, :take]\n",
    "\n",
    "        # build long rows efficiently\n",
    "        sample_idx = np.repeat(np.arange(S), take)\n",
    "        station_col = np.tile(np.array(stations, dtype=object), S)\n",
    "\n",
    "        df_h = pd.DataFrame({\n",
    "            \"sample\": sample_idx,\n",
    "            \"horizon_h\": h,\n",
    "            \"station\": station_col,\n",
    "            \"y_true\": t.reshape(-1),\n",
    "            \"y_pred\": p.reshape(-1),\n",
    "        })\n",
    "        rows.append(df_h)\n",
    "\n",
    "    df = pd.concat(rows, ignore_index=True)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return out_csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d3352-3e78-444b-b8a3-eabbe61866a6",
   "metadata": {},
   "source": [
    "### WORKING ON STGCN AGAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691985f4-5b04-4bc4-a410-ed56026f3e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.1.1+cu121\n",
      "Device: cuda\n",
      "GPU: Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "import os, json, time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ---------------- Repro ----------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Device:\", DEVICE)\n",
    "if DEVICE == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1705b30d-f128-4bf7-9f88-fb7d56704077",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: artifacts/pems_graph_dataset_strict.npz\n",
      "Keys: ['X', 'Y', 'A', 'stations', 'timestamps', 'train_starts', 'val_starts', 'test_starts', 'in_len', 'out_len', 'flow_mean', 'flow_std', 'speed_mean', 'speed_std']\n",
      "\n",
      "Shapes:\n",
      "X_raw: (2208, 1821, 6) (T,N,F)\n",
      "Y_raw: (2208, 1821) (T,N)\n",
      "A: (1821, 1821)\n",
      "IN_LEN: 24 OUT_LEN: 72\n",
      "train/val/test starts: 1009 289 673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43/3711306228.py:18: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  IN_LEN  = int(data[\"in_len\"])\n",
      "/tmp/ipykernel_43/3711306228.py:19: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  OUT_LEN = int(data[\"out_len\"])\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"artifacts/pems_graph_dataset_strict.npz\")\n",
    "assert DATA_PATH.exists(), f\"Missing {DATA_PATH}. Rebuild the dataset first.\"\n",
    "\n",
    "data = np.load(DATA_PATH, allow_pickle=True)\n",
    "print(\"Loaded:\", DATA_PATH)\n",
    "print(\"Keys:\", list(data.keys()))\n",
    "\n",
    "X_raw = data[\"X\"]            # (T, N, F)\n",
    "Y_raw = data[\"Y\"]            # (T, N)  (flow target)\n",
    "A = data[\"A\"]                # (N, N)\n",
    "stations = data[\"stations\"]\n",
    "timestamps = data[\"timestamps\"]\n",
    "\n",
    "train_starts = data[\"train_starts\"]\n",
    "val_starts   = data[\"val_starts\"]\n",
    "test_starts  = data[\"test_starts\"]\n",
    "\n",
    "IN_LEN  = int(data[\"in_len\"])\n",
    "OUT_LEN = int(data[\"out_len\"])\n",
    "\n",
    "flow_mean = data[\"flow_mean\"]   # (N,)\n",
    "flow_std  = data[\"flow_std\"]    # (N,)\n",
    "speed_mean = data[\"speed_mean\"] # (N,)\n",
    "speed_std  = data[\"speed_std\"]  # (N,)\n",
    "\n",
    "T, N, Fdim = X_raw.shape\n",
    "print(\"\\nShapes:\")\n",
    "print(\"X_raw:\", X_raw.shape, \"(T,N,F)\")\n",
    "print(\"Y_raw:\", Y_raw.shape, \"(T,N)\")\n",
    "print(\"A:\", A.shape)\n",
    "print(\"IN_LEN:\", IN_LEN, \"OUT_LEN:\", OUT_LEN)\n",
    "print(\"train/val/test starts:\", len(train_starts), len(val_starts), len(test_starts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4fc82b-e352-4a7f-a921-51fd16e48c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_fnt: (6, 1821, 2208) Y_scaled: (2208, 1821) TF_all: (2208, 4)\n",
      "Sanity (Y_scaled mean/std approx): -780.4212036132812 30666.189453125\n"
     ]
    }
   ],
   "source": [
    "def time_encoding(dt_index: pd.DatetimeIndex) -> np.ndarray:\n",
    "    hours = dt_index.hour.values\n",
    "    dow   = dt_index.dayofweek.values\n",
    "    hour_sin = np.sin(2*np.pi*hours/24.0)\n",
    "    hour_cos = np.cos(2*np.pi*hours/24.0)\n",
    "    dow_sin  = np.sin(2*np.pi*dow/7.0)\n",
    "    dow_cos  = np.cos(2*np.pi*dow/7.0)\n",
    "    return np.stack([hour_sin, hour_cos, dow_sin, dow_cos], axis=1).astype(np.float32)\n",
    "\n",
    "dt_idx = pd.to_datetime(timestamps)\n",
    "TF_all = time_encoding(dt_idx)         # (T,4)\n",
    "\n",
    "# ----- scale inputs -----\n",
    "X_scaled = X_raw.astype(np.float32).copy()\n",
    "X_scaled[:, :, 0] = (X_scaled[:, :, 0] - flow_mean[None, :]) / (flow_std[None, :] + 1e-6)\n",
    "X_scaled[:, :, 1] = (X_scaled[:, :, 1] - speed_mean[None, :]) / (speed_std[None, :] + 1e-6)\n",
    "\n",
    "# ----- scale targets (flow) -----\n",
    "Y_scaled = (Y_raw.astype(np.float32) - flow_mean[None, :]) / (flow_std[None, :] + 1e-6)\n",
    "\n",
    "# Store for fast slicing as (F,N,T)\n",
    "X_fnt = np.transpose(X_scaled, (2, 1, 0)).copy()  # (F,N,T)\n",
    "\n",
    "print(\"X_fnt:\", X_fnt.shape, \"Y_scaled:\", Y_scaled.shape, \"TF_all:\", TF_all.shape)\n",
    "print(\"Sanity (Y_scaled mean/std approx):\", float(Y_scaled.mean()), float(Y_scaled.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8f7a593-ee85-467e-b6dd-a95264f34500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x: torch.Size([8, 6, 1821, 24]) Batch y: torch.Size([8, 72, 1821]) Batch tf: torch.Size([8, 72, 4])\n"
     ]
    }
   ],
   "source": [
    "class FastPeMSWindowDataset(Dataset):\n",
    "    def __init__(self, X_fnt, Y_scaled, TF_all, starts, in_len, out_len):\n",
    "        self.X_fnt = X_fnt\n",
    "        self.Y = Y_scaled\n",
    "        self.TF = TF_all\n",
    "        self.starts = starts.astype(np.int64)\n",
    "        self.in_len = int(in_len)\n",
    "        self.out_len = int(out_len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.starts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = int(self.starts[idx])\n",
    "        x = self.X_fnt[:, :, t:t+self.in_len]  # (F,N,IN_LEN)\n",
    "        y = self.Y[t+self.in_len:t+self.in_len+self.out_len, :]  # (OUT_LEN,N)\n",
    "        tf = self.TF[t+self.in_len:t+self.in_len+self.out_len, :]  # (OUT_LEN,4)\n",
    "        return (\n",
    "            torch.from_numpy(x).float(),\n",
    "            torch.from_numpy(y).float(),\n",
    "            torch.from_numpy(tf).float()\n",
    "        )\n",
    "\n",
    "train_ds = FastPeMSWindowDataset(X_fnt, Y_scaled, TF_all, train_starts, IN_LEN, OUT_LEN)\n",
    "val_ds   = FastPeMSWindowDataset(X_fnt, Y_scaled, TF_all, val_starts,   IN_LEN, OUT_LEN)\n",
    "test_ds  = FastPeMSWindowDataset(X_fnt, Y_scaled, TF_all, test_starts,  IN_LEN, OUT_LEN)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0, pin_memory=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "print(\"Batch x:\", xb.shape, \"Batch y:\", yb.shape, \"Batch tf:\", tfb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ca9bf5-4491-41d9-9164-6e64ed0bb2da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_sp nnz: 7856\n"
     ]
    }
   ],
   "source": [
    "def dense_to_sparse(A_dense: np.ndarray, device: str):\n",
    "    idx = np.nonzero(A_dense)\n",
    "    indices = torch.from_numpy(np.vstack(idx)).long()\n",
    "    values  = torch.from_numpy(A_dense[idx].astype(np.float32))\n",
    "    sp = torch.sparse_coo_tensor(indices, values, size=A_dense.shape, device=device)\n",
    "    return sp.coalesce()\n",
    "\n",
    "def scaled_laplacian(A: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build scaled Laplacian L_tilde = (2/lambda_max)*L - I.\n",
    "    We follow the common approximation lambda_max ≈ 2. :contentReference[oaicite:3]{index=3}\n",
    "    \"\"\"\n",
    "    A = A.astype(np.float32)\n",
    "    # Make undirected for STGCN (common choice)\n",
    "    A = np.maximum(A, A.T)\n",
    "\n",
    "    # Add self loops\n",
    "    A = A + np.eye(A.shape[0], dtype=np.float32)\n",
    "\n",
    "    d = A.sum(axis=1)\n",
    "    d_inv_sqrt = np.power(d, -0.5, where=(d > 0))\n",
    "    d_inv_sqrt[~np.isfinite(d_inv_sqrt)] = 0.0\n",
    "\n",
    "    A_norm = (d_inv_sqrt[:, None] * A) * d_inv_sqrt[None, :]\n",
    "    L = np.eye(A.shape[0], dtype=np.float32) - A_norm\n",
    "\n",
    "    lambda_max = 2.0\n",
    "    L_tilde = (2.0 / lambda_max) * L - np.eye(A.shape[0], dtype=np.float32)\n",
    "    return L_tilde\n",
    "\n",
    "L_tilde = scaled_laplacian(A)\n",
    "L_sp = dense_to_sparse(L_tilde, DEVICE)\n",
    "print(\"L_sp nnz:\", int(L_sp._nnz()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d387f1c5-ca91-483b-a325-efd5807832a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EVAL_HORIZONS = [12, 24, 48, 72]\n",
    "h_idx = torch.tensor([h-1 for h in EVAL_HORIZONS], device=DEVICE)\n",
    "\n",
    "flow_mean_t = torch.tensor(flow_mean, dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "flow_std_t  = torch.tensor(flow_std,  dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "\n",
    "def print_metrics(title, metrics):\n",
    "    print(\"\\n\" + title)\n",
    "    for h in sorted(metrics.keys()):\n",
    "        print(f\"  {h:>3}h  MAE={metrics[h]['MAE']:.3f}  RMSE={metrics[h]['RMSE']:.3f}\")\n",
    "\n",
    "def avg_mae(metrics):\n",
    "    return float(np.mean([metrics[h][\"MAE\"] for h in metrics]))\n",
    "\n",
    "@torch.inference_mode()\n",
    "def eval_horizons_fast(model, loader):\n",
    "    model.eval()\n",
    "    acc = {h: {\"abs\": 0.0, \"sq\": 0.0, \"count\": 0} for h in EVAL_HORIZONS}\n",
    "\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        pred = model(xb, tfb)  # MUST be scaled outputs (B,OUT_LEN,N)\n",
    "\n",
    "        pred_u = pred * flow_std_t + flow_mean_t\n",
    "        true_u = yb   * flow_std_t + flow_mean_t\n",
    "\n",
    "        # selected horizons\n",
    "        pred_sel = pred_u[:, h_idx, :]\n",
    "        true_sel = true_u[:, h_idx, :]\n",
    "        for i, h in enumerate(EVAL_HORIZONS):\n",
    "            err = pred_sel[:, i, :] - true_sel[:, i, :]\n",
    "            acc[h][\"abs\"] += float(err.abs().sum())\n",
    "            acc[h][\"sq\"]  += float((err ** 2).sum())\n",
    "            acc[h][\"count\"] += err.numel()\n",
    "\n",
    "    metrics = {}\n",
    "    for h in EVAL_HORIZONS:\n",
    "        mae = acc[h][\"abs\"] / acc[h][\"count\"]\n",
    "        rmse = (acc[h][\"sq\"] / acc[h][\"count\"]) ** 0.5\n",
    "        metrics[h] = {\"MAE\": mae, \"RMSE\": rmse}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0457d4f1-c83c-4f14-9f57-edf959387477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NConv(nn.Module):\n",
    "    \"\"\"Sparse matrix multiply along node dimension.\"\"\"\n",
    "    def forward(self, x, A_sp):\n",
    "        # x: (B, C, N, T)\n",
    "        B, C, N, T = x.shape\n",
    "        x_r = x.permute(2, 0, 1, 3).reshape(N, -1).float()      # (N, B*C*T)\n",
    "        x_r = torch.sparse.mm(A_sp, x_r)                         # (N, B*C*T)\n",
    "        x_out = x_r.reshape(N, B, C, T).permute(1, 2, 0, 3)      # (B, C, N, T)\n",
    "        return x_out\n",
    "\n",
    "class ChebGraphConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Chebyshev graph conv using recurrence:\n",
    "      T0(X)=X\n",
    "      T1(X)=L~ X\n",
    "      Tk(X)=2 L~ T_{k-1}(X) - T_{k-2}(X)\n",
    "    Then 1x1 conv mixes the K stacks.\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_out, K, L_sp):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.L_sp = L_sp\n",
    "        self.nconv = NConv()\n",
    "        self.mlp = nn.Conv2d(c_in * K, c_out, kernel_size=(1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,C,N,T)\n",
    "        out = [x]\n",
    "        if self.K > 1:\n",
    "            x1 = self.nconv(x, self.L_sp)\n",
    "            out.append(x1)\n",
    "        for k in range(2, self.K):\n",
    "            x2 = 2.0 * self.nconv(out[-1], self.L_sp) - out[-2]\n",
    "            out.append(x2)\n",
    "\n",
    "        h = torch.cat(out, dim=1)  # (B, C*K, N, T)\n",
    "        return self.mlp(h)\n",
    "\n",
    "class TemporalGLU(nn.Module):\n",
    "    \"\"\"Temporal convolution + GLU gating. No padding -> time shrinks.\"\"\"\n",
    "    def __init__(self, c_in, c_out, kt):\n",
    "        super().__init__()\n",
    "        self.kt = kt\n",
    "        self.conv = nn.Conv2d(c_in, 2*c_out, kernel_size=(1, kt))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,C,N,T)\n",
    "        z = self.conv(x)                 # (B,2C,N,T-kt+1)\n",
    "        P, Q = torch.chunk(z, 2, dim=1)  # each (B,C,N,T')\n",
    "        return P * torch.sigmoid(Q)\n",
    "\n",
    "class STConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    STGCN block: TemporalGLU -> ChebGraphConv -> ReLU -> TemporalGLU\n",
    "    + residual (time-aligned) + LayerNorm over channels\n",
    "    \"\"\"\n",
    "    def __init__(self, c_in, c_t, c_s, c_out, kt, Ks, L_sp, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.temporal1 = TemporalGLU(c_in, c_t, kt)\n",
    "        self.graphconv = ChebGraphConv(c_t, c_s, Ks, L_sp)\n",
    "        self.temporal2 = TemporalGLU(c_s, c_out, kt)\n",
    "\n",
    "        self.res_conv = None\n",
    "        if c_in != c_out:\n",
    "            self.res_conv = nn.Conv2d(c_in, c_out, kernel_size=(1,1))\n",
    "\n",
    "        self.ln = nn.LayerNorm(c_out)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        self.kt = kt\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,C_in,N,T)\n",
    "        x_in = x\n",
    "        x = self.temporal1(x)            # (B,c_t,N,T1)\n",
    "        x = self.graphconv(x)            # (B,c_s,N,T1)\n",
    "        x = F.relu(x)\n",
    "        x = self.temporal2(x)            # (B,c_out,N,T2)\n",
    "\n",
    "        # residual: align last T2 timesteps\n",
    "        T2 = x.shape[-1]\n",
    "        res = x_in[..., -T2:]\n",
    "        if self.res_conv is not None:\n",
    "            res = self.res_conv(res)\n",
    "        x = x + res\n",
    "\n",
    "        x = self.drop(x)\n",
    "\n",
    "        # LayerNorm over channels (per node per time)\n",
    "        x = x.permute(0, 2, 3, 1)        # (B,N,T,C)\n",
    "        x = self.ln(x)\n",
    "        x = x.permute(0, 3, 1, 2)        # (B,C,N,T)\n",
    "        return x\n",
    "\n",
    "class STGCN_MultiHorizon(nn.Module):\n",
    "    \"\"\"\n",
    "    STGCN encoder + multi-horizon head.\n",
    "    Output is (B, OUT_LEN, N) in SCALED space (no unscale inside).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_nodes, in_dim, out_len, L_sp,\n",
    "                 kt=3, Ks=3, dropout=0.1,\n",
    "                 c_t=64, c_s=16, c_out=64, blocks=2):\n",
    "        super().__init__()\n",
    "        self.out_len = out_len\n",
    "\n",
    "        layers = []\n",
    "        c_in = in_dim\n",
    "        for _ in range(blocks):\n",
    "            layers.append(STConvBlock(c_in, c_t=c_t, c_s=c_s, c_out=c_out,\n",
    "                                      kt=kt, Ks=Ks, L_sp=L_sp, dropout=dropout))\n",
    "            c_in = c_out\n",
    "        self.blocks = nn.ModuleList(layers)\n",
    "\n",
    "        # After blocks, time is reduced by blocks * 2*(kt-1)\n",
    "        # We will infer the remaining time at runtime and build head lazily if needed.\n",
    "        self.head = None\n",
    "        self.c_out = c_out\n",
    "\n",
    "    def _build_head(self, T_rem):\n",
    "        # Collapse time dimension into 1, output channels = out_len\n",
    "        self.head = nn.Conv2d(self.c_out, self.out_len, kernel_size=(1, T_rem))\n",
    "\n",
    "    def forward(self, x, tf_future=None):\n",
    "        # x: (B,F,N,IN_LEN)\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        T_rem = x.shape[-1]\n",
    "        if self.head is None:\n",
    "            self._build_head(T_rem)\n",
    "            self.head = self.head.to(x.device)\n",
    "\n",
    "        y = self.head(x)       # (B,OUT_LEN,N,1)\n",
    "        y = y.squeeze(-1)      # (B,OUT_LEN,N)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19cb7d69-1f9c-4358-98da-88e75bccf54c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ART_DIR = Path(\"artifacts\")\n",
    "RUNS_DIR = ART_DIR / \"runs\"\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def make_run_dir(model_name: str) -> Path:\n",
    "    ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = RUNS_DIR / f\"{ts}_{model_name}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def save_json(path: Path, obj: dict):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def metrics_to_flat_row(model_name: str, split: str, metrics: dict) -> dict:\n",
    "    row = {\"model_name\": model_name, \"split\": split}\n",
    "    for h in EVAL_HORIZONS:\n",
    "        row[f\"{split}_MAE_{h}h\"] = metrics[h][\"MAE\"]\n",
    "        row[f\"{split}_RMSE_{h}h\"] = metrics[h][\"RMSE\"]\n",
    "    row[f\"{split}_avg_MAE\"] = avg_mae(metrics)\n",
    "    return row\n",
    "\n",
    "def append_results_summary(row: dict, out_csv: Path = ART_DIR/\"results_summary.csv\"):\n",
    "    df_new = pd.DataFrame([row])\n",
    "    if out_csv.exists():\n",
    "        df_old = pd.read_csv(out_csv)\n",
    "        df = pd.concat([df_old, df_new], ignore_index=True)\n",
    "    else:\n",
    "        df = df_new\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return out_csv\n",
    "\n",
    "@torch.inference_mode()\n",
    "def collect_predictions_selected_horizons(model, loader, horizons=(12,24,48,72)):\n",
    "    model.eval()\n",
    "    h_idx_local = torch.tensor([h-1 for h in horizons], device=DEVICE)\n",
    "    preds_all = []\n",
    "    trues_all = []\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Collect preds\", leave=False):\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "        tfb = tfb.to(DEVICE)\n",
    "        pred = model(xb, tfb)  # scaled\n",
    "\n",
    "        pred_u = pred * flow_std_t + flow_mean_t\n",
    "        true_u = yb   * flow_std_t + flow_mean_t\n",
    "\n",
    "        preds_all.append(pred_u[:, h_idx_local, :].detach().cpu().numpy())\n",
    "        trues_all.append(true_u[:, h_idx_local, :].detach().cpu().numpy())\n",
    "\n",
    "    preds_all = np.concatenate(preds_all, axis=0)  # (Btot, Hsel, N)\n",
    "    trues_all = np.concatenate(trues_all, axis=0)\n",
    "    return preds_all, trues_all, horizons\n",
    "\n",
    "def save_predictions_excel(run_dir: Path, preds, trues, horizons, stations, max_stations=300):\n",
    "    N_total = preds.shape[-1]\n",
    "    N_use = min(max_stations, N_total)\n",
    "    st_sel = stations[:N_use]\n",
    "\n",
    "    out_xlsx = run_dir / \"test_pred_true_selected_horizons.xlsx\"\n",
    "    with pd.ExcelWriter(out_xlsx, engine=\"openpyxl\") as writer:\n",
    "        for hi, h in enumerate(horizons):\n",
    "            df = pd.DataFrame({\n",
    "                \"station\": np.repeat(st_sel, preds.shape[0]),\n",
    "                \"sample\":  np.tile(np.arange(preds.shape[0]), N_use),\n",
    "                \"true\":    trues[:, hi, :N_use].T.reshape(-1),\n",
    "                \"pred\":    preds[:, hi, :N_use].T.reshape(-1),\n",
    "            })\n",
    "            df.to_excel(writer, sheet_name=f\"h{h}\", index=False)\n",
    "    return out_xlsx\n",
    "\n",
    "def train_and_save_best(\n",
    "    model, model_name: str, run_dir: Path,\n",
    "    epochs=40, lr=1e-3, weight_decay=1e-4, clip=5.0,\n",
    "    patience=6, eval_every=2\n",
    "):\n",
    "    model = model.to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    best_score = float(\"inf\")\n",
    "    best_state = None\n",
    "    bad = 0\n",
    "\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        run_loss = 0.0\n",
    "\n",
    "        for xb, yb, tfb in tqdm(train_loader, desc=f\"Train {epoch}/{epochs}\", leave=False):\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            tfb = tfb.to(DEVICE)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            pred = model(xb, tfb)               # scaled\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "\n",
    "            run_loss += float(loss.item())\n",
    "\n",
    "        row = {\"epoch\": epoch, \"train_loss\": run_loss / max(1, len(train_loader))}\n",
    "        history.append(row)\n",
    "\n",
    "        # Evaluate every eval_every epochs\n",
    "        if epoch % eval_every == 0:\n",
    "            val_m = eval_horizons_fast(model, val_loader)\n",
    "            score = avg_mae(val_m)\n",
    "\n",
    "            print(f\"\\nEpoch {epoch}: train_loss={row['train_loss']:.6f} val_avg_MAE={score:.3f}\")\n",
    "            print_metrics(\"VAL\", val_m)\n",
    "\n",
    "            row.update({f\"val_MAE_{h}h\": val_m[h][\"MAE\"] for h in EVAL_HORIZONS})\n",
    "            row.update({f\"val_RMSE_{h}h\": val_m[h][\"RMSE\"] for h in EVAL_HORIZONS})\n",
    "            row[\"val_avg_MAE\"] = score\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                bad = 0\n",
    "                torch.save(best_state, run_dir / \"best.pt\")\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= patience:\n",
    "                    print(f\"\\nEarly stopping. Best val_avg_MAE={best_score:.3f}\")\n",
    "                    break\n",
    "\n",
    "    # Save history\n",
    "    hist_df = pd.DataFrame(history)\n",
    "    hist_df.to_csv(run_dir / \"history.csv\", index=False)\n",
    "    print(\"Saved history:\", run_dir / \"history.csv\")\n",
    "\n",
    "    # Load best\n",
    "    assert best_state is not None, \"best_state is None (evaluation never ran?)\"\n",
    "    model.load_state_dict(best_state)\n",
    "    return model, hist_df\n",
    "\n",
    "def run_experiment_and_save(\n",
    "    model_name: str,\n",
    "    model: nn.Module,\n",
    "    epochs=40, patience=6, eval_every=2,\n",
    "    horizons_to_save=(12,24,48,72),\n",
    "    max_stations_excel=300\n",
    "):\n",
    "    run_dir = make_run_dir(model_name)\n",
    "    print(\"Run dir:\", run_dir)\n",
    "\n",
    "    # Train\n",
    "    model, history_df = train_and_save_best(\n",
    "        model=model,\n",
    "        model_name=model_name,\n",
    "        run_dir=run_dir,\n",
    "        epochs=epochs,\n",
    "        patience=patience,\n",
    "        eval_every=eval_every,\n",
    "    )\n",
    "\n",
    "    # Test metrics\n",
    "    print(\"\\nEvaluating on TEST set...\")\n",
    "    test_m = eval_horizons_fast(model, test_loader)\n",
    "    print_metrics(f\"{model_name} — TEST\", test_m)\n",
    "\n",
    "    # Save test metrics\n",
    "    save_json(run_dir / \"test_metrics.json\", test_m)\n",
    "    pd.DataFrame([metrics_to_flat_row(model_name, \"test\", test_m)]).to_csv(run_dir / \"test_metrics.csv\", index=False)\n",
    "\n",
    "    # Collect & save predictions\n",
    "    preds, trues, horizons = collect_predictions_selected_horizons(model, test_loader, horizons=horizons_to_save)\n",
    "    np.savez_compressed(run_dir / \"test_pred_true_selected_horizons.npz\",\n",
    "                        preds=preds, trues=trues, horizons=np.array(horizons))\n",
    "    out_xlsx = save_predictions_excel(run_dir, preds, trues, horizons, stations, max_stations=max_stations_excel)\n",
    "\n",
    "    # Update master summary CSV\n",
    "    summary_row = metrics_to_flat_row(model_name, \"test\", test_m)\n",
    "    out_summary = append_results_summary(summary_row)\n",
    "\n",
    "    print(\"\\nSaved run outputs to:\", run_dir)\n",
    "    print(\" - best checkpoint:\", run_dir / \"best.pt\")\n",
    "    print(\" - history:\", run_dir / \"history.csv\")\n",
    "    print(\" - test metrics:\", run_dir / \"test_metrics.json\")\n",
    "    print(\" - predictions (npz):\", run_dir / \"test_pred_true_selected_horizons.npz\")\n",
    "    print(\" - predictions (xlsx):\", out_xlsx)\n",
    "    print(\" - master summary:\", out_summary)\n",
    "\n",
    "    return run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28abba99-1355-4d64-89c3-afb50914dd9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch check: torch.Size([8, 6, 1821, 24]) torch.Size([8, 72, 1821]) torch.Size([8, 72, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE_ABL = 8  \n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE_ABL, shuffle=True, num_workers=0, pin_memory=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE_ABL, shuffle=False, num_workers=0, pin_memory=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE_ABL, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "print(\"Batch check:\", xb.shape, yb.shape, tfb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3639546b-232c-46ae-a0ce-8fff3fff4857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# Assumes you already have:\n",
    "# N, Fdim, OUT_LEN, L_sp, DEVICE\n",
    "# and STGCN_MultiHorizon class defined\n",
    "# ----------------------------\n",
    "\n",
    "def build_stgcn_backbone():\n",
    "    # EXACT same hyperparams as your STGCN baseline\n",
    "    return STGCN_MultiHorizon(\n",
    "        num_nodes=N,\n",
    "        in_dim=Fdim,\n",
    "        out_len=OUT_LEN,\n",
    "        L_sp=L_sp,\n",
    "        kt=3,\n",
    "        Ks=3,\n",
    "        dropout=0.1,\n",
    "        c_t=64, c_s=16, c_out=64,\n",
    "        blocks=2\n",
    "    )\n",
    "\n",
    "class HorizonRNNRefinement(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes baseline multi-horizon predictions y0: (B, T, N),\n",
    "    runs an RNN across horizon dimension T for each node independently,\n",
    "    and outputs y = y0 + delta (residual refinement).\n",
    "    \"\"\"\n",
    "    def __init__(self, out_len, mode=\"gru\", hidden=32, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.out_len = out_len\n",
    "        self.mode = mode\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        if mode == \"gru\":\n",
    "            self.rnn = nn.GRU(input_size=1, hidden_size=hidden, num_layers=1, batch_first=True)\n",
    "            self.proj = nn.Linear(hidden, 1)\n",
    "\n",
    "        elif mode == \"lstm\":\n",
    "            self.rnn = nn.LSTM(input_size=1, hidden_size=hidden, num_layers=1, batch_first=True)\n",
    "            self.proj = nn.Linear(hidden, 1)\n",
    "\n",
    "        elif mode == \"gru_lstm\":\n",
    "            self.gru  = nn.GRU(input_size=1, hidden_size=hidden, num_layers=1, batch_first=True)\n",
    "            self.lstm = nn.LSTM(input_size=hidden, hidden_size=hidden, num_layers=1, batch_first=True)\n",
    "            self.proj = nn.Linear(hidden, 1)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown mode={mode}\")\n",
    "\n",
    "    def forward(self, y0):\n",
    "        # y0: (B, T, N)\n",
    "        B, T, Nn = y0.shape\n",
    "        assert T == self.out_len\n",
    "\n",
    "        # reshape into (B*N, T, 1)\n",
    "        seq = y0.permute(0, 2, 1).contiguous().view(B * Nn, T, 1)\n",
    "\n",
    "        if self.mode in (\"gru\", \"lstm\"):\n",
    "            out, _ = self.rnn(seq)\n",
    "            out = self.drop(out)\n",
    "        else:\n",
    "            out, _ = self.gru(seq)\n",
    "            out = self.drop(out)\n",
    "            out, _ = self.lstm(out)\n",
    "            out = self.drop(out)\n",
    "\n",
    "        delta = self.proj(out)  # (B*N, T, 1)\n",
    "        delta = delta.view(B, Nn, T).permute(0, 2, 1).contiguous()  # (B, T, N)\n",
    "\n",
    "        return y0 + delta\n",
    "\n",
    "class STGCN_WithHorizonRNN(nn.Module):\n",
    "    def __init__(self, backbone, rnn_mode=\"gru\", rnn_hidden=32, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.head = HorizonRNNRefinement(\n",
    "            out_len=OUT_LEN,\n",
    "            mode=rnn_mode,\n",
    "            hidden=rnn_hidden,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, x, tf):\n",
    "        y0 = self.backbone(x, tf)      # (B, OUT_LEN, N)\n",
    "        y  = self.head(y0)             # refined (B, OUT_LEN, N)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74e1a568-85ba-4b7a-ac8b-5ae79540c027",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU out: torch.Size([8, 72, 1821]) 0.02864772267639637 0.5788347721099854\n",
      "LSTM out: torch.Size([8, 72, 1821]) 0.12592457234859467 0.6218409538269043\n",
      "GRU+LSTM out: torch.Size([8, 72, 1821]) 0.08967868238687515 0.5888320207595825\n"
     ]
    }
   ],
   "source": [
    "RNN_H = 64   \n",
    "\n",
    "# STGCN + GRU\n",
    "stgcn_gru = STGCN_WithHorizonRNN(\n",
    "    backbone=build_stgcn_backbone(),\n",
    "    rnn_mode=\"gru\",\n",
    "    rnn_hidden=RNN_H,\n",
    "    dropout=0.1\n",
    ").to(DEVICE)\n",
    "\n",
    "# STGCN + LSTM\n",
    "stgcn_lstm = STGCN_WithHorizonRNN(\n",
    "    backbone=build_stgcn_backbone(),\n",
    "    rnn_mode=\"lstm\",\n",
    "    rnn_hidden=RNN_H,\n",
    "    dropout=0.1\n",
    ").to(DEVICE)\n",
    "\n",
    "# STGCN + GRU + LSTM\n",
    "stgcn_gru_lstm = STGCN_WithHorizonRNN(\n",
    "    backbone=build_stgcn_backbone(),\n",
    "    rnn_mode=\"gru_lstm\",\n",
    "    rnn_hidden=RNN_H,\n",
    "    dropout=0.1\n",
    ").to(DEVICE)\n",
    "\n",
    "# Sanity forward on one batch\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "with torch.no_grad():\n",
    "    o1 = stgcn_gru(xb.to(DEVICE), tfb.to(DEVICE))\n",
    "    o2 = stgcn_lstm(xb.to(DEVICE), tfb.to(DEVICE))\n",
    "    o3 = stgcn_gru_lstm(xb.to(DEVICE), tfb.to(DEVICE))\n",
    "\n",
    "print(\"GRU out:\", o1.shape, float(o1.mean()), float(o1.std()))\n",
    "print(\"LSTM out:\", o2.shape, float(o2.mean()), float(o2.std()))\n",
    "print(\"GRU+LSTM out:\", o3.shape, float(o3.mean()), float(o3.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "441d6911-3ffa-4e4c-a1c7-5638cfe1679a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run dir: artifacts/runs/20260210_205540_STGCN_GRU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 2/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.233463 val_avg_MAE=162.356\n",
      "\n",
      "VAL\n",
      "   12h  MAE=132.676  RMSE=274.626\n",
      "   24h  MAE=145.894  RMSE=296.259\n",
      "   48h  MAE=169.784  RMSE=326.262\n",
      "   72h  MAE=201.069  RMSE=372.833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 3/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 4/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=0.192946 val_avg_MAE=157.003\n",
      "\n",
      "VAL\n",
      "   12h  MAE=130.237  RMSE=264.035\n",
      "   24h  MAE=141.342  RMSE=288.684\n",
      "   48h  MAE=169.147  RMSE=331.933\n",
      "   72h  MAE=187.287  RMSE=358.725\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 5/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 6/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: train_loss=0.181731 val_avg_MAE=145.411\n",
      "\n",
      "VAL\n",
      "   12h  MAE=123.244  RMSE=256.278\n",
      "   24h  MAE=130.935  RMSE=274.027\n",
      "   48h  MAE=161.921  RMSE=320.886\n",
      "   72h  MAE=165.542  RMSE=327.881\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 7/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 8/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: train_loss=0.176248 val_avg_MAE=155.406\n",
      "\n",
      "VAL\n",
      "   12h  MAE=122.552  RMSE=253.167\n",
      "   24h  MAE=145.858  RMSE=298.626\n",
      "   48h  MAE=168.445  RMSE=332.267\n",
      "   72h  MAE=184.768  RMSE=365.919\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 9/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 10/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: train_loss=0.172655 val_avg_MAE=147.587\n",
      "\n",
      "VAL\n",
      "   12h  MAE=121.398  RMSE=254.440\n",
      "   24h  MAE=135.759  RMSE=283.503\n",
      "   48h  MAE=156.392  RMSE=313.810\n",
      "   72h  MAE=176.799  RMSE=349.246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 11/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 12/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: train_loss=0.170455 val_avg_MAE=142.511\n",
      "\n",
      "VAL\n",
      "   12h  MAE=118.069  RMSE=246.943\n",
      "   24h  MAE=125.894  RMSE=267.419\n",
      "   48h  MAE=155.732  RMSE=312.486\n",
      "   72h  MAE=170.348  RMSE=336.480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 13/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 14/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: train_loss=0.167309 val_avg_MAE=138.601\n",
      "\n",
      "VAL\n",
      "   12h  MAE=115.004  RMSE=243.286\n",
      "   24h  MAE=126.489  RMSE=268.424\n",
      "   48h  MAE=151.298  RMSE=303.059\n",
      "   72h  MAE=161.613  RMSE=319.477\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 15/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 16/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: train_loss=0.165813 val_avg_MAE=140.444\n",
      "\n",
      "VAL\n",
      "   12h  MAE=112.601  RMSE=240.774\n",
      "   24h  MAE=130.684  RMSE=273.027\n",
      "   48h  MAE=155.929  RMSE=313.941\n",
      "   72h  MAE=162.563  RMSE=324.785\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 17/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 18/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: train_loss=0.164232 val_avg_MAE=142.060\n",
      "\n",
      "VAL\n",
      "   12h  MAE=110.060  RMSE=237.707\n",
      "   24h  MAE=126.093  RMSE=268.763\n",
      "   48h  MAE=159.701  RMSE=318.785\n",
      "   72h  MAE=172.388  RMSE=338.958\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 19/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 20/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: train_loss=0.162565 val_avg_MAE=146.843\n",
      "\n",
      "VAL\n",
      "   12h  MAE=119.711  RMSE=246.898\n",
      "   24h  MAE=134.406  RMSE=273.631\n",
      "   48h  MAE=155.861  RMSE=311.123\n",
      "   72h  MAE=177.395  RMSE=350.573\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 21/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 22/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: train_loss=0.161220 val_avg_MAE=145.467\n",
      "\n",
      "VAL\n",
      "   12h  MAE=120.149  RMSE=247.475\n",
      "   24h  MAE=132.424  RMSE=277.767\n",
      "   48h  MAE=158.536  RMSE=322.430\n",
      "   72h  MAE=170.758  RMSE=341.814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52d0380f3d94dc3bff25b16761594f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 23/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 36/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: train_loss=0.157849 val_avg_MAE=141.897\n",
      "\n",
      "VAL\n",
      "   12h  MAE=107.517  RMSE=232.973\n",
      "   24h  MAE=133.671  RMSE=278.473\n",
      "   48h  MAE=154.960  RMSE=311.373\n",
      "   72h  MAE=171.438  RMSE=344.917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05cdf41fb8244bfb968e36a4e96553e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 37/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d66704977644d2aea18577cee6128a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 38/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4092ed7917c14358b663a92a8ba7a139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: train_loss=0.158196 val_avg_MAE=140.529\n",
      "\n",
      "VAL\n",
      "   12h  MAE=114.924  RMSE=242.604\n",
      "   24h  MAE=127.911  RMSE=269.247\n",
      "   48h  MAE=153.328  RMSE=312.856\n",
      "   72h  MAE=165.951  RMSE=333.921\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbe9ff5ecc54b61b35218b5888c4d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 39/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c585a252fb1b453b9874f4bc6857da02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 40/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd90c89278f47d4a3a7aa6a4b6f3ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40: train_loss=0.157007 val_avg_MAE=140.659\n",
      "\n",
      "VAL\n",
      "   12h  MAE=114.564  RMSE=244.315\n",
      "   24h  MAE=127.082  RMSE=267.980\n",
      "   48h  MAE=152.742  RMSE=307.844\n",
      "   72h  MAE=168.250  RMSE=335.281\n",
      "Saved history: artifacts/runs/20260210_205540_STGCN_GRU/history.csv\n",
      "\n",
      "Evaluating on TEST set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2815021249742dd961734c93393ca49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STGCN_GRU — TEST\n",
      "   12h  MAE=114.700  RMSE=237.349\n",
      "   24h  MAE=121.738  RMSE=246.057\n",
      "   48h  MAE=139.977  RMSE=288.806\n",
      "   72h  MAE=154.095  RMSE=311.351\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfb20e517044fa5930621cbeaafd4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collect preds:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved run outputs to: artifacts/runs/20260210_205540_STGCN_GRU\n",
      " - best checkpoint: artifacts/runs/20260210_205540_STGCN_GRU/best.pt\n",
      " - history: artifacts/runs/20260210_205540_STGCN_GRU/history.csv\n",
      " - test metrics: artifacts/runs/20260210_205540_STGCN_GRU/test_metrics.json\n",
      " - predictions (npz): artifacts/runs/20260210_205540_STGCN_GRU/test_pred_true_selected_horizons.npz\n",
      " - predictions (xlsx): artifacts/runs/20260210_205540_STGCN_GRU/test_pred_true_selected_horizons.xlsx\n",
      " - master summary: artifacts/results_summary.csv\n",
      "Run dir: artifacts/runs/20260210_213135_STGCN_LSTM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62845c9c107e43f2a732a6c8d39d3e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc14dddd8a74c0988f0decb50f682c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 2/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3f899ec34d40fa948bc4c78753775b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.235438 val_avg_MAE=168.156\n",
      "\n",
      "VAL\n",
      "   12h  MAE=136.834  RMSE=282.608\n",
      "   24h  MAE=156.041  RMSE=312.736\n",
      "   48h  MAE=186.112  RMSE=347.875\n",
      "   72h  MAE=193.638  RMSE=366.169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4188f64ec2450d8f90490fbaf00b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 3/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8d4b1060b34f9db59a1dc9f7f75cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 4/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815fd509dfc34ab294be0af1eaff4271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=0.191357 val_avg_MAE=156.985\n",
      "\n",
      "VAL\n",
      "   12h  MAE=133.067  RMSE=262.449\n",
      "   24h  MAE=140.911  RMSE=283.656\n",
      "   48h  MAE=170.360  RMSE=325.826\n",
      "   72h  MAE=183.601  RMSE=351.599\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552e991c603649e98f2595351353a1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 5/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e518d95303d54c2e986a1d257233e1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 6/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc23e494d6da4675a5535b1d5ccc1ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: train_loss=0.179752 val_avg_MAE=146.464\n",
      "\n",
      "VAL\n",
      "   12h  MAE=121.773  RMSE=254.973\n",
      "   24h  MAE=130.611  RMSE=275.136\n",
      "   48h  MAE=163.391  RMSE=324.446\n",
      "   72h  MAE=170.083  RMSE=333.749\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdac795917642a7bfb092e573fe97d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 7/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688cb9af21c84cce82f88509ee2c4aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 8/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1b0d934da34a5b899ec5d210a7e9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: train_loss=0.174459 val_avg_MAE=152.235\n",
      "\n",
      "VAL\n",
      "   12h  MAE=122.576  RMSE=254.195\n",
      "   24h  MAE=145.103  RMSE=294.936\n",
      "   48h  MAE=166.064  RMSE=327.203\n",
      "   72h  MAE=175.195  RMSE=343.373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8205103cda4fee9d5099bc8ebeb9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 9/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5edebdbc6441e08bca6824d899224a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 10/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea132d38ac34f7bb5fb0c12d30f5e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: train_loss=0.171299 val_avg_MAE=147.710\n",
      "\n",
      "VAL\n",
      "   12h  MAE=120.365  RMSE=248.124\n",
      "   24h  MAE=138.321  RMSE=285.497\n",
      "   48h  MAE=158.271  RMSE=316.608\n",
      "   72h  MAE=173.882  RMSE=344.818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d778fe39e4c940bb94bcbf262d8e913f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 11/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153cda83c2cc4b9bbd2d361d5958ccda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 12/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ebdc276a2c4cc8a754861a74f97db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: train_loss=0.169861 val_avg_MAE=142.583\n",
      "\n",
      "VAL\n",
      "   12h  MAE=119.498  RMSE=248.133\n",
      "   24h  MAE=126.954  RMSE=268.936\n",
      "   48h  MAE=152.218  RMSE=305.648\n",
      "   72h  MAE=171.664  RMSE=340.248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3117a7c9a2e644e9a85da04b39a75112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 13/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2de84b58ea942e3976b6f6ebd8ff3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 14/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6103df3338cc4eadb3678177a88fceb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: train_loss=0.166665 val_avg_MAE=137.085\n",
      "\n",
      "VAL\n",
      "   12h  MAE=116.327  RMSE=246.383\n",
      "   24h  MAE=126.377  RMSE=269.919\n",
      "   48h  MAE=147.226  RMSE=295.715\n",
      "   72h  MAE=158.411  RMSE=314.506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ceb0c37a077472e93145a1c977e56be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 15/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb3f2cc77f243b19c33b7b0ec35dd03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 16/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394c1b62a88e4791a480731ebde943fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: train_loss=0.165718 val_avg_MAE=140.395\n",
      "\n",
      "VAL\n",
      "   12h  MAE=116.427  RMSE=244.096\n",
      "   24h  MAE=131.026  RMSE=273.229\n",
      "   48h  MAE=153.786  RMSE=311.070\n",
      "   72h  MAE=160.340  RMSE=325.649\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe480e8412f41f5b0c4296c57572bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 17/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6236bd2a9f7541d1bbe216daf50876ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 18/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba7dea195d040358c0d4a6efc451170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: train_loss=0.163657 val_avg_MAE=146.375\n",
      "\n",
      "VAL\n",
      "   12h  MAE=115.364  RMSE=248.303\n",
      "   24h  MAE=131.535  RMSE=278.240\n",
      "   48h  MAE=164.478  RMSE=329.032\n",
      "   72h  MAE=174.122  RMSE=343.663\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edce953bdeb943ec8ef5e327547c54f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 19/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85a872c72984a638a0a96caf6fce065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 20/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17414ca776f84016af02f39798392468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: train_loss=0.162586 val_avg_MAE=144.401\n",
      "\n",
      "VAL\n",
      "   12h  MAE=119.664  RMSE=244.301\n",
      "   24h  MAE=130.797  RMSE=268.998\n",
      "   48h  MAE=154.198  RMSE=306.704\n",
      "   72h  MAE=172.945  RMSE=342.690\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f4a4aca0064bfdbe0dbe0d94e90303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 21/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5ebd82e7034f8d8b371bac88815ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 22/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea220cfba39e4250805ea5173bb3d03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: train_loss=0.160441 val_avg_MAE=145.354\n",
      "\n",
      "VAL\n",
      "   12h  MAE=122.735  RMSE=252.082\n",
      "   24h  MAE=131.826  RMSE=276.570\n",
      "   48h  MAE=156.517  RMSE=318.339\n",
      "   72h  MAE=170.337  RMSE=342.086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a3392f07964383a7a9b3e4cc9e64ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 23/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd36352776564d3fb21cf861ee055be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 24/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83fc8737d664660b6c4eb71a0629df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: train_loss=0.159786 val_avg_MAE=140.623\n",
      "\n",
      "VAL\n",
      "   12h  MAE=111.748  RMSE=233.924\n",
      "   24h  MAE=133.183  RMSE=273.733\n",
      "   48h  MAE=155.823  RMSE=311.206\n",
      "   72h  MAE=161.738  RMSE=323.364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342e8652e99c46a2bedff08aa92d97ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 25/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d292b70622149f59da3535e3ff29910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 26/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f51de246054c8d98315f7c0edee52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: train_loss=0.159669 val_avg_MAE=137.312\n",
      "\n",
      "VAL\n",
      "   12h  MAE=114.973  RMSE=243.987\n",
      "   24h  MAE=122.287  RMSE=260.352\n",
      "   48h  MAE=148.387  RMSE=301.416\n",
      "   72h  MAE=163.603  RMSE=328.830\n",
      "\n",
      "Early stopping. Best val_avg_MAE=137.085\n",
      "Saved history: artifacts/runs/20260210_213135_STGCN_LSTM/history.csv\n",
      "\n",
      "Evaluating on TEST set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5967e19e60024e76b17ea865e2c0d828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STGCN_LSTM — TEST\n",
      "   12h  MAE=119.302  RMSE=241.473\n",
      "   24h  MAE=124.602  RMSE=255.679\n",
      "   48h  MAE=139.211  RMSE=284.156\n",
      "   72h  MAE=152.125  RMSE=302.663\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cb1612145e4867b43e745889b20de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collect preds:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved run outputs to: artifacts/runs/20260210_213135_STGCN_LSTM\n",
      " - best checkpoint: artifacts/runs/20260210_213135_STGCN_LSTM/best.pt\n",
      " - history: artifacts/runs/20260210_213135_STGCN_LSTM/history.csv\n",
      " - test metrics: artifacts/runs/20260210_213135_STGCN_LSTM/test_metrics.json\n",
      " - predictions (npz): artifacts/runs/20260210_213135_STGCN_LSTM/test_pred_true_selected_horizons.npz\n",
      " - predictions (xlsx): artifacts/runs/20260210_213135_STGCN_LSTM/test_pred_true_selected_horizons.xlsx\n",
      " - master summary: artifacts/results_summary.csv\n",
      "Run dir: artifacts/runs/20260210_215633_STGCN_GRU_LSTM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9c64dc216547d7b77a3a85cf3dccaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8bc8ef717d4b89b86b1709c22f63a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 2/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227f287e67c6412fb6cccb6a759eb08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.237603 val_avg_MAE=162.906\n",
      "\n",
      "VAL\n",
      "   12h  MAE=144.636  RMSE=282.637\n",
      "   24h  MAE=149.053  RMSE=303.920\n",
      "   48h  MAE=172.479  RMSE=331.723\n",
      "   72h  MAE=185.455  RMSE=355.479\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c43e60832b4e2fbdfae9c5f5c067bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 3/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0839a720b67b4ec1bfbe9a00ea200741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 4/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eea86efecb24beeb7d374c5a424f522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=0.193425 val_avg_MAE=154.668\n",
      "\n",
      "VAL\n",
      "   12h  MAE=132.365  RMSE=270.265\n",
      "   24h  MAE=136.452  RMSE=283.101\n",
      "   48h  MAE=163.750  RMSE=323.023\n",
      "   72h  MAE=186.106  RMSE=360.543\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba7b0d5de4f45b8b80621980b8a101f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 5/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9a83f03d4042d59662ac0156cd013f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 6/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3cf663c01d248b99be576e26403348b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: train_loss=0.183178 val_avg_MAE=148.843\n",
      "\n",
      "VAL\n",
      "   12h  MAE=127.880  RMSE=260.625\n",
      "   24h  MAE=133.700  RMSE=280.580\n",
      "   48h  MAE=163.274  RMSE=327.813\n",
      "   72h  MAE=170.518  RMSE=335.863\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5aca70f2e3240f8953728dd180de799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 7/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd366ed1c7c4d91b1845f362804e130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 8/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbbbe7758804dda8e10fb00699d8bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: train_loss=0.177234 val_avg_MAE=154.520\n",
      "\n",
      "VAL\n",
      "   12h  MAE=127.858  RMSE=255.679\n",
      "   24h  MAE=148.648  RMSE=303.584\n",
      "   48h  MAE=166.251  RMSE=327.664\n",
      "   72h  MAE=175.323  RMSE=347.749\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52f932b0b7f48af8651f31fefba3ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 9/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623de95bfa07478da4058419bb3c7200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 10/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79e2aff1b444c9191716d82ec864042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: train_loss=0.173290 val_avg_MAE=146.593\n",
      "\n",
      "VAL\n",
      "   12h  MAE=122.953  RMSE=256.028\n",
      "   24h  MAE=139.710  RMSE=291.586\n",
      "   48h  MAE=154.361  RMSE=310.631\n",
      "   72h  MAE=169.346  RMSE=334.173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0c5f2c7f74402da9e57615666a9f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 11/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56157351913498aa2a05f720d73fcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 12/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ac6cd44da74ec998c7226ebc605f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: train_loss=0.171537 val_avg_MAE=143.401\n",
      "\n",
      "VAL\n",
      "   12h  MAE=118.147  RMSE=242.184\n",
      "   24h  MAE=125.730  RMSE=268.846\n",
      "   48h  MAE=159.139  RMSE=319.977\n",
      "   72h  MAE=170.588  RMSE=339.899\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e93191ac21b4e1f9feff337cd2cb0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 13/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae9e5ad02354a81ae7a3c65010ad8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 14/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6214cd708a491aabfa374a203093c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: train_loss=0.169009 val_avg_MAE=138.996\n",
      "\n",
      "VAL\n",
      "   12h  MAE=116.082  RMSE=241.626\n",
      "   24h  MAE=124.626  RMSE=263.935\n",
      "   48h  MAE=151.468  RMSE=301.849\n",
      "   72h  MAE=163.809  RMSE=321.111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd23800cdcd344be9c45324173ce7430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 15/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b970ce2306f64fcdbcc9c1a032767c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 16/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8450ca17cbb9453b826035a1805707a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: train_loss=0.168379 val_avg_MAE=142.159\n",
      "\n",
      "VAL\n",
      "   12h  MAE=117.564  RMSE=250.414\n",
      "   24h  MAE=132.743  RMSE=278.390\n",
      "   48h  MAE=155.823  RMSE=316.785\n",
      "   72h  MAE=162.506  RMSE=326.917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ea6766e11f4a74977e9de1b99b145f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 17/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59d36dcb86d4530a65233bf50d76b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 18/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328ee36c4acc4cd5b2a1fd682f25493c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: train_loss=0.165653 val_avg_MAE=143.009\n",
      "\n",
      "VAL\n",
      "   12h  MAE=114.471  RMSE=242.480\n",
      "   24h  MAE=125.567  RMSE=266.700\n",
      "   48h  MAE=161.444  RMSE=322.430\n",
      "   72h  MAE=170.555  RMSE=336.321\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23efc37065bb4fd7846561822c4038bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 19/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a511198f63f4e239f4d80098656d766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 20/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff26aa9a1c94ab3bfa7bf989aa6b443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: train_loss=0.165318 val_avg_MAE=148.338\n",
      "\n",
      "VAL\n",
      "   12h  MAE=123.690  RMSE=252.784\n",
      "   24h  MAE=137.117  RMSE=279.523\n",
      "   48h  MAE=157.508  RMSE=316.159\n",
      "   72h  MAE=175.038  RMSE=350.283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2dc16f6b036405ab2803e3766143f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 21/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69f1b615d2049f1b5ec3c138a4a3970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 22/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d59b659b4745a4803809ef3f82622a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: train_loss=0.162441 val_avg_MAE=145.536\n",
      "\n",
      "VAL\n",
      "   12h  MAE=125.369  RMSE=255.188\n",
      "   24h  MAE=130.941  RMSE=275.790\n",
      "   48h  MAE=156.627  RMSE=318.608\n",
      "   72h  MAE=169.206  RMSE=338.761\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3085c7fe3640568ec6233a62362c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 23/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b32acd04d6f49afb9604ab8f86fd978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 24/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd93bd4e02714ca89139e99ee9152526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: train_loss=0.161498 val_avg_MAE=140.612\n",
      "\n",
      "VAL\n",
      "   12h  MAE=113.087  RMSE=239.323\n",
      "   24h  MAE=130.494  RMSE=272.679\n",
      "   48h  MAE=155.995  RMSE=314.110\n",
      "   72h  MAE=162.871  RMSE=324.030\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78eb8f7758241d2a63ed9a084070cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 25/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f139c71de6342a4b23714824cf836c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 26/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf6bb566cec4fb88b7a9414219429af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: train_loss=0.161323 val_avg_MAE=142.125\n",
      "\n",
      "VAL\n",
      "   12h  MAE=118.401  RMSE=250.192\n",
      "   24h  MAE=123.616  RMSE=260.885\n",
      "   48h  MAE=155.419  RMSE=310.612\n",
      "   72h  MAE=171.063  RMSE=338.146\n",
      "\n",
      "Early stopping. Best val_avg_MAE=138.996\n",
      "Saved history: artifacts/runs/20260210_215633_STGCN_GRU_LSTM/history.csv\n",
      "\n",
      "Evaluating on TEST set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3ca115d6ac4320b199bb1c209404c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STGCN_GRU_LSTM — TEST\n",
      "   12h  MAE=119.174  RMSE=240.949\n",
      "   24h  MAE=122.301  RMSE=249.547\n",
      "   48h  MAE=141.759  RMSE=288.465\n",
      "   72h  MAE=154.342  RMSE=308.134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3342ffd3fc4056a549b72a8f31421f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collect preds:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved run outputs to: artifacts/runs/20260210_215633_STGCN_GRU_LSTM\n",
      " - best checkpoint: artifacts/runs/20260210_215633_STGCN_GRU_LSTM/best.pt\n",
      " - history: artifacts/runs/20260210_215633_STGCN_GRU_LSTM/history.csv\n",
      " - test metrics: artifacts/runs/20260210_215633_STGCN_GRU_LSTM/test_metrics.json\n",
      " - predictions (npz): artifacts/runs/20260210_215633_STGCN_GRU_LSTM/test_pred_true_selected_horizons.npz\n",
      " - predictions (xlsx): artifacts/runs/20260210_215633_STGCN_GRU_LSTM/test_pred_true_selected_horizons.xlsx\n",
      " - master summary: artifacts/results_summary.csv\n",
      "Done.\n",
      "GRU run dir: artifacts/runs/20260210_205540_STGCN_GRU\n",
      "LSTM run dir: artifacts/runs/20260210_213135_STGCN_LSTM\n",
      "GRU_LSTM run dir: artifacts/runs/20260210_215633_STGCN_GRU_LSTM\n"
     ]
    }
   ],
   "source": [
    "#  make station subset selection reproducible \n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "run_dir_gru = run_experiment_and_save(\n",
    "    model_name=\"STGCN_GRU\",\n",
    "    model=stgcn_gru,\n",
    "    epochs=40,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    "    horizons_to_save=(12,24,48,72),\n",
    "    max_stations_excel=300\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "run_dir_lstm = run_experiment_and_save(\n",
    "    model_name=\"STGCN_LSTM\",\n",
    "    model=stgcn_lstm,\n",
    "    epochs=40,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    "    horizons_to_save=(12,24,48,72),\n",
    "    max_stations_excel=300\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "run_dir_gru_lstm = run_experiment_and_save(\n",
    "    model_name=\"STGCN_GRU_LSTM\",\n",
    "    model=stgcn_gru_lstm,\n",
    "    epochs=40,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    "    horizons_to_save=(12,24,48,72),\n",
    "    max_stations_excel=300\n",
    ")\n",
    "\n",
    "print(\"Done.\")\n",
    "print(\"GRU run dir:\", run_dir_gru)\n",
    "print(\"LSTM run dir:\", run_dir_lstm)\n",
    "print(\"GRU_LSTM run dir:\", run_dir_gru_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61054206-ca75-487a-83ad-4bab23a07d03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported CSVs to: artifacts/runs/20260210_205540_STGCN_GRU\n",
      "Exported CSVs to: artifacts/runs/20260210_213135_STGCN_LSTM\n",
      "Exported CSVs to: artifacts/runs/20260210_215633_STGCN_GRU_LSTM\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def xlsx_to_csvs(run_dir):\n",
    "    run_dir = Path(run_dir)\n",
    "    xlsx_path = run_dir / \"test_pred_true_selected_horizons.xlsx\"\n",
    "    if not xlsx_path.exists():\n",
    "        print(\"No xlsx found:\", xlsx_path)\n",
    "        return\n",
    "\n",
    "    xls = pd.ExcelFile(xlsx_path)\n",
    "    for sheet in xls.sheet_names:\n",
    "        df = pd.read_excel(xlsx_path, sheet_name=sheet)\n",
    "        out = run_dir / f\"{sheet}.csv\"\n",
    "        df.to_csv(out, index=False)\n",
    "    print(\"Exported CSVs to:\", run_dir)\n",
    "\n",
    "\n",
    "xlsx_to_csvs(run_dir_gru)\n",
    "xlsx_to_csvs(run_dir_lstm)\n",
    "xlsx_to_csvs(run_dir_gru_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b18d31ec-fdea-4e77-836d-19ee0c415bea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>avg_MAE</th>\n",
       "      <th>test_MAE_12h</th>\n",
       "      <th>test_MAE_24h</th>\n",
       "      <th>test_MAE_48h</th>\n",
       "      <th>test_MAE_72h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>119.585777</td>\n",
       "      <td>114.454689</td>\n",
       "      <td>115.199486</td>\n",
       "      <td>123.086647</td>\n",
       "      <td>125.602287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GraphWaveNet_GRU_LSTM</td>\n",
       "      <td>130.347263</td>\n",
       "      <td>119.049412</td>\n",
       "      <td>125.123518</td>\n",
       "      <td>135.325328</td>\n",
       "      <td>141.890796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GraphWaveNet_LSTM</td>\n",
       "      <td>131.859503</td>\n",
       "      <td>123.367641</td>\n",
       "      <td>125.953695</td>\n",
       "      <td>135.830582</td>\n",
       "      <td>142.286094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>STGCN</td>\n",
       "      <td>132.266313</td>\n",
       "      <td>119.125651</td>\n",
       "      <td>121.787452</td>\n",
       "      <td>139.610473</td>\n",
       "      <td>148.541676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>STGCN_GRU</td>\n",
       "      <td>132.610577</td>\n",
       "      <td>114.689314</td>\n",
       "      <td>121.745046</td>\n",
       "      <td>139.941089</td>\n",
       "      <td>154.066858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>STGCN_GRU</td>\n",
       "      <td>132.627357</td>\n",
       "      <td>114.699978</td>\n",
       "      <td>121.737924</td>\n",
       "      <td>139.976878</td>\n",
       "      <td>154.094648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>STGCN</td>\n",
       "      <td>132.881293</td>\n",
       "      <td>124.865714</td>\n",
       "      <td>121.199576</td>\n",
       "      <td>136.894008</td>\n",
       "      <td>148.565873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>STGCN</td>\n",
       "      <td>132.881293</td>\n",
       "      <td>124.865714</td>\n",
       "      <td>121.199576</td>\n",
       "      <td>136.894008</td>\n",
       "      <td>148.565873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GraphWaveNet_GRU</td>\n",
       "      <td>133.121911</td>\n",
       "      <td>122.688777</td>\n",
       "      <td>127.520536</td>\n",
       "      <td>138.531665</td>\n",
       "      <td>143.746668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>STGCN_LSTM</td>\n",
       "      <td>133.809814</td>\n",
       "      <td>119.301886</td>\n",
       "      <td>124.601723</td>\n",
       "      <td>139.211051</td>\n",
       "      <td>152.124597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>STGCN_LSTM</td>\n",
       "      <td>133.812095</td>\n",
       "      <td>119.279658</td>\n",
       "      <td>124.610721</td>\n",
       "      <td>139.245704</td>\n",
       "      <td>152.112297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>STGCN_GRU_LSTM</td>\n",
       "      <td>134.393986</td>\n",
       "      <td>119.173538</td>\n",
       "      <td>122.300857</td>\n",
       "      <td>141.759212</td>\n",
       "      <td>154.342336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>STGCN_GRU_LSTM</td>\n",
       "      <td>135.100299</td>\n",
       "      <td>118.894072</td>\n",
       "      <td>123.719928</td>\n",
       "      <td>142.578867</td>\n",
       "      <td>155.208328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>147.571213</td>\n",
       "      <td>151.053421</td>\n",
       "      <td>148.707306</td>\n",
       "      <td>149.398804</td>\n",
       "      <td>141.125320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>214.265528</td>\n",
       "      <td>217.363009</td>\n",
       "      <td>212.865069</td>\n",
       "      <td>214.150324</td>\n",
       "      <td>212.683710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STGCN</td>\n",
       "      <td>4925.363840</td>\n",
       "      <td>4932.437692</td>\n",
       "      <td>4919.577328</td>\n",
       "      <td>4923.404710</td>\n",
       "      <td>4926.035632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STGCN</td>\n",
       "      <td>8772.041396</td>\n",
       "      <td>8775.111610</td>\n",
       "      <td>8771.100333</td>\n",
       "      <td>8771.417389</td>\n",
       "      <td>8770.536252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_name      avg_MAE  test_MAE_12h  test_MAE_24h  \\\n",
       "13           RandomForest   119.585777    114.454689    115.199486   \n",
       "2   GraphWaveNet_GRU_LSTM   130.347263    119.049412    125.123518   \n",
       "1       GraphWaveNet_LSTM   131.859503    123.367641    125.953695   \n",
       "5                   STGCN   132.266313    119.125651    121.787452   \n",
       "8               STGCN_GRU   132.610577    114.689314    121.745046   \n",
       "14              STGCN_GRU   132.627357    114.699978    121.737924   \n",
       "6                   STGCN   132.881293    124.865714    121.199576   \n",
       "7                   STGCN   132.881293    124.865714    121.199576   \n",
       "0        GraphWaveNet_GRU   133.121911    122.688777    127.520536   \n",
       "15             STGCN_LSTM   133.809814    119.301886    124.601723   \n",
       "9              STGCN_LSTM   133.812095    119.279658    124.610721   \n",
       "16         STGCN_GRU_LSTM   134.393986    119.173538    122.300857   \n",
       "10         STGCN_GRU_LSTM   135.100299    118.894072    123.719928   \n",
       "12             ElasticNet   147.571213    151.053421    148.707306   \n",
       "11                   LSTM   214.265528    217.363009    212.865069   \n",
       "4                   STGCN  4925.363840   4932.437692   4919.577328   \n",
       "3                   STGCN  8772.041396   8775.111610   8771.100333   \n",
       "\n",
       "    test_MAE_48h  test_MAE_72h  \n",
       "13    123.086647    125.602287  \n",
       "2     135.325328    141.890796  \n",
       "1     135.830582    142.286094  \n",
       "5     139.610473    148.541676  \n",
       "8     139.941089    154.066858  \n",
       "14    139.976878    154.094648  \n",
       "6     136.894008    148.565873  \n",
       "7     136.894008    148.565873  \n",
       "0     138.531665    143.746668  \n",
       "15    139.211051    152.124597  \n",
       "9     139.245704    152.112297  \n",
       "16    141.759212    154.342336  \n",
       "10    142.578867    155.208328  \n",
       "12    149.398804    141.125320  \n",
       "11    214.150324    212.683710  \n",
       "4    4923.404710   4926.035632  \n",
       "3    8771.417389   8770.536252  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"artifacts/results_summary.csv\")\n",
    "\n",
    "horizons = [12, 24, 48, 72]\n",
    "for h in horizons:\n",
    "    df[f\"test_MAE_{h}h\"] = pd.to_numeric(df[f\"test_MAE_{h}h\"], errors=\"coerce\")\n",
    "\n",
    "df[\"avg_MAE\"] = df[[f\"test_MAE_{h}h\" for h in horizons]].mean(axis=1)\n",
    "\n",
    "cols = [\"model_name\", \"avg_MAE\"] + [f\"test_MAE_{h}h\" for h in horizons]\n",
    "display(df.sort_values(\"avg_MAE\")[cols].head(25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa60e41-dd87-4132-aed9-3434d79563f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b51c0ca-2070-4f1f-9858-71d082a1aa26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# IMPORTANT: limit CPU thread explosions (helps stop Paperspace kernels from dying)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import json\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc3f30bd-ce49-469f-ae44-5cdf4f4b3211",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18b89456-2e01-44e9-bf69-b275869f7817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import MultiTaskElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "537dac38-51b6-4bd0-83b6-ded09ab58b84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: Quadro P5000\n",
      "X: (2208, 1821, 6) (T,N,F)\n",
      "Y: (2208, 1821) (T,N)\n",
      "IN_LEN/OUT_LEN: 24 72\n",
      "N stations: 1821\n",
      "train/val/test starts: 1009 289 673\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "if DEVICE == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "DATA_PATH = Path(\"artifacts/pems_graph_dataset_strict.npz\")\n",
    "assert DATA_PATH.exists(), f\"Missing: {DATA_PATH}\"\n",
    "\n",
    "data = np.load(DATA_PATH, allow_pickle=True)\n",
    "\n",
    "X = data[\"X\"].astype(np.float32)         # (T, N, F)\n",
    "Y = data[\"Y\"].astype(np.float32)         # (T, N)   raw flow\n",
    "A = data[\"A\"].astype(np.float32)         # (N, N)\n",
    "stations = data[\"stations\"]\n",
    "timestamps = data[\"timestamps\"]\n",
    "\n",
    "train_starts = data[\"train_starts\"].astype(np.int64)\n",
    "val_starts   = data[\"val_starts\"].astype(np.int64)\n",
    "test_starts  = data[\"test_starts\"].astype(np.int64)\n",
    "\n",
    "IN_LEN  = int(np.array(data[\"in_len\"]).item())\n",
    "OUT_LEN = int(np.array(data[\"out_len\"]).item())\n",
    "\n",
    "flow_mean  = data[\"flow_mean\"].astype(np.float32)   # (N,)\n",
    "flow_std   = data[\"flow_std\"].astype(np.float32)    # (N,)\n",
    "speed_mean = data[\"speed_mean\"].astype(np.float32)  # (N,)\n",
    "speed_std  = data[\"speed_std\"].astype(np.float32)   # (N,)\n",
    "\n",
    "T, N, Fdim = X.shape\n",
    "print(\"X:\", X.shape, \"(T,N,F)\")\n",
    "print(\"Y:\", Y.shape, \"(T,N)\")\n",
    "print(\"IN_LEN/OUT_LEN:\", IN_LEN, OUT_LEN)\n",
    "print(\"N stations:\", N)\n",
    "print(\"train/val/test starts:\", len(train_starts), len(val_starts), len(test_starts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "272b7c1c-3a43-4aaf-a0ae-8e2566bc8c72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF_all: (2208, 4)\n"
     ]
    }
   ],
   "source": [
    "def time_encoding(dt_index: pd.DatetimeIndex) -> np.ndarray:\n",
    "    hours = dt_index.hour.values\n",
    "    dow   = dt_index.dayofweek.values\n",
    "    hour_sin = np.sin(2*np.pi*hours/24.0)\n",
    "    hour_cos = np.cos(2*np.pi*hours/24.0)\n",
    "    dow_sin  = np.sin(2*np.pi*dow/7.0)\n",
    "    dow_cos  = np.cos(2*np.pi*dow/7.0)\n",
    "    return np.stack([hour_sin, hour_cos, dow_sin, dow_cos], axis=1).astype(np.float32)\n",
    "\n",
    "TF_all = time_encoding(pd.to_datetime(timestamps))  # (T,4)\n",
    "print(\"TF_all:\", TF_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eeb7b61f-a4a4-4476-a7d2-6b91f81730a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity (scaled) flow mean/std ~ 0/1 on TRAIN-ish slice:\n",
      "Y_scaled mean/std: -781.403564453125 30704.76953125\n"
     ]
    }
   ],
   "source": [
    "# Avoid divide-by-zero\n",
    "flow_std  = np.maximum(flow_std,  1e-6).astype(np.float32)\n",
    "speed_std = np.maximum(speed_std, 1e-6).astype(np.float32)\n",
    "\n",
    "X_scaled = X.copy()\n",
    "# assume channel0=flow, channel1=speed (your pipeline)\n",
    "X_scaled[:, :, 0] = (X_scaled[:, :, 0] - flow_mean[None, :])  / flow_std[None, :]\n",
    "X_scaled[:, :, 1] = (X_scaled[:, :, 1] - speed_mean[None, :]) / speed_std[None, :]\n",
    "\n",
    "Y_scaled = (Y - flow_mean[None, :]) / flow_std[None, :]\n",
    "\n",
    "print(\"Sanity (scaled) flow mean/std ~ 0/1 on TRAIN-ish slice:\")\n",
    "print(\"Y_scaled mean/std:\", float(Y_scaled.mean()), float(Y_scaled.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea2fe815-876c-4744-a5c0-f965e11cb8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch x: torch.Size([8, 6, 1821, 24]) Batch y: torch.Size([8, 72, 1821]) Batch tf: torch.Size([8, 72, 4])\n"
     ]
    }
   ],
   "source": [
    "X_fnt = np.transpose(X_scaled, (2, 1, 0)).copy()  # (F, N, T)\n",
    "\n",
    "class FastPemsWindowDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X_fnt, Y_scaled, TF_all, starts, in_len, out_len):\n",
    "        self.X_fnt = X_fnt\n",
    "        self.Y = Y_scaled\n",
    "        self.TF = TF_all\n",
    "        self.starts = np.asarray(starts, dtype=np.int64)\n",
    "        self.in_len = int(in_len)\n",
    "        self.out_len = int(out_len)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.starts)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        s = int(self.starts[i])\n",
    "        x = self.X_fnt[:, :, s:s+self.in_len]                    # (F,N,IN)\n",
    "        y = self.Y[s+self.in_len:s+self.in_len+self.out_len, :]  # (OUT,N)\n",
    "        tf = self.TF[s+self.in_len:s+self.in_len+self.out_len]   # (OUT,4)\n",
    "        return torch.from_numpy(x), torch.from_numpy(y), torch.from_numpy(tf)\n",
    "\n",
    "train_ds = FastPemsWindowDataset(X_fnt, Y_scaled, TF_all, train_starts, IN_LEN, OUT_LEN)\n",
    "val_ds   = FastPemsWindowDataset(X_fnt, Y_scaled, TF_all, val_starts,   IN_LEN, OUT_LEN)\n",
    "test_ds  = FastPemsWindowDataset(X_fnt, Y_scaled, TF_all, test_starts,  IN_LEN, OUT_LEN)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0, pin_memory=False)\n",
    "val_loader   = torch.utils.data.DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False)\n",
    "test_loader  = torch.utils.data.DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "print(\"Batch x:\", xb.shape, \"Batch y:\", yb.shape, \"Batch tf:\", tfb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "317e5874-d2ee-4a0c-82d5-c037488d6e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EVAL_HORIZONS = [12, 24, 48, 72]\n",
    "H = len(EVAL_HORIZONS)\n",
    "\n",
    "flow_mean_t = torch.tensor(flow_mean, dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "flow_std_t  = torch.tensor(flow_std,  dtype=torch.float32, device=DEVICE).view(1, 1, -1)\n",
    "\n",
    "def print_metrics(title, metrics):\n",
    "    print(\"\\n\" + title)\n",
    "    for h in sorted(metrics.keys()):\n",
    "        print(f\"  {h:>3}h  MAE={metrics[h]['MAE']:.3f}  RMSE={metrics[h]['RMSE']:.3f}\")\n",
    "\n",
    "def avg_mae(metrics):\n",
    "    return float(np.mean([metrics[h][\"MAE\"] for h in metrics]))\n",
    "\n",
    "@torch.inference_mode()\n",
    "def eval_horizons_fast(model, loader):\n",
    "    model.eval()\n",
    "    acc = {h: {\"abs\": 0.0, \"sq\": 0.0, \"count\": 0} for h in EVAL_HORIZONS}\n",
    "\n",
    "    for xb, yb, tfb in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        xb  = xb.to(DEVICE, non_blocking=True)\n",
    "        yb  = yb.to(DEVICE, non_blocking=True)\n",
    "        tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        pred = model(xb, tfb)  # scaled (B,OUT,N)\n",
    "\n",
    "        pred_u = pred * flow_std_t + flow_mean_t\n",
    "        true_u = yb   * flow_std_t + flow_mean_t\n",
    "\n",
    "        for h in EVAL_HORIZONS:\n",
    "            idx = h - 1\n",
    "            err = pred_u[:, idx, :] - true_u[:, idx, :]\n",
    "            acc[h][\"abs\"]   += float(err.abs().sum())\n",
    "            acc[h][\"sq\"]    += float((err**2).sum())\n",
    "            acc[h][\"count\"] += err.numel()\n",
    "\n",
    "    metrics = {}\n",
    "    for h in EVAL_HORIZONS:\n",
    "        mae = acc[h][\"abs\"] / acc[h][\"count\"]\n",
    "        rmse = (acc[h][\"sq\"] / acc[h][\"count\"]) ** 0.5\n",
    "        metrics[h] = {\"MAE\": float(mae), \"RMSE\": float(rmse)}\n",
    "    return metrics\n",
    "\n",
    "def make_run_dir(model_name: str) -> Path:\n",
    "    ts = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = Path(\"artifacts/runs\") / f\"{ts}_{model_name}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=False)\n",
    "    return run_dir\n",
    "\n",
    "def save_metrics_files(run_dir: Path, split_name: str, metrics: dict):\n",
    "    (run_dir / f\"{split_name}_metrics.json\").write_text(json.dumps(metrics, indent=2))\n",
    "    rows = []\n",
    "    for h in sorted(metrics.keys()):\n",
    "        rows.append({\"horizon\": h, \"MAE\": metrics[h][\"MAE\"], \"RMSE\": metrics[h][\"RMSE\"]})\n",
    "    pd.DataFrame(rows).to_csv(run_dir / f\"{split_name}_metrics.csv\", index=False)\n",
    "\n",
    "def append_results_summary(model_name: str, run_dir: Path, test_metrics: dict):\n",
    "    summary_path = Path(\"artifacts/results_summary.csv\")\n",
    "    row = {\n",
    "        \"timestamp\": pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model_name\": model_name,\n",
    "        \"run_dir\": str(run_dir),\n",
    "    }\n",
    "    for h in EVAL_HORIZONS:\n",
    "        row[f\"test_MAE_{h}h\"] = test_metrics[h][\"MAE\"]\n",
    "        row[f\"test_RMSE_{h}h\"] = test_metrics[h][\"RMSE\"]\n",
    "\n",
    "    df_new = pd.DataFrame([row])\n",
    "    if summary_path.exists():\n",
    "        df_old = pd.read_csv(summary_path)\n",
    "        df = pd.concat([df_old, df_new], ignore_index=True)\n",
    "    else:\n",
    "        df = df_new\n",
    "    df.to_csv(summary_path, index=False)\n",
    "    return summary_path\n",
    "\n",
    "def save_preds_npz_and_csv_subset(\n",
    "    run_dir: Path,\n",
    "    pred_u: np.ndarray,   # (S,N,H)\n",
    "    true_u: np.ndarray,   # (S,N,H)\n",
    "    starts: np.ndarray,\n",
    "    max_stations_csv: int = 300,\n",
    "):\n",
    "    # NPZ (full)\n",
    "    np.savez_compressed(\n",
    "        run_dir / \"test_pred_true_selected_horizons.npz\",\n",
    "        pred=pred_u.astype(np.float32),\n",
    "        true=true_u.astype(np.float32),\n",
    "        horizons=np.array(EVAL_HORIZONS, dtype=np.int64),\n",
    "        starts=starts.astype(np.int64),\n",
    "        stations=stations,\n",
    "        timestamps=timestamps\n",
    "    )\n",
    "\n",
    "    # CSV subset (manageable)\n",
    "    K = min(max_stations_csv, N)\n",
    "    keep = np.arange(K)\n",
    "\n",
    "    frames = []\n",
    "    for j, h in enumerate(EVAL_HORIZONS):\n",
    "        idx = starts + IN_LEN + (h - 1)\n",
    "        ts_h = pd.to_datetime(timestamps[idx])\n",
    "\n",
    "        df_h = pd.DataFrame({\n",
    "            \"start_idx\": np.repeat(starts, K),\n",
    "            \"timestamp\": np.repeat(ts_h, K),\n",
    "            \"station\": np.tile(np.array(stations)[keep], len(starts)),\n",
    "            \"horizon_h\": h,\n",
    "            \"y_true\": true_u[:, keep, j].reshape(-1),\n",
    "            \"y_pred\": pred_u[:, keep, j].reshape(-1),\n",
    "        })\n",
    "        frames.append(df_h)\n",
    "\n",
    "    df_out = pd.concat(frames, ignore_index=True)\n",
    "    df_out.to_csv(run_dir / \"test_pred_true_selected_horizons.csv\", index=False)\n",
    "    return run_dir / \"test_pred_true_selected_horizons.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe60f4ba-ab85-475c-8072-e66920d8aa25",
   "metadata": {},
   "source": [
    "## LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f93a873-d68c-42f2-8aae-cee63abdece8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTM_Baseline(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_len: int, hidden: int = 64, layers: int = 1, dropout: float = 0.1, tf_dim: int = 4):\n",
    "        super().__init__()\n",
    "        self.out_len = out_len\n",
    "        self.hidden = hidden\n",
    "        self.lstm = nn.LSTM(input_size=in_dim, hidden_size=hidden, num_layers=layers, dropout=(dropout if layers > 1 else 0.0), batch_first=True)\n",
    "        self.head = nn.Linear(hidden + tf_dim, 1)\n",
    "\n",
    "    def forward(self, x, tf):\n",
    "        # x: (B,F,N,IN) -> (B,N,IN,F) -> (B*N, IN, F)\n",
    "        B, F, Nn, INL = x.shape\n",
    "        x_seq = x.permute(0, 2, 3, 1).contiguous().view(B * Nn, INL, F)\n",
    "\n",
    "        out, (h, c) = self.lstm(x_seq)\n",
    "        h_last = h[-1]  # (B*N, hidden)\n",
    "\n",
    "        # tf: (B, OUT, 4) -> repeat per node -> (B*N, OUT, 4)\n",
    "        tf_rep = tf.unsqueeze(1).expand(B, Nn, self.out_len, tf.shape[-1]).contiguous().view(B * Nn, self.out_len, tf.shape[-1])\n",
    "\n",
    "        h_rep = h_last.unsqueeze(1).expand(B * Nn, self.out_len, self.hidden)\n",
    "        z = torch.cat([h_rep, tf_rep], dim=-1)           # (B*N, OUT, hidden+4)\n",
    "        y = self.head(z).squeeze(-1)                    # (B*N, OUT)\n",
    "        y = y.view(B, Nn, self.out_len).permute(0, 2, 1) # (B, OUT, N)\n",
    "        return y\n",
    "\n",
    "def train_torch_and_save(model_name: str, model: nn.Module, epochs=40, lr=1e-3, weight_decay=1e-4, clip=5.0, patience=6, eval_every=2):\n",
    "    run_dir = make_run_dir(model_name)\n",
    "    print(\"Run dir:\", run_dir)\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.SmoothL1Loss(beta=1.0)\n",
    "\n",
    "    best = float(\"inf\")\n",
    "    bad = 0\n",
    "    best_state = None\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "\n",
    "        for xb, yb, tfb in tqdm(train_loader, desc=f\"Train {epoch}/{epochs}\", leave=False):\n",
    "            xb = xb.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "            tfb = tfb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            pred = model(xb, tfb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            opt.step()\n",
    "            running += float(loss.item())\n",
    "\n",
    "        if epoch % eval_every == 0:\n",
    "            val_m = eval_horizons_fast(model, val_loader)\n",
    "            score = avg_mae(val_m)\n",
    "            print(f\"\\nEpoch {epoch}: train_loss={running/len(train_loader):.6f}  val_avg_MAE={score:.3f}\")\n",
    "            print_metrics(\"VAL\", val_m)\n",
    "\n",
    "            history.append({\"epoch\": epoch, \"train_loss\": running/len(train_loader), \"val_avg_MAE\": score, **{f\"val_MAE_{h}h\": val_m[h][\"MAE\"] for h in EVAL_HORIZONS}})\n",
    "\n",
    "            if score < best:\n",
    "                best = score\n",
    "                bad = 0\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            else:\n",
    "                bad += 1\n",
    "                if bad >= patience:\n",
    "                    print(f\"\\nEarly stopping. Best val_avg_MAE={best:.3f}\")\n",
    "                    break\n",
    "\n",
    "    # save history\n",
    "    if len(history) > 0:\n",
    "        pd.DataFrame(history).to_csv(run_dir / \"history.csv\", index=False)\n",
    "\n",
    "    # load best + save checkpoint\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    torch.save(model.state_dict(), run_dir / \"best.pt\")\n",
    "\n",
    "    # TEST\n",
    "    print(\"\\nEvaluating on TEST set...\")\n",
    "    test_m = eval_horizons_fast(model, test_loader)\n",
    "    print_metrics(f\"{model_name} — TEST\", test_m)\n",
    "\n",
    "    save_metrics_files(run_dir, \"test\", test_m)\n",
    "\n",
    "    # Collect & save preds (selected horizons only)\n",
    "    S = len(test_starts)\n",
    "    pred_u = np.zeros((S, N, len(EVAL_HORIZONS)), dtype=np.float32)\n",
    "    true_u = np.zeros((S, N, len(EVAL_HORIZONS)), dtype=np.float32)\n",
    "\n",
    "    model.eval()\n",
    "    pos = 0\n",
    "    with torch.inference_mode():\n",
    "        for xb, yb, tfb in tqdm(test_loader, desc=\"Collect preds\", leave=False):\n",
    "            bsz = xb.shape[0]\n",
    "            xb  = xb.to(DEVICE)\n",
    "            yb  = yb.to(DEVICE)\n",
    "            tfb = tfb.to(DEVICE)\n",
    "\n",
    "            pred = model(xb, tfb)  # scaled (B,OUT,N)\n",
    "            pred_u_b = (pred * flow_std_t + flow_mean_t)  # (B,OUT,N)\n",
    "            true_u_b = (yb   * flow_std_t + flow_mean_t)\n",
    "\n",
    "            for j, h in enumerate(EVAL_HORIZONS):\n",
    "                idx = h - 1\n",
    "                pred_u[pos:pos+bsz, :, j] = pred_u_b[:, idx, :].detach().cpu().numpy()\n",
    "                true_u[pos:pos+bsz, :, j] = true_u_b[:, idx, :].detach().cpu().numpy()\n",
    "\n",
    "            pos += bsz\n",
    "\n",
    "    csv_path = save_preds_npz_and_csv_subset(run_dir, pred_u, true_u, test_starts, max_stations_csv=300)\n",
    "    summary_path = append_results_summary(model_name, run_dir, test_m)\n",
    "\n",
    "    print(\"\\nSaved run outputs to:\", run_dir)\n",
    "    print(\" - best checkpoint:\", run_dir / \"best.pt\")\n",
    "    print(\" - history:\", run_dir / \"history.csv\")\n",
    "    print(\" - test metrics:\", run_dir / \"test_metrics.json\")\n",
    "    print(\" - preds npz:\", run_dir / \"test_pred_true_selected_horizons.npz\")\n",
    "    print(\" - preds csv:\", csv_path)\n",
    "    print(\" - master summary:\", summary_path)\n",
    "\n",
    "    return run_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ec3afe5-7640-4493-bb74-512ffe01cf77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run dir: artifacts/runs/20260210_194456_LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.320809  val_avg_MAE=382.517\n",
      "\n",
      "VAL\n",
      "   12h  MAE=379.311  RMSE=625.654\n",
      "   24h  MAE=381.042  RMSE=630.496\n",
      "   48h  MAE=386.313  RMSE=638.276\n",
      "   72h  MAE=383.400  RMSE=630.289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=0.236424  val_avg_MAE=312.220\n",
      "\n",
      "VAL\n",
      "   12h  MAE=314.541  RMSE=533.124\n",
      "   24h  MAE=310.456  RMSE=528.506\n",
      "   48h  MAE=313.938  RMSE=532.925\n",
      "   72h  MAE=309.946  RMSE=521.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: train_loss=0.191218  val_avg_MAE=268.685\n",
      "\n",
      "VAL\n",
      "   12h  MAE=270.014  RMSE=471.836\n",
      "   24h  MAE=267.554  RMSE=467.962\n",
      "   48h  MAE=270.475  RMSE=471.248\n",
      "   72h  MAE=266.697  RMSE=459.570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: train_loss=0.169478  val_avg_MAE=243.285\n",
      "\n",
      "VAL\n",
      "   12h  MAE=241.783  RMSE=433.174\n",
      "   24h  MAE=242.627  RMSE=433.923\n",
      "   48h  MAE=246.278  RMSE=437.987\n",
      "   72h  MAE=242.451  RMSE=425.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: train_loss=0.159286  val_avg_MAE=228.872\n",
      "\n",
      "VAL\n",
      "   12h  MAE=225.890  RMSE=411.183\n",
      "   24h  MAE=228.787  RMSE=414.217\n",
      "   48h  MAE=231.621  RMSE=416.383\n",
      "   72h  MAE=229.188  RMSE=406.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: train_loss=0.155571  val_avg_MAE=219.229\n",
      "\n",
      "VAL\n",
      "   12h  MAE=217.691  RMSE=402.907\n",
      "   24h  MAE=218.839  RMSE=404.333\n",
      "   48h  MAE=221.824  RMSE=406.237\n",
      "   72h  MAE=218.563  RMSE=393.787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: train_loss=0.154543  val_avg_MAE=217.548\n",
      "\n",
      "VAL\n",
      "   12h  MAE=215.619  RMSE=398.803\n",
      "   24h  MAE=217.312  RMSE=401.362\n",
      "   48h  MAE=220.151  RMSE=402.976\n",
      "   72h  MAE=217.110  RMSE=391.180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: train_loss=0.154310  val_avg_MAE=215.735\n",
      "\n",
      "VAL\n",
      "   12h  MAE=214.697  RMSE=396.537\n",
      "   24h  MAE=214.984  RMSE=396.953\n",
      "   48h  MAE=217.842  RMSE=399.114\n",
      "   72h  MAE=215.418  RMSE=388.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: train_loss=0.153910  val_avg_MAE=216.894\n",
      "\n",
      "VAL\n",
      "   12h  MAE=214.726  RMSE=396.012\n",
      "   24h  MAE=216.812  RMSE=398.659\n",
      "   48h  MAE=219.204  RMSE=399.618\n",
      "   72h  MAE=216.832  RMSE=389.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: train_loss=0.153893  val_avg_MAE=214.605\n",
      "\n",
      "VAL\n",
      "   12h  MAE=210.363  RMSE=393.016\n",
      "   24h  MAE=215.191  RMSE=399.678\n",
      "   48h  MAE=218.016  RMSE=401.261\n",
      "   72h  MAE=214.850  RMSE=389.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: train_loss=0.153931  val_avg_MAE=217.337\n",
      "\n",
      "VAL\n",
      "   12h  MAE=214.923  RMSE=395.916\n",
      "   24h  MAE=216.774  RMSE=398.869\n",
      "   48h  MAE=220.158  RMSE=401.589\n",
      "   72h  MAE=217.494  RMSE=391.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: train_loss=0.154166  val_avg_MAE=216.516\n",
      "\n",
      "VAL\n",
      "   12h  MAE=213.300  RMSE=394.374\n",
      "   24h  MAE=216.472  RMSE=398.559\n",
      "   48h  MAE=219.286  RMSE=400.382\n",
      "   72h  MAE=217.006  RMSE=390.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: train_loss=0.154025  val_avg_MAE=212.017\n",
      "\n",
      "VAL\n",
      "   12h  MAE=211.293  RMSE=394.835\n",
      "   24h  MAE=211.839  RMSE=396.043\n",
      "   48h  MAE=214.018  RMSE=396.692\n",
      "   72h  MAE=210.917  RMSE=384.676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: train_loss=0.153823  val_avg_MAE=220.093\n",
      "\n",
      "VAL\n",
      "   12h  MAE=216.945  RMSE=395.549\n",
      "   24h  MAE=219.505  RMSE=399.129\n",
      "   48h  MAE=222.564  RMSE=401.864\n",
      "   72h  MAE=221.357  RMSE=394.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: train_loss=0.153642  val_avg_MAE=220.669\n",
      "\n",
      "VAL\n",
      "   12h  MAE=217.018  RMSE=397.284\n",
      "   24h  MAE=221.059  RMSE=402.909\n",
      "   48h  MAE=223.714  RMSE=404.069\n",
      "   72h  MAE=220.886  RMSE=393.742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: train_loss=0.153735  val_avg_MAE=219.903\n",
      "\n",
      "VAL\n",
      "   12h  MAE=217.648  RMSE=399.058\n",
      "   24h  MAE=219.960  RMSE=402.868\n",
      "   48h  MAE=222.741  RMSE=404.134\n",
      "   72h  MAE=219.262  RMSE=392.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: train_loss=0.153863  val_avg_MAE=218.836\n",
      "\n",
      "VAL\n",
      "   12h  MAE=216.376  RMSE=398.738\n",
      "   24h  MAE=219.371  RMSE=403.235\n",
      "   48h  MAE=221.700  RMSE=403.637\n",
      "   72h  MAE=217.898  RMSE=391.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: train_loss=0.153885  val_avg_MAE=216.502\n",
      "\n",
      "VAL\n",
      "   12h  MAE=213.170  RMSE=392.736\n",
      "   24h  MAE=215.992  RMSE=397.322\n",
      "   48h  MAE=219.361  RMSE=400.568\n",
      "   72h  MAE=217.483  RMSE=391.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: train_loss=0.153954  val_avg_MAE=215.830\n",
      "\n",
      "VAL\n",
      "   12h  MAE=212.955  RMSE=393.432\n",
      "   24h  MAE=215.556  RMSE=397.488\n",
      "   48h  MAE=218.603  RMSE=400.005\n",
      "   72h  MAE=216.204  RMSE=389.975\n",
      "\n",
      "Early stopping. Best val_avg_MAE=212.017\n",
      "\n",
      "Evaluating on TEST set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM — TEST\n",
      "   12h  MAE=217.363  RMSE=403.856\n",
      "   24h  MAE=212.865  RMSE=399.008\n",
      "   48h  MAE=214.150  RMSE=399.032\n",
      "   72h  MAE=212.684  RMSE=392.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved run outputs to: artifacts/runs/20260210_194456_LSTM\n",
      " - best checkpoint: artifacts/runs/20260210_194456_LSTM/best.pt\n",
      " - history: artifacts/runs/20260210_194456_LSTM/history.csv\n",
      " - test metrics: artifacts/runs/20260210_194456_LSTM/test_metrics.json\n",
      " - preds npz: artifacts/runs/20260210_194456_LSTM/test_pred_true_selected_horizons.npz\n",
      " - preds csv: artifacts/runs/20260210_194456_LSTM/test_pred_true_selected_horizons.csv\n",
      " - master summary: artifacts/results_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('artifacts/runs/20260210_194456_LSTM')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_base = LSTM_Baseline(in_dim=Fdim, out_len=OUT_LEN, hidden=64, layers=1, dropout=0.1).to(DEVICE)\n",
    "run_dir_lstm = train_torch_and_save(\"LSTM\", lstm_base, epochs=40, patience=6, eval_every=2)\n",
    "run_dir_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d65545-422a-455e-a34c-c85233420813",
   "metadata": {},
   "source": [
    "## Elastic Net Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8aea03c-4dd6-4880-9e00-cc86c83fe3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "H_OFF = np.array([h - 1 for h in EVAL_HORIZONS], dtype=np.int64)\n",
    "\n",
    "def node_features_and_targets(node: int, starts: np.ndarray):\n",
    "    # past window features (scaled) for this node\n",
    "    Xn = X_scaled[:, node, :]  # (T,F)\n",
    "    win = np.lib.stride_tricks.sliding_window_view(Xn, window_shape=IN_LEN, axis=0)  # (T-IN_LEN+1, IN_LEN, F)\n",
    "    X_hist = win[starts].reshape(len(starts), -1)  # (S, IN_LEN*F)\n",
    "\n",
    "    # future time features for all horizons (S,H,4) -> (S, H*4)\n",
    "    idx = starts[:, None] + IN_LEN + H_OFF[None, :]\n",
    "    X_tf = TF_all[idx].reshape(len(starts), -1)\n",
    "\n",
    "    X_feat = np.concatenate([X_hist, X_tf], axis=1)\n",
    "\n",
    "    # targets (scaled) (S,H)\n",
    "    y = Y_scaled[idx, node]\n",
    "    return X_feat, y.astype(np.float32)\n",
    "\n",
    "def run_elasticnet_baseline(alpha=1e-3, l1_ratio=0.5, jobs=4):\n",
    "    model_name = \"ElasticNet\"\n",
    "    run_dir = make_run_dir(model_name)\n",
    "    print(\"Run dir:\", run_dir)\n",
    "\n",
    "    S_test = len(test_starts)\n",
    "    pred_scaled = np.zeros((S_test, N, H), dtype=np.float32)\n",
    "    true_scaled = np.zeros((S_test, N, H), dtype=np.float32)\n",
    "\n",
    "    def fit_one(node: int):\n",
    "        Xtr, ytr = node_features_and_targets(node, train_starts)\n",
    "        Xte, yte = node_features_and_targets(node, test_starts)\n",
    "\n",
    "        # Elastic net + scaling\n",
    "        mdl = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            MultiTaskElasticNet(alpha=alpha, l1_ratio=l1_ratio, max_iter=5000, random_state=42)\n",
    "        )\n",
    "        mdl.fit(Xtr, ytr)\n",
    "        pred = mdl.predict(Xte).astype(np.float32)  # (S_test,H)\n",
    "        return node, pred, yte\n",
    "\n",
    "    nodes = list(range(N))\n",
    "    results = Parallel(n_jobs=jobs, prefer=\"threads\")(\n",
    "        delayed(fit_one)(node) for node in tqdm(nodes, desc=\"ElasticNet per-node\")\n",
    "    )\n",
    "\n",
    "    for node, pred, yte in results:\n",
    "        pred_scaled[:, node, :] = pred\n",
    "        true_scaled[:, node, :] = yte\n",
    "\n",
    "    # unscale\n",
    "    pred_u = pred_scaled * flow_std[None, :, None] + flow_mean[None, :, None]\n",
    "    true_u = true_scaled * flow_std[None, :, None] + flow_mean[None, :, None]\n",
    "\n",
    "    # metrics\n",
    "    metrics = {}\n",
    "    for j, h in enumerate(EVAL_HORIZONS):\n",
    "        err = pred_u[:, :, j] - true_u[:, :, j]\n",
    "        metrics[h] = {\n",
    "            \"MAE\": float(np.abs(err).mean()),\n",
    "            \"RMSE\": float(np.sqrt((err**2).mean())),\n",
    "        }\n",
    "\n",
    "    print_metrics(\"ElasticNet — TEST\", metrics)\n",
    "    save_metrics_files(run_dir, \"test\", metrics)\n",
    "\n",
    "    csv_path = save_preds_npz_and_csv_subset(run_dir, pred_u, true_u, test_starts, max_stations_csv=300)\n",
    "    summary_path = append_results_summary(model_name, run_dir, metrics)\n",
    "\n",
    "    print(\"\\nSaved:\", run_dir)\n",
    "    print(\" - test metrics:\", run_dir / \"test_metrics.json\")\n",
    "    print(\" - preds npz:\", run_dir / \"test_pred_true_selected_horizons.npz\")\n",
    "    print(\" - preds csv:\", csv_path)\n",
    "    print(\" - master summary:\", summary_path)\n",
    "\n",
    "    return run_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "750edfb8-c7e3-401f-ae4f-e09849189260",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run dir: artifacts/runs/20260210_195631_ElasticNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ElasticNet per-node:   1%|          | 12/1821 [00:01<02:56, 10.26it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8663005828857422, tolerance: 0.38365796208381653\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:   1%|▏         | 24/1821 [00:02<03:20,  8.95it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4602660536766052, tolerance: 0.4010064899921417\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:   2%|▏         | 36/1821 [00:04<04:45,  6.25it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4602660536766052, tolerance: 0.4010064899921417\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  11%|█         | 196/1821 [00:35<06:19,  4.28it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4602660536766052, tolerance: 0.4010064899921417\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  11%|█         | 200/1821 [00:36<05:59,  4.51it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4986342191696167, tolerance: 0.4012649953365326\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  16%|█▌        | 292/1821 [00:55<05:22,  4.74it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.6221299171447754, tolerance: 0.40124812722206116\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  20%|█▉        | 364/1821 [01:10<04:35,  5.29it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6584926843643188, tolerance: 0.4064045250415802\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  36%|███▌      | 656/1821 [02:17<04:08,  4.68it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.44889310002326965, tolerance: 0.4171396493911743\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  37%|███▋      | 668/1821 [02:20<04:54,  3.92it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7681939005851746, tolerance: 0.40168821811676025\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  38%|███▊      | 700/1821 [02:28<04:11,  4.45it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9654268622398376, tolerance: 0.39281603693962097\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  40%|███▉      | 728/1821 [02:34<03:35,  5.07it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4682033061981201, tolerance: 0.40125828981399536\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  40%|████      | 732/1821 [02:34<02:55,  6.19it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4682033061981201, tolerance: 0.40125828981399536\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0, tolerance: 0.0\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  43%|████▎     | 780/1821 [02:43<03:46,  4.61it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4602660536766052, tolerance: 0.4010064899921417\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  52%|█████▏    | 940/1821 [03:15<03:13,  4.56it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.645818293094635, tolerance: 0.4116685092449188\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  53%|█████▎    | 968/1821 [03:22<03:37,  3.92it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5832305550575256, tolerance: 0.4110391438007355\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  54%|█████▍    | 988/1821 [03:26<03:22,  4.12it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.43976256251335144, tolerance: 0.4167461395263672\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  58%|█████▊    | 1056/1821 [03:44<03:42,  3.44it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.38997146487236023, tolerance: 0.329557329416275\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  63%|██████▎   | 1152/1821 [04:04<02:11,  5.08it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4236897826194763, tolerance: 0.4104951024055481\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  64%|██████▍   | 1168/1821 [04:08<02:27,  4.44it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4245269000530243, tolerance: 0.4014166295528412\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  67%|██████▋   | 1212/1821 [04:17<01:55,  5.27it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6247127056121826, tolerance: 0.40517356991767883\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  67%|██████▋   | 1216/1821 [04:18<02:38,  3.83it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5156073570251465, tolerance: 0.39401984214782715\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  71%|███████▏  | 1300/1821 [04:37<02:05,  4.16it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5559744834899902, tolerance: 0.4026634991168976\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  75%|███████▍  | 1360/1821 [04:49<01:52,  4.08it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6286512017250061, tolerance: 0.3868473172187805\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  75%|███████▍  | 1364/1821 [04:50<01:47,  4.25it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9469077587127686, tolerance: 0.4277578890323639\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.48785659670829773, tolerance: 0.3675461411476135\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  76%|███████▌  | 1376/1821 [04:53<01:57,  3.80it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3594775199890137, tolerance: 0.42457109689712524\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  76%|███████▌  | 1384/1821 [04:55<01:44,  4.16it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4734618067741394, tolerance: 0.39650478959083557\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  77%|███████▋  | 1400/1821 [04:59<01:32,  4.56it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8067962527275085, tolerance: 0.40232598781585693\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  78%|███████▊  | 1428/1821 [05:04<01:29,  4.41it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8880859017372131, tolerance: 0.4103725850582123\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  81%|████████  | 1476/1821 [05:15<01:16,  4.49it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9740669131278992, tolerance: 0.39512163400650024\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3924879729747772, tolerance: 0.3654349446296692\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  83%|████████▎ | 1508/1821 [05:23<01:35,  3.27it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5623096227645874, tolerance: 0.40487995743751526\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  87%|████████▋ | 1588/1821 [05:40<00:48,  4.83it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.40386807918548584, tolerance: 0.31999385356903076\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  95%|█████████▍| 1728/1821 [06:15<00:22,  4.15it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6797438859939575, tolerance: 0.40404558181762695\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node:  97%|█████████▋| 1772/1821 [06:26<00:14,  3.43it/s]/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:2412: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7565670609474182, tolerance: 0.41006195545196533\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n",
      "ElasticNet per-node: 100%|██████████| 1821/1821 [06:37<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ElasticNet — TEST\n",
      "   12h  MAE=151.053  RMSE=306.839\n",
      "   24h  MAE=148.707  RMSE=304.068\n",
      "   48h  MAE=149.399  RMSE=305.192\n",
      "   72h  MAE=141.125  RMSE=295.535\n",
      "\n",
      "Saved: artifacts/runs/20260210_195631_ElasticNet\n",
      " - test metrics: artifacts/runs/20260210_195631_ElasticNet/test_metrics.json\n",
      " - preds npz: artifacts/runs/20260210_195631_ElasticNet/test_pred_true_selected_horizons.npz\n",
      " - preds csv: artifacts/runs/20260210_195631_ElasticNet/test_pred_true_selected_horizons.csv\n",
      " - master summary: artifacts/results_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('artifacts/runs/20260210_195631_ElasticNet')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_dir_en = run_elasticnet_baseline(alpha=1e-3, l1_ratio=0.5, jobs=4)\n",
    "run_dir_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac54c782-dcab-478d-9ad1-754e5a0972b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f0781d9-3279-4d80-bac3-f437940da785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_random_forest_baseline(\n",
    "    n_estimators=50,\n",
    "    max_depth=20,\n",
    "    min_samples_leaf=5,\n",
    "    max_features=\"sqrt\",\n",
    "    jobs=4\n",
    "):\n",
    "    model_name = \"RandomForest\"\n",
    "    run_dir = make_run_dir(model_name)\n",
    "    print(\"Run dir:\", run_dir)\n",
    "\n",
    "    S_test = len(test_starts)\n",
    "    pred_scaled = np.zeros((S_test, N, H), dtype=np.float32)\n",
    "    true_scaled = np.zeros((S_test, N, H), dtype=np.float32)\n",
    "\n",
    "    def fit_one(node: int):\n",
    "        Xtr, ytr = node_features_and_targets(node, train_starts)\n",
    "        Xte, yte = node_features_and_targets(node, test_starts)\n",
    "\n",
    "        mdl = RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            max_features=max_features,\n",
    "            n_jobs=1,             # IMPORTANT: keep 1; we parallelize across nodes\n",
    "            random_state=42\n",
    "        )\n",
    "        mdl.fit(Xtr, ytr)\n",
    "        pred = mdl.predict(Xte).astype(np.float32)\n",
    "        return node, pred, yte\n",
    "\n",
    "    nodes = list(range(N))\n",
    "    results = Parallel(n_jobs=jobs, prefer=\"threads\")(\n",
    "        delayed(fit_one)(node) for node in tqdm(nodes, desc=\"RF per-node\")\n",
    "    )\n",
    "\n",
    "    for node, pred, yte in results:\n",
    "        pred_scaled[:, node, :] = pred\n",
    "        true_scaled[:, node, :] = yte\n",
    "\n",
    "    pred_u = pred_scaled * flow_std[None, :, None] + flow_mean[None, :, None]\n",
    "    true_u = true_scaled * flow_std[None, :, None] + flow_mean[None, :, None]\n",
    "\n",
    "    metrics = {}\n",
    "    for j, h in enumerate(EVAL_HORIZONS):\n",
    "        err = pred_u[:, :, j] - true_u[:, :, j]\n",
    "        metrics[h] = {\n",
    "            \"MAE\": float(np.abs(err).mean()),\n",
    "            \"RMSE\": float(np.sqrt((err**2).mean())),\n",
    "        }\n",
    "\n",
    "    print_metrics(\"RandomForest — TEST\", metrics)\n",
    "    save_metrics_files(run_dir, \"test\", metrics)\n",
    "\n",
    "    csv_path = save_preds_npz_and_csv_subset(run_dir, pred_u, true_u, test_starts, max_stations_csv=300)\n",
    "    summary_path = append_results_summary(model_name, run_dir, metrics)\n",
    "\n",
    "    print(\"\\nSaved:\", run_dir)\n",
    "    print(\" - test metrics:\", run_dir / \"test_metrics.json\")\n",
    "    print(\" - preds npz:\", run_dir / \"test_pred_true_selected_horizons.npz\")\n",
    "    print(\" - preds csv:\", csv_path)\n",
    "    print(\" - master summary:\", summary_path)\n",
    "\n",
    "    return run_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b29ea460-33c8-4134-ae4d-540dd8cf9903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run dir: artifacts/runs/20260210_200319_RandomForest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RF per-node: 100%|██████████| 1821/1821 [03:09<00:00,  9.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForest — TEST\n",
      "   12h  MAE=114.455  RMSE=259.444\n",
      "   24h  MAE=115.199  RMSE=263.879\n",
      "   48h  MAE=123.087  RMSE=279.939\n",
      "   72h  MAE=125.602  RMSE=284.720\n",
      "\n",
      "Saved: artifacts/runs/20260210_200319_RandomForest\n",
      " - test metrics: artifacts/runs/20260210_200319_RandomForest/test_metrics.json\n",
      " - preds npz: artifacts/runs/20260210_200319_RandomForest/test_pred_true_selected_horizons.npz\n",
      " - preds csv: artifacts/runs/20260210_200319_RandomForest/test_pred_true_selected_horizons.csv\n",
      " - master summary: artifacts/results_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('artifacts/runs/20260210_200319_RandomForest')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_dir_rf = run_random_forest_baseline(n_estimators=50, max_depth=20, min_samples_leaf=5, jobs=4)\n",
    "run_dir_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "349c7b16-b91a-4102-b289-1445a4bbb30e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model_name</th>\n",
       "      <th>avg_MAE</th>\n",
       "      <th>test_MAE_12h</th>\n",
       "      <th>test_MAE_24h</th>\n",
       "      <th>test_MAE_48h</th>\n",
       "      <th>test_MAE_72h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2026-02-10 20:06:36</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>119.585777</td>\n",
       "      <td>114.454689</td>\n",
       "      <td>115.199486</td>\n",
       "      <td>123.086647</td>\n",
       "      <td>125.602287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GraphWaveNet_GRU_LSTM</td>\n",
       "      <td>130.347263</td>\n",
       "      <td>119.049412</td>\n",
       "      <td>125.123518</td>\n",
       "      <td>135.325328</td>\n",
       "      <td>141.890796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GraphWaveNet_LSTM</td>\n",
       "      <td>131.859503</td>\n",
       "      <td>123.367641</td>\n",
       "      <td>125.953695</td>\n",
       "      <td>135.830582</td>\n",
       "      <td>142.286094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>STGCN</td>\n",
       "      <td>132.266313</td>\n",
       "      <td>119.125651</td>\n",
       "      <td>121.787452</td>\n",
       "      <td>139.610473</td>\n",
       "      <td>148.541676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>STGCN_GRU</td>\n",
       "      <td>132.610577</td>\n",
       "      <td>114.689314</td>\n",
       "      <td>121.745046</td>\n",
       "      <td>139.941089</td>\n",
       "      <td>154.066858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>STGCN</td>\n",
       "      <td>132.881293</td>\n",
       "      <td>124.865714</td>\n",
       "      <td>121.199576</td>\n",
       "      <td>136.894008</td>\n",
       "      <td>148.565873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>STGCN</td>\n",
       "      <td>132.881293</td>\n",
       "      <td>124.865714</td>\n",
       "      <td>121.199576</td>\n",
       "      <td>136.894008</td>\n",
       "      <td>148.565873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GraphWaveNet_GRU</td>\n",
       "      <td>133.121911</td>\n",
       "      <td>122.688777</td>\n",
       "      <td>127.520536</td>\n",
       "      <td>138.531665</td>\n",
       "      <td>143.746668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>STGCN_LSTM</td>\n",
       "      <td>133.812095</td>\n",
       "      <td>119.279658</td>\n",
       "      <td>124.610721</td>\n",
       "      <td>139.245704</td>\n",
       "      <td>152.112297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>STGCN_GRU_LSTM</td>\n",
       "      <td>135.100299</td>\n",
       "      <td>118.894072</td>\n",
       "      <td>123.719928</td>\n",
       "      <td>142.578867</td>\n",
       "      <td>155.208328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2026-02-10 20:03:18</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>147.571213</td>\n",
       "      <td>151.053421</td>\n",
       "      <td>148.707306</td>\n",
       "      <td>149.398804</td>\n",
       "      <td>141.125320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2026-02-10 19:53:08</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>214.265528</td>\n",
       "      <td>217.363009</td>\n",
       "      <td>212.865069</td>\n",
       "      <td>214.150324</td>\n",
       "      <td>212.683710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>STGCN</td>\n",
       "      <td>4925.363840</td>\n",
       "      <td>4932.437692</td>\n",
       "      <td>4919.577328</td>\n",
       "      <td>4923.404710</td>\n",
       "      <td>4926.035632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>STGCN</td>\n",
       "      <td>8772.041396</td>\n",
       "      <td>8775.111610</td>\n",
       "      <td>8771.100333</td>\n",
       "      <td>8771.417389</td>\n",
       "      <td>8770.536252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp             model_name      avg_MAE  test_MAE_12h  \\\n",
       "13  2026-02-10 20:06:36           RandomForest   119.585777    114.454689   \n",
       "2                   NaN  GraphWaveNet_GRU_LSTM   130.347263    119.049412   \n",
       "1                   NaN      GraphWaveNet_LSTM   131.859503    123.367641   \n",
       "5                   NaN                  STGCN   132.266313    119.125651   \n",
       "8                   NaN              STGCN_GRU   132.610577    114.689314   \n",
       "6                   NaN                  STGCN   132.881293    124.865714   \n",
       "7                   NaN                  STGCN   132.881293    124.865714   \n",
       "0                   NaN       GraphWaveNet_GRU   133.121911    122.688777   \n",
       "9                   NaN             STGCN_LSTM   133.812095    119.279658   \n",
       "10                  NaN         STGCN_GRU_LSTM   135.100299    118.894072   \n",
       "12  2026-02-10 20:03:18             ElasticNet   147.571213    151.053421   \n",
       "11  2026-02-10 19:53:08                   LSTM   214.265528    217.363009   \n",
       "4                   NaN                  STGCN  4925.363840   4932.437692   \n",
       "3                   NaN                  STGCN  8772.041396   8775.111610   \n",
       "\n",
       "    test_MAE_24h  test_MAE_48h  test_MAE_72h  \n",
       "13    115.199486    123.086647    125.602287  \n",
       "2     125.123518    135.325328    141.890796  \n",
       "1     125.953695    135.830582    142.286094  \n",
       "5     121.787452    139.610473    148.541676  \n",
       "8     121.745046    139.941089    154.066858  \n",
       "6     121.199576    136.894008    148.565873  \n",
       "7     121.199576    136.894008    148.565873  \n",
       "0     127.520536    138.531665    143.746668  \n",
       "9     124.610721    139.245704    152.112297  \n",
       "10    123.719928    142.578867    155.208328  \n",
       "12    148.707306    149.398804    141.125320  \n",
       "11    212.865069    214.150324    212.683710  \n",
       "4    4919.577328   4923.404710   4926.035632  \n",
       "3    8771.100333   8771.417389   8770.536252  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"artifacts/results_summary.csv\")\n",
    "\n",
    "horizons = [12, 24, 48, 72]\n",
    "for h in horizons:\n",
    "    df[f\"test_MAE_{h}h\"] = pd.to_numeric(df[f\"test_MAE_{h}h\"], errors=\"coerce\")\n",
    "\n",
    "df[\"avg_MAE\"] = df[[f\"test_MAE_{h}h\" for h in horizons]].mean(axis=1)\n",
    "\n",
    "cols = [\"timestamp\",\"model_name\",\"avg_MAE\"] + [f\"test_MAE_{h}h\" for h in horizons]\n",
    "display(df.sort_values(\"avg_MAE\")[cols].head(50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e170cb42-bfbe-4ef4-94b7-1eb7d2d744f4",
   "metadata": {},
   "source": [
    "## CNN-GRU-LSTM (Literature Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4efe81bd-98f4-4ed3-9eb0-d48d7206cd8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_GRU_LSTM_MultiHorizon(nn.Module):\n",
    "    \"\"\"\n",
    "    Per-node temporal model:\n",
    "      (Conv1D over time) -> GRU -> LSTM -> Linear(out_len)\n",
    "    Works on x: (B, F, N, IN_LEN)  and tf: (B, OUT_LEN, tf_dim)\n",
    "    Returns: (B, OUT_LEN, N)\n",
    "\n",
    "    node_chunk: splits nodes to avoid OOM when N is large (like 1821).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_len: int,\n",
    "        tf_dim: int = 4,\n",
    "        conv_channels: int = 32,\n",
    "        conv_kernel: int = 3,\n",
    "        gru_hidden: int = 64,\n",
    "        lstm_hidden: int = 64,\n",
    "        dropout: float = 0.1,\n",
    "        use_time_bias: bool = True,\n",
    "        node_chunk: int = 256,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_len = out_len\n",
    "        self.tf_dim = tf_dim\n",
    "        self.use_time_bias = use_time_bias\n",
    "        self.node_chunk = node_chunk\n",
    "\n",
    "        pad = conv_kernel // 2\n",
    "\n",
    "        # Temporal CNN encoder (per node)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=in_dim, out_channels=conv_channels, kernel_size=conv_kernel, padding=pad),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=conv_kernel, padding=pad),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Stacked RNN encoder (per node)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=conv_channels,\n",
    "            hidden_size=gru_hidden,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=gru_hidden,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        # Map final hidden -> all horizons directly\n",
    "        self.h_to_out = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, out_len),\n",
    "        )\n",
    "\n",
    "        # Optional: horizon/time bias from tf (same for all nodes in a sample)\n",
    "        if use_time_bias:\n",
    "            self.tf_to_bias = nn.Sequential(\n",
    "                nn.Linear(tf_dim, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32, 1),   # per-horizon scalar\n",
    "            )\n",
    "\n",
    "    def forward(self, x, tf):\n",
    "        \"\"\"\n",
    "        x:  (B, F, N, IN_LEN)\n",
    "        tf: (B, OUT_LEN, tf_dim)\n",
    "        \"\"\"\n",
    "        B, Fdim, N, IN_LEN = x.shape\n",
    "        device = x.device\n",
    "        dtype = x.dtype\n",
    "\n",
    "        # time bias: (B, OUT_LEN) — computed once, broadcast across nodes\n",
    "        if self.use_time_bias:\n",
    "            tf = tf.to(device=device, dtype=dtype)\n",
    "            time_bias = self.tf_to_bias(tf).squeeze(-1)  # (B, OUT_LEN)\n",
    "        else:\n",
    "            time_bias = None\n",
    "\n",
    "        out = torch.empty((B, self.out_len, N), device=device, dtype=dtype)\n",
    "\n",
    "        # process nodes in chunks to avoid OOM\n",
    "        for s in range(0, N, self.node_chunk):\n",
    "            e = min(N, s + self.node_chunk)\n",
    "            Nc = e - s\n",
    "\n",
    "            # x_chunk: (B, F, Nc, IN_LEN)\n",
    "            x_chunk = x[:, :, s:e, :]\n",
    "\n",
    "            # reshape to per-node sequences: (B*Nc, F, IN_LEN)\n",
    "            x_seq = x_chunk.permute(0, 2, 1, 3).contiguous().view(B * Nc, Fdim, IN_LEN)\n",
    "\n",
    "            # CNN over time -> (B*Nc, C, IN_LEN)\n",
    "            z = self.cnn(x_seq)\n",
    "\n",
    "            # RNN expects (B*Nc, IN_LEN, C)\n",
    "            z = z.transpose(1, 2).contiguous()\n",
    "\n",
    "            z, _ = self.gru(z)                 # (B*Nc, IN_LEN, gru_hidden)\n",
    "            z, (h, c) = self.lstm(z)           # h: (1, B*Nc, lstm_hidden)\n",
    "            h_last = h[-1]                     # (B*Nc, lstm_hidden)\n",
    "\n",
    "            pred = self.h_to_out(h_last)       # (B*Nc, OUT_LEN)\n",
    "\n",
    "            # reshape to (B, OUT_LEN, Nc)\n",
    "            pred = pred.view(B, Nc, self.out_len).permute(0, 2, 1).contiguous()\n",
    "\n",
    "            if time_bias is not None:\n",
    "                pred = pred + time_bias.unsqueeze(-1)  # broadcast over nodes\n",
    "\n",
    "            out[:, :, s:e] = pred\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10eb3a1d-48a0-4162-a5a7-7b97b291f2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward: torch.Size([8, 72, 1821]) mean/std: -0.10008469969034195 0.21270188689231873\n",
      "Run dir: artifacts/runs/20260210_223029_CNN_GRU_LSTM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 1/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 2/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=0.279704 val_avg_MAE=187.348\n",
      "\n",
      "VAL\n",
      "   12h  MAE=183.550  RMSE=333.511\n",
      "   24h  MAE=184.685  RMSE=343.514\n",
      "   48h  MAE=187.308  RMSE=349.380\n",
      "   72h  MAE=193.849  RMSE=355.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 3/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 4/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=0.245881 val_avg_MAE=178.873\n",
      "\n",
      "VAL\n",
      "   12h  MAE=160.190  RMSE=302.606\n",
      "   24h  MAE=174.787  RMSE=322.889\n",
      "   48h  MAE=187.620  RMSE=342.224\n",
      "   72h  MAE=192.896  RMSE=350.863\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 5/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 6/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: train_loss=0.225988 val_avg_MAE=175.368\n",
      "\n",
      "VAL\n",
      "   12h  MAE=164.786  RMSE=310.027\n",
      "   24h  MAE=164.573  RMSE=307.617\n",
      "   48h  MAE=182.529  RMSE=337.886\n",
      "   72h  MAE=189.584  RMSE=348.248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 7/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 8/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: train_loss=0.211273 val_avg_MAE=165.319\n",
      "\n",
      "VAL\n",
      "   12h  MAE=149.580  RMSE=286.344\n",
      "   24h  MAE=157.797  RMSE=301.509\n",
      "   48h  MAE=174.591  RMSE=329.848\n",
      "   72h  MAE=179.308  RMSE=336.321\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 9/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 10/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: train_loss=0.202945 val_avg_MAE=163.730\n",
      "\n",
      "VAL\n",
      "   12h  MAE=151.945  RMSE=292.227\n",
      "   24h  MAE=153.064  RMSE=295.175\n",
      "   48h  MAE=171.462  RMSE=326.036\n",
      "   72h  MAE=178.449  RMSE=335.917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 11/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 12/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: train_loss=0.198216 val_avg_MAE=155.706\n",
      "\n",
      "VAL\n",
      "   12h  MAE=136.625  RMSE=266.437\n",
      "   24h  MAE=144.763  RMSE=286.044\n",
      "   48h  MAE=167.613  RMSE=320.622\n",
      "   72h  MAE=173.824  RMSE=329.629\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 13/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 14/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: train_loss=0.192930 val_avg_MAE=155.351\n",
      "\n",
      "VAL\n",
      "   12h  MAE=141.359  RMSE=274.892\n",
      "   24h  MAE=143.427  RMSE=283.277\n",
      "   48h  MAE=165.045  RMSE=319.274\n",
      "   72h  MAE=171.573  RMSE=327.310\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 15/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 16/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: train_loss=0.190082 val_avg_MAE=151.296\n",
      "\n",
      "VAL\n",
      "   12h  MAE=136.104  RMSE=268.312\n",
      "   24h  MAE=140.233  RMSE=278.416\n",
      "   48h  MAE=160.874  RMSE=311.844\n",
      "   72h  MAE=167.973  RMSE=322.489\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 17/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 18/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: train_loss=0.185419 val_avg_MAE=148.935\n",
      "\n",
      "VAL\n",
      "   12h  MAE=131.536  RMSE=258.236\n",
      "   24h  MAE=137.515  RMSE=274.154\n",
      "   48h  MAE=160.364  RMSE=310.237\n",
      "   72h  MAE=166.323  RMSE=318.238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 19/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 20/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: train_loss=0.183914 val_avg_MAE=150.846\n",
      "\n",
      "VAL\n",
      "   12h  MAE=131.105  RMSE=259.312\n",
      "   24h  MAE=140.069  RMSE=278.347\n",
      "   48h  MAE=164.003  RMSE=314.785\n",
      "   72h  MAE=168.208  RMSE=320.337\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 21/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 22/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: train_loss=0.180233 val_avg_MAE=152.782\n",
      "\n",
      "VAL\n",
      "   12h  MAE=129.453  RMSE=251.578\n",
      "   24h  MAE=138.289  RMSE=276.005\n",
      "   48h  MAE=168.168  RMSE=323.403\n",
      "   72h  MAE=175.219  RMSE=333.212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 23/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 24/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: train_loss=0.178551 val_avg_MAE=146.026\n",
      "\n",
      "VAL\n",
      "   12h  MAE=133.525  RMSE=262.309\n",
      "   24h  MAE=136.011  RMSE=271.153\n",
      "   48h  MAE=154.218  RMSE=300.318\n",
      "   72h  MAE=160.350  RMSE=309.459\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 25/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a4c6e961a54ef1ae67d4a61ce2ce5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 26/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915d986f84bf490a826988fc0ea0e9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: train_loss=0.177030 val_avg_MAE=148.570\n",
      "\n",
      "VAL\n",
      "   12h  MAE=135.140  RMSE=266.850\n",
      "   24h  MAE=135.999  RMSE=273.156\n",
      "   48h  MAE=158.709  RMSE=309.698\n",
      "   72h  MAE=164.434  RMSE=319.642\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e37f5d94c5e432aa24eda9900fcbc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 27/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80dbd7581e964b59a369f2093ddbe895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 28/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507a94137c33433f8347f70217021efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: train_loss=0.175294 val_avg_MAE=141.994\n",
      "\n",
      "VAL\n",
      "   12h  MAE=128.672  RMSE=253.429\n",
      "   24h  MAE=130.524  RMSE=265.118\n",
      "   48h  MAE=151.308  RMSE=297.043\n",
      "   72h  MAE=157.473  RMSE=305.931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d44b3481d6148358923051a39eb0096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 29/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae2858dfc154fb09525b684f19f109e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 30/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c899299a7e4bfbb7b2c05fdae3219c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: train_loss=0.174034 val_avg_MAE=145.617\n",
      "\n",
      "VAL\n",
      "   12h  MAE=129.858  RMSE=257.859\n",
      "   24h  MAE=132.704  RMSE=268.412\n",
      "   48h  MAE=155.743  RMSE=305.075\n",
      "   72h  MAE=164.161  RMSE=320.209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2204ccb85446a2ac5fa5f3c39d5aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 31/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5600f285de54b51af26b7c3e10b3edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 32/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42325a07fb24a9da77fafbb22cc6e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: train_loss=0.172956 val_avg_MAE=145.367\n",
      "\n",
      "VAL\n",
      "   12h  MAE=129.445  RMSE=256.178\n",
      "   24h  MAE=132.911  RMSE=270.741\n",
      "   48h  MAE=156.525  RMSE=307.543\n",
      "   72h  MAE=162.586  RMSE=316.788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8e1b70490f47f38a332d9ddfd8110f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 33/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5aeed39a9b49c98226a387311260c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 34/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899da9b986fc42e2a073971d1762c08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: train_loss=0.171843 val_avg_MAE=143.985\n",
      "\n",
      "VAL\n",
      "   12h  MAE=120.119  RMSE=239.259\n",
      "   24h  MAE=134.027  RMSE=273.253\n",
      "   48h  MAE=158.614  RMSE=312.432\n",
      "   72h  MAE=163.180  RMSE=316.732\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be0e61cf89445e4827fe10e27eb3227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 35/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594d9d29c4e14d94a735857b291802c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 36/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fce1a0dd8049c490715df486e36d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: train_loss=0.171044 val_avg_MAE=147.171\n",
      "\n",
      "VAL\n",
      "   12h  MAE=130.143  RMSE=258.121\n",
      "   24h  MAE=133.319  RMSE=270.872\n",
      "   48h  MAE=157.858  RMSE=310.634\n",
      "   72h  MAE=167.366  RMSE=326.320\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016819f092fd49089498e9f9df6e169a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 37/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08d96c4242a4272ad1673cb0b0e0c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 38/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9226fc13cee4c9184deaf85a5ae3f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: train_loss=0.169688 val_avg_MAE=144.147\n",
      "\n",
      "VAL\n",
      "   12h  MAE=121.013  RMSE=241.299\n",
      "   24h  MAE=131.525  RMSE=268.733\n",
      "   48h  MAE=158.283  RMSE=311.138\n",
      "   72h  MAE=165.768  RMSE=320.365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14106a30491a4bf3bedda804fccd34a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 39/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6b831f93b846888d1eadebcc97585e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train 40/40:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2a5f07f8aa4f088d356c34f2cfbc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40: train_loss=0.169250 val_avg_MAE=144.258\n",
      "\n",
      "VAL\n",
      "   12h  MAE=119.834  RMSE=241.589\n",
      "   24h  MAE=133.103  RMSE=272.535\n",
      "   48h  MAE=157.770  RMSE=308.974\n",
      "   72h  MAE=166.324  RMSE=321.353\n",
      "\n",
      "Early stopping. Best val_avg_MAE=141.994\n",
      "Saved history: artifacts/runs/20260210_223029_CNN_GRU_LSTM/history.csv\n",
      "\n",
      "Evaluating on TEST set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5f48908deb41818d84b3d7148e120a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN_GRU_LSTM — TEST\n",
      "   12h  MAE=132.169  RMSE=254.404\n",
      "   24h  MAE=126.465  RMSE=251.612\n",
      "   48h  MAE=142.666  RMSE=285.668\n",
      "   72h  MAE=152.196  RMSE=297.030\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcfda5aeb5847f780e2d26917161cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collect preds:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved run outputs to: artifacts/runs/20260210_223029_CNN_GRU_LSTM\n",
      " - best checkpoint: artifacts/runs/20260210_223029_CNN_GRU_LSTM/best.pt\n",
      " - history: artifacts/runs/20260210_223029_CNN_GRU_LSTM/history.csv\n",
      " - test metrics: artifacts/runs/20260210_223029_CNN_GRU_LSTM/test_metrics.json\n",
      " - predictions (npz): artifacts/runs/20260210_223029_CNN_GRU_LSTM/test_pred_true_selected_horizons.npz\n",
      " - predictions (xlsx): artifacts/runs/20260210_223029_CNN_GRU_LSTM/test_pred_true_selected_horizons.xlsx\n",
      " - master summary: artifacts/results_summary.csv\n",
      "Saved to: artifacts/runs/20260210_223029_CNN_GRU_LSTM\n"
     ]
    }
   ],
   "source": [
    "# Make the model\n",
    "cnn_gru_lstm = CNN_GRU_LSTM_MultiHorizon(\n",
    "    in_dim=Fdim,\n",
    "    out_len=OUT_LEN,\n",
    "    tf_dim=4,\n",
    "    conv_channels=32,\n",
    "    conv_kernel=3,\n",
    "    gru_hidden=64,\n",
    "    lstm_hidden=64,\n",
    "    dropout=0.1,\n",
    "    use_time_bias=True,\n",
    "    node_chunk=256,   # if you still OOM, drop to 128\n",
    ").to(DEVICE)\n",
    "\n",
    "# Sanity forward\n",
    "xb, yb, tfb = next(iter(train_loader))\n",
    "with torch.no_grad():\n",
    "    out = cnn_gru_lstm(xb.to(DEVICE), tfb.to(DEVICE))\n",
    "print(\"Forward:\", out.shape, \"mean/std:\", float(out.mean()), float(out.std()))\n",
    "\n",
    "# Train + save (same as you did for STGCN/GWN)\n",
    "run_dir = run_experiment_and_save(\n",
    "    model_name=\"CNN_GRU_LSTM\",\n",
    "    model=cnn_gru_lstm,\n",
    "    epochs=40,\n",
    "    patience=6,\n",
    "    eval_every=2,\n",
    "    horizons_to_save=(12, 24, 48, 72),\n",
    "    max_stations_excel=300\n",
    ")\n",
    "\n",
    "print(\"Saved to:\", run_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc5ab27-36ed-4ac5-92ab-bc7eb49dab2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
